{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup in GCP\n",
    "- apt-get --purge remove \"cublas\" \"cuda*\"\n",
    "- reboot\n",
    "- sudo curl -O http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
    "- sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
    "- sudo apt-get install cuda-10-1\n",
    "- pip3 install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-geometric\n",
    "\n",
    "** Both the PyTorch and torch_sparse CUDA version must matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import torch; print(torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.243\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all required arguments\n",
    "class gnn_args:\n",
    "    def __init__(self):\n",
    "        self.datadir = \"data\"        # Directory where benchmark is stored (io_parser)\n",
    "        self.logdir = \"log\"          # Tensorboard log directory\n",
    "        self.ckptdir = \"ckpt\"        # Model checkpoint directory\n",
    "        self.dataset = \"BAGraph\"     # Synthetic dataset, syn1\n",
    "        self.opt = \"adam\"            # opt_parser\n",
    "        self.opt_scheduler = \"none\"  # Optimizer scheduler\n",
    "        self.max_nodes = 100         # Maximum number of nodes\n",
    "                                     # (ignore graphs with nodes exceeding the number)\n",
    "        self.cuda = \"0\"              # CUDA value\n",
    "        self.feature_type = \"default\"# Feature used for encoder with possible values : id, deg\n",
    "        self.lr = 0.001              # Learning rate\n",
    "        self.clip = 2.0\n",
    "        \n",
    "        self.batch_size = 20         # Batch size\n",
    "        self.num_epochs = 1000       # Number of epochs to train data\n",
    "        self.train_ratio = 0.8       # Ratio of number of training set to all graphs\n",
    "        self.test_ratio = 0.1\n",
    "        self.num_workers = 1         # Number of workers to load data\n",
    "        self.input_dim = 10          # Input feature dimension\n",
    "        self.hidden_dim = 20         # Hidden layer dimension\n",
    "        self.output_dim = 20         # Output layer dimension\n",
    "        self.num_classes = 2         # Number of label classes\n",
    "        self.num_gc_layers = 3       # Number of graph convolution layers before each pooling\n",
    "        \n",
    "        self.dropout = 0.0           # Dropout rate\n",
    "        self.weight_decay = 0.005    # Weight decay regularization constant\n",
    "        self.method = \"base\"         # Method used with possible values : base\n",
    "        self.name_suffix = \"\"        # Suffix added to the output filename\n",
    "        self.assign_ratio = 0.1      # Ratio of number of nodes in consecutive layers\n",
    "        \n",
    "        self.bias = True             # \"Whether to add bias\n",
    "        \n",
    "        self.gpu = False             # Whether to use GPU\n",
    "        self.linkpred = False        # Whether link prediction side objective is used\n",
    "        self.bn = False              # Whether batch normalization is used\n",
    "        self.bmname = None           # Name of the benchmark datase\n",
    "\n",
    "prog_args = gnn_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in Constant Feature Generator :  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Constant feature generator :  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "------ Building the Synthetic BA graph with 'House' motifs ------\n",
      "Role Id of the BA graph :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Indicator of the id of the next node : 20\n",
      "Number of nodes in the BA graph :  20\n",
      "Number of motifs :  3\n",
      "List of shapes : [['house'], ['house'], ['house']]\n",
      "No. of shapes : 3\n",
      "Spacing :  6\n",
      "Plugins :  [0, 6, 12]\n",
      "seen_shapes :  {'basis': [0, 20]}\n",
      "\n",
      "-----------------------------------------\n",
      "Shape_ID : 0 with shape type : house\n",
      "1 shapes with list of Shape : ['house']\n",
      "The shape starts from index 1 :  []\n",
      "\n",
      "The list of arguments : [20, 0]\n",
      "The first item in list of arguments : 20\n",
      "The second item in list of arguments : 0\n",
      "Column start : 1\n",
      "Observe seen_shapes :  {'basis': [0, 20], 'house': [1, 5]}\n",
      "Labels of BA graph with attached motifs :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3]\n",
      "No. of nodes in attached graph :  25\n",
      "With attached motif nodes, index starts from :  25\n",
      "\n",
      "-----------------------------------------\n",
      "Shape_ID : 1 with shape type : house\n",
      "1 shapes with list of Shape : ['house']\n",
      "The shape starts from index 1 :  []\n",
      "\n",
      "The list of arguments : [25, 0]\n",
      "The first item in list of arguments : 25\n",
      "The second item in list of arguments : 0\n",
      "Column start : 1\n",
      "Observe seen_shapes :  {'basis': [0, 20], 'house': [1, 5]}\n",
      "Labels of BA graph with attached motifs :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3]\n",
      "No. of nodes in attached graph :  30\n",
      "With attached motif nodes, index starts from :  30\n",
      "\n",
      "-----------------------------------------\n",
      "Shape_ID : 2 with shape type : house\n",
      "1 shapes with list of Shape : ['house']\n",
      "The shape starts from index 1 :  []\n",
      "\n",
      "The list of arguments : [30, 0]\n",
      "The first item in list of arguments : 30\n",
      "The second item in list of arguments : 0\n",
      "Column start : 1\n",
      "Observe seen_shapes :  {'basis': [0, 20], 'house': [1, 5]}\n",
      "Labels of BA graph with attached motifs :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3]\n",
      "No. of nodes in attached graph :  35\n",
      "With attached motif nodes, index starts from :  35\n",
      "\n",
      "Information of the motif graph :\n",
      " Name: \n",
      "Type: Graph\n",
      "Number of nodes: 5\n",
      "Number of edges: 6\n",
      "Average degree:   2.4000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate node features for 35 nodes.\n",
      "Values of feat_dict[0][\"feat\"]: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Node attributes of node '0', G.nodes[0][\"feat\"]: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "------ Generated the Synthetic BA graph with 'House' motifs ------\n",
      "Name of generated graph : ba_20_3\n",
      "------------ GCNEncoderNode Model ------------\n",
      "Input dimensions : 10\n",
      "Hidden dimensions : 20\n",
      "Output dimensions : 20\n",
      "Number of classes in args : 4\n",
      "Number of GCN layers : 3\n",
      "Method :  base\n",
      "*** Check received batch_size argument : 20\n",
      "*** Batch normalization from caller (default : False) : False\n",
      "GcnEncoderNode model :\n",
      " GcnEncoderNode(\n",
      "  (conv_first): GraphConv()\n",
      "  (conv_block): ModuleList(\n",
      "    (0): GraphConv()\n",
      "  )\n",
      "  (conv_last): GraphConv()\n",
      "  (act): ReLU()\n",
      "  (pred_model): Linear(in_features=60, out_features=4, bias=True)\n",
      "  (celoss): CrossEntropyLoss()\n",
      ")\n",
      "------ Preprocess Input graph ------\n",
      "The shape of the adjacency matrix ('dxd') of input graph : (35, 35)\n",
      "Feature dimensions of the last node '34' : 10\n",
      "The shape of the adjacency matrix after expansion : (1, 35, 35)\n",
      "The shape of the features matrix after expansion : (1, 35, 10)\n",
      "The shape of the labels matrix after expansion : (1, 35)\n",
      "epoch:  0 ; loss:  1.2813977003097534 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.02\n",
      "epoch:  10 ; loss:  1.2268707752227783 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  20 ; loss:  1.1831876039505005 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  30 ; loss:  1.1483770608901978 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  40 ; loss:  1.121497392654419 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  50 ; loss:  1.100620150566101 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  60 ; loss:  1.084598422050476 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  70 ; loss:  1.071054220199585 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  80 ; loss:  1.056596279144287 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  90 ; loss:  1.03703773021698 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  100 ; loss:  1.0029340982437134 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  110 ; loss:  0.9399576187133789 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  120 ; loss:  0.8476147055625916 ; train_acc:  0.6071428571428571 ; test_acc:  0.42857142857142855 ; train_prec:  0.15178571428571427 ; test_prec:  0.10714285714285714 ; epoch time:  0.00\n",
      "epoch:  130 ; loss:  0.7613278031349182 ; train_acc:  0.6785714285714286 ; test_acc:  0.5714285714285714 ; train_prec:  0.275 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  140 ; loss:  0.7027201056480408 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  150 ; loss:  0.6572378277778625 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  160 ; loss:  0.6203130483627319 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  170 ; loss:  0.5903053879737854 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  180 ; loss:  0.56557297706604 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  190 ; loss:  0.5441924929618835 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  200 ; loss:  0.5245459675788879 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  210 ; loss:  0.5047427415847778 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  220 ; loss:  0.48257869482040405 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  230 ; loss:  0.45650243759155273 ; train_acc:  0.7857142857142857 ; test_acc:  0.5714285714285714 ; train_prec:  0.36363636363636365 ; test_prec:  0.3125 ; epoch time:  0.00\n",
      "epoch:  240 ; loss:  0.42487213015556335 ; train_acc:  0.9285714285714286 ; test_acc:  0.8571428571428571 ; train_prec:  0.6666666666666666 ; test_prec:  0.6666666666666666 ; epoch time:  0.00\n",
      "epoch:  250 ; loss:  0.3952179253101349 ; train_acc:  0.9285714285714286 ; test_acc:  0.8571428571428571 ; train_prec:  0.6666666666666666 ; test_prec:  0.6666666666666666 ; epoch time:  0.00\n",
      "epoch:  260 ; loss:  0.3684850037097931 ; train_acc:  0.9285714285714286 ; test_acc:  0.8571428571428571 ; train_prec:  0.6666666666666666 ; test_prec:  0.6666666666666666 ; epoch time:  0.00\n",
      "epoch:  270 ; loss:  0.3446097671985626 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  280 ; loss:  0.32174065709114075 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  290 ; loss:  0.3012123107910156 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  300 ; loss:  0.2813742756843567 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  310 ; loss:  0.2627962529659271 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  320 ; loss:  0.24469269812107086 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  330 ; loss:  0.22769519686698914 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  340 ; loss:  0.21207499504089355 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  350 ; loss:  0.197464257478714 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  360 ; loss:  0.18450352549552917 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  370 ; loss:  0.17288582026958466 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  380 ; loss:  0.1621144562959671 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  390 ; loss:  0.1527441293001175 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  400 ; loss:  0.14395061135292053 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  410 ; loss:  0.13622352480888367 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  420 ; loss:  0.12948647141456604 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  430 ; loss:  0.12277315557003021 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  440 ; loss:  0.11686494201421738 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  450 ; loss:  0.11132128536701202 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  460 ; loss:  0.10613115131855011 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  470 ; loss:  0.10136053711175919 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  480 ; loss:  0.0970691442489624 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  490 ; loss:  0.092899851500988 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  500 ; loss:  0.08908329159021378 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  510 ; loss:  0.08573535829782486 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  520 ; loss:  0.08255492895841599 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  530 ; loss:  0.07921961694955826 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  540 ; loss:  0.07626450061798096 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  550 ; loss:  0.07357489317655563 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  560 ; loss:  0.07092233747243881 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  570 ; loss:  0.06847823411226273 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  580 ; loss:  0.06613960862159729 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  590 ; loss:  0.06376198679208755 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  600 ; loss:  0.06183060631155968 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  610 ; loss:  0.05968832969665527 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  620 ; loss:  0.05774857848882675 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  630 ; loss:  0.05594600364565849 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  640 ; loss:  0.05418305844068527 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  650 ; loss:  0.052451085299253464 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  660 ; loss:  0.050960976630449295 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  670 ; loss:  0.04932389408349991 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  680 ; loss:  0.04785609990358353 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  690 ; loss:  0.04635069891810417 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  700 ; loss:  0.04498649016022682 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  710 ; loss:  0.04366278275847435 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  720 ; loss:  0.042307786643505096 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  730 ; loss:  0.04101800546050072 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  740 ; loss:  0.03991040214896202 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  750 ; loss:  0.038592059165239334 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  760 ; loss:  0.03743257746100426 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  770 ; loss:  0.03627929836511612 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  780 ; loss:  0.03522053360939026 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  790 ; loss:  0.03407863527536392 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  800 ; loss:  0.03315367549657822 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  810 ; loss:  0.03224045783281326 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  820 ; loss:  0.03118905983865261 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  830 ; loss:  0.030463868752121925 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  840 ; loss:  0.029652999714016914 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  850 ; loss:  0.02889123000204563 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  860 ; loss:  0.028006939217448235 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  870 ; loss:  0.02724115364253521 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  880 ; loss:  0.026477664709091187 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  890 ; loss:  0.025825798511505127 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  900 ; loss:  0.0251732487231493 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  910 ; loss:  0.024584872648119926 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  920 ; loss:  0.02396063692867756 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  930 ; loss:  0.023364486172795296 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  940 ; loss:  0.022761564701795578 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  950 ; loss:  0.022189736366271973 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  960 ; loss:  0.02168690226972103 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  970 ; loss:  0.02122332714498043 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  980 ; loss:  0.02064400538802147 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  990 ; loss:  0.020177805796265602 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "Confusion Matrix of train result :\n",
      " [[17  0  0  0]\n",
      " [ 0  5  0  0]\n",
      " [ 0  0  4  0]\n",
      " [ 0  0  0  2]]\n",
      "Confusion Matrix of test result :\n",
      " [[3 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 1]]\n",
      "Labels of the Computational graph :\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 2 3 1 1 2 2 3 1 1 2 2 3]]\n",
      "Prediction result of the Computational graph :\n",
      " [[[ 3.6736860e+00 -1.6599860e+00 -4.6704564e+00 -2.1966453e+00]\n",
      "  [ 3.6267667e+00 -2.0992751e+00 -3.9906774e+00 -2.3146467e+00]\n",
      "  [ 3.7007194e+00 -2.0671744e+00 -4.1609516e+00 -2.2798772e+00]\n",
      "  [ 3.6802325e+00 -1.8951300e+00 -4.3362646e+00 -2.3238745e+00]\n",
      "  [ 3.4166341e+00 -2.4232545e+00 -3.3606343e+00 -2.0964022e+00]\n",
      "  [ 3.5891595e+00 -1.6461571e+00 -4.4655619e+00 -2.3630919e+00]\n",
      "  [ 3.6137071e+00 -1.5754014e+00 -4.6293774e+00 -2.2869935e+00]\n",
      "  [ 3.6807306e+00 -1.8284740e+00 -4.4047446e+00 -2.3295140e+00]\n",
      "  [ 3.5877421e+00 -1.7230319e+00 -4.3911514e+00 -2.3617578e+00]\n",
      "  [ 3.6060596e+00 -1.8042718e+00 -4.3278084e+00 -2.3601761e+00]\n",
      "  [ 3.6700091e+00 -1.8380210e+00 -4.3822885e+00 -2.3341575e+00]\n",
      "  [ 3.7067192e+00 -1.9675404e+00 -4.2850499e+00 -2.2994475e+00]\n",
      "  [ 3.6512260e+00 -1.7869762e+00 -4.5448866e+00 -2.2204547e+00]\n",
      "  [ 3.5723877e+00 -2.0918269e+00 -3.8925095e+00 -2.3365993e+00]\n",
      "  [ 3.6371303e+00 -2.2308948e+00 -3.8341250e+00 -2.2533960e+00]\n",
      "  [ 3.5845289e+00 -2.0877137e+00 -3.9280379e+00 -2.3324838e+00]\n",
      "  [ 3.4670672e+00 -2.0304155e+00 -3.7892575e+00 -2.3607144e+00]\n",
      "  [ 3.7128572e+00 -2.2163711e+00 -3.9990501e+00 -2.1859560e+00]\n",
      "  [ 3.6118479e+00 -2.1872005e+00 -3.8601470e+00 -2.2778964e+00]\n",
      "  [ 3.5998173e+00 -2.2015700e+00 -3.8168247e+00 -2.2731268e+00]\n",
      "  [-1.8264988e-01  3.8801899e+00 -1.0796434e+00 -3.5896912e+00]\n",
      "  [-1.1833704e+00  3.9066038e+00  4.9942732e-04 -3.2247910e+00]\n",
      "  [-2.5463543e+00 -5.0574660e-02  3.6609259e+00 -2.6098651e-01]\n",
      "  [-2.6320674e+00 -3.6672869e-01  3.8778143e+00  1.2888318e-01]\n",
      "  [-6.7302585e-01 -3.3510113e+00 -3.7014550e-01  2.8996739e+00]\n",
      "  [ 4.5077711e-02  3.7686443e+00 -1.3796352e+00 -3.5882592e+00]\n",
      "  [-1.1938553e+00  3.9094415e+00  5.1310271e-02 -3.2561488e+00]\n",
      "  [-2.5463543e+00 -5.0574660e-02  3.6609259e+00 -2.6098651e-01]\n",
      "  [-2.5818567e+00 -4.4392434e-01  3.8527932e+00  1.1740786e-01]\n",
      "  [-6.3388419e-01 -3.4795957e+00 -3.5484093e-01  2.9075360e+00]\n",
      "  [-1.3462710e-01  3.8613267e+00 -1.1875023e+00 -3.5678673e+00]\n",
      "  [-1.1833704e+00  3.9066038e+00  4.9942732e-04 -3.2247910e+00]\n",
      "  [-2.5463543e+00 -5.0574660e-02  3.6609259e+00 -2.6098651e-01]\n",
      "  [-2.6320674e+00 -3.6672869e-01  3.8778143e+00  1.2888318e-01]\n",
      "  [-6.7302585e-01 -3.3510113e+00 -3.7014550e-01  2.8996739e+00]]]\n",
      "Train index of the Computational graph data :\n",
      " [16, 30, 6, 1, 21, 4, 13, 0, 8, 7, 12, 28, 33, 17, 27, 20, 34, 26, 19, 10, 3, 11, 2, 25, 14, 32, 9, 24]\n",
      "Created filename with path :  ./ckpt/BAGraph_base_hdim20_odim20/BA_graph_model_dict.pth\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "\n",
    "model = train.syn_task1(prog_args, writer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv_first.weight \t torch.Size([10, 20])\n",
      "conv_first.bias \t torch.Size([20])\n",
      "conv_block.0.weight \t torch.Size([20, 20])\n",
      "conv_block.0.bias \t torch.Size([20])\n",
      "conv_last.weight \t torch.Size([20, 20])\n",
      "conv_last.bias \t torch.Size([20])\n",
      "pred_model.weight \t torch.Size([4, 60])\n",
      "pred_model.bias \t torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "# Print optimizer's state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optimizer.state_dict():\n",
    "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/io_utils.py\n",
    "import torch\n",
    "\n",
    "'''\n",
    "Load a pre-trained pytorch model from checkpoint.\n",
    "'''\n",
    "def load_ckpt(args, isbest=False):\n",
    "\n",
    "    print(\"Attempt to load model...\")\n",
    "    filename = create_filename(args.ckptdir, args, isbest)\n",
    "    print(\"Loading file : \", filename)\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        ckpt = torch.load(filename)\n",
    "    else:\n",
    "        print(\"Checkpoint does not exist!\")\n",
    "        print(\"Check correct path for : {}\".format(filename))\n",
    "        print(\"Make sure you have provided the correct path!\")\n",
    "        print(\"Or you may have forgotten to train a model for this dataset.\")\n",
    "        print()\n",
    "        print(\"To train one of the models, run the following\")\n",
    "        print(\">> python train.py --dataset=DATASET_NAME\")\n",
    "        print()\n",
    "        raise Exception(\"File is not found.\")\n",
    "    return ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn-model-explainer/utils/io_utils.py\n",
    "import os\n",
    "\n",
    "'''\n",
    "Generate label prefix for a graph model.\n",
    "'''\n",
    "def gen_prefix(args):\n",
    "    if args.bmname is not None:\n",
    "        name = args.bmname\n",
    "    else:\n",
    "        name = args.dataset\n",
    "    name += \"_\" + args.method\n",
    "\n",
    "    name += \"_hdim\" + str(args.hidden_dim) + \"_odim\" + str(args.output_dim)\n",
    "    if not args.bias:\n",
    "        name += \"_nobias\"\n",
    "    if len(args.name_suffix) > 0:\n",
    "        name += \"_\" + args.name_suffix\n",
    "    return name\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create filename for saving.\n",
    "\n",
    "Args:\n",
    "    args        :  the arguments parsed in the parser\n",
    "    isbest      :  whether the saved model is the best-performing one\n",
    "    num_epochs  :  epoch number of the model (when isbest=False)\n",
    "\"\"\"\n",
    "def create_filename(save_dir, args, isbest=False, num_epochs=-1):\n",
    "    filename = os.path.join(\"./\", save_dir, gen_prefix(args))\n",
    "    os.makedirs(filename, exist_ok=True)\n",
    "\n",
    "    if isbest:\n",
    "        filename = os.path.join(filename, \"best\")\n",
    "    elif num_epochs > 0:\n",
    "        filename = os.path.join(filename, str(num_epochs))\n",
    "    else:\n",
    "        filename = os.path.join(filename, \"BA_graph\")\n",
    "\n",
    "    path_filename = filename + \"_model_dict.pth\" # \".pth.tar\"\n",
    "    print(\"Created filename with path : \", path_filename)\n",
    "    return path_filename\n",
    "\n",
    "\"\"\"\n",
    "Save pytorch model checkpoint.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "model         : The PyTorch model to save.\n",
    "optimizer     : The optimizer used to train the model.\n",
    "args          : A dict of meta-data about the model.\n",
    "num_epochs    : Number of training epochs.\n",
    "isbest        : True if the model has the highest accuracy so far.\n",
    "cg_dict       : A dictionary of the sampled computation graphs.\n",
    "\n",
    "Output :\n",
    "----------------------------------------------------------------------------------------\n",
    "filename      : File saved in \"ckpt\" subdirectory\n",
    "\"\"\"\n",
    "def save_checkpoint(model, optimizer, args, num_epochs=-1, isbest=False, cg_dict=None):\n",
    "    filename = create_filename(args.ckptdir, args, isbest, num_epochs=num_epochs)\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": num_epochs,\n",
    "            \"model_type\": args.method,\n",
    "            \"optimizer\": optimizer,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"cg\": cg_dict,\n",
    "        },\n",
    "        filename\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to load model...\n",
      "Created filename with path :  ./ckpt/BAGraph_base_hdim20_odim20/BA_graph_model_dict.pth\n",
      "Loading file :  ./ckpt/BAGraph_base_hdim20_odim20/BA_graph_model_dict.pth\n",
      "=> loading checkpoint './ckpt/BAGraph_base_hdim20_odim20/BA_graph_model_dict.pth'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0.0,\n",
       "  'amsgrad': False,\n",
       "  'params': [140499740569320,\n",
       "   140497399553912,\n",
       "   140497399583656,\n",
       "   140499740542656,\n",
       "   140499740543232,\n",
       "   140497399536952,\n",
       "   140497399873256,\n",
       "   140497449297672]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = load_ckpt(prog_args)\n",
    "model_optimizer = model_dict['optimizer']\n",
    "model_optimizer.state_dict()['param_groups']\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in loaded model dictionary : ['epoch', 'model_type', 'optimizer', 'model_state', 'optimizer_state', 'cg']\n",
      "Keys in loaded model optimizer dictionary: ['state', 'param_groups']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        2, 2, 3, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Keys in loaded model dictionary :\",list(model_dict))\n",
    "print(\"Keys in loaded model optimizer dictionary:\",list(model_optimizer.state_dict()))\n",
    "\n",
    "model_dict['cg']['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All respective files are in placed to run the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# This notebook works with Pytorch geometric GNNExplainer for explaining node predictions\n",
    "# of Cora dataset and/or BA Graph with house motifs\n",
    "# Created by : Au Jit Seah\n",
    "# File owners : Au Jit Seah\n",
    "##########################################################################################\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic graphs for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntheticSim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the BA-shape with house motifs and setting roles that will be used as labels\n",
    "\"\"\"\n",
    "Builds a BA preferential attachment graph, with \"node index\" starting from \"start\"\n",
    "parameter and \"role_ids\" from \"role_start\" parameter\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "start       :    starting index of the shape\n",
    "width       :    int size of the graph (no. of nodes)\n",
    "role_start  :    starting index for the roles\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "graph       :    a ba graph, with ids beginning from start\n",
    "roles       :    list of the roles of the nodes (indexed starting from\n",
    "                 role_start) that will be used as labels\n",
    "\"\"\"\n",
    "def ba(start, width, role_start=0, m=5):\n",
    "    graph = nx.barabasi_albert_graph(width, m)\n",
    "    graph.add_nodes_from(range(start, start + width))\n",
    "    nids = sorted(graph)\n",
    "    mapping = {nid: start + i for i, nid in enumerate(nids)}\n",
    "    graph = nx.relabel_nodes(graph, mapping)\n",
    "    roles = [role_start for i in range(width)]\n",
    "    return graph, roles\n",
    "\n",
    "\"\"\"\n",
    "Builds a house-like graph/motif, with \"node index\" starting from \"start\"\n",
    "parameter and \"role_ids\" from \"role_start\" parameter\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "start       :    starting index for the shape\n",
    "role_start  :    starting index for the roles\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "graph       :    a house-like graph/motif, with ids beginning from start\n",
    "roles       :    list of the roles of the nodes (indexed starting at\n",
    "                 role_start) that will be used as labels\n",
    "\"\"\"\n",
    "def house(start, role_start=0):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(start, start + 5))\n",
    "    graph.add_edges_from(\n",
    "        [\n",
    "            (start, start + 1),\n",
    "            (start + 1, start + 2),\n",
    "            (start + 2, start + 3),\n",
    "            (start + 3, start),\n",
    "        ]\n",
    "    )\n",
    "    # graph.add_edges_from([(start, start + 2), (start + 1, start + 3)])\n",
    "    graph.add_edges_from([(start + 4, start), (start + 4, start + 1)])\n",
    "    roles = [role_start, role_start, role_start + 1, role_start + 1, role_start + 2]\n",
    "    return graph, roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a basis graph and attaches elements of the type in the list randomly along the basis.\n",
    "Possibility to add random edges afterwards.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "width_basis       :      width (in terms of number of nodes) of the basis\n",
    "basis_type        :      \"ba\"\n",
    "shapes            :      list of shape list\n",
    "                         (1st arg  : type of shape,\n",
    "                         next args : args for building the shape except for the start)\n",
    "start             :      initial node label for the first node\n",
    "rdm_basis_plugins :      Boolean\n",
    "                         For the shapes to be attached randomly (True) or\n",
    "                         regularly (False) to the basis graph\n",
    "add_random_edges  :      no. of edges to randomly add on the structure\n",
    "m                 :      no. of new edges to attach to existing node (for BA graph)\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "basis             :      a networkx graph with the particular shape used as the base\n",
    "role_id           :      label for each role (eg. representing basis or edges)\n",
    "plugins           :      node ids whereby the motif graph will be attached to the basis\n",
    "\"\"\"\n",
    "# Eg. build_graph(20, \"ba\", [[\"house\"]], start=0, m=5)\n",
    "def build_graph(width_basis, basis_type, list_shapes, start=0,\n",
    "                rdm_basis_plugins=False,add_random_edges=0, m=5):\n",
    "    print(\"------ Building the Synthetic BA graph with 'House' motifs ------\")\n",
    "    # Build the BA graph start with 0 and number of nodes (width basis)\n",
    "    if basis_type == \"ba\":\n",
    "        # Drawing of a house motif\n",
    "        basis, role_id = eval(basis_type)(start, width_basis, m=m)\n",
    "        print(\"Role Id of the BA graph :\\n\", role_id)\n",
    "#     else:\n",
    "#         # Drawing other type of motif\n",
    "#         basis, role_id = eval(basis_type)(start, width_basis)\n",
    "\n",
    "    n_basis, n_shapes = nx.number_of_nodes(basis), len(list_shapes)\n",
    "    start += n_basis  # indicator of the id of the next node\n",
    "    print(\"Indicator of the id of the next node :\", start)\n",
    "    \n",
    "    # role_id are '0's for all the nodes of the basis, BA graph\n",
    "    print(\"Number of nodes in the BA graph : \", n_basis)\n",
    "    print(\"Number of motifs : \", n_shapes)\n",
    "\n",
    "    print(\"List of shapes :\", list_shapes)\n",
    "    print(\"No. of shapes :\", len(list_shapes))\n",
    "\n",
    "    # Sample (with replacement) where to attach the new motifs\n",
    "    if rdm_basis_plugins is True:\n",
    "        plugins = np.random.choice(n_basis, n_shapes, replace=False)\n",
    "    else:\n",
    "        spacing = math.floor(n_basis / n_shapes)\n",
    "        print(\"Spacing : \", spacing)\n",
    "        plugins = [int(k * spacing) for k in range(n_shapes)]\n",
    "        print(\"Plugins : \", plugins)\n",
    "    seen_shapes = {\"basis\": [0, n_basis]}\n",
    "    print(\"seen_shapes : \", seen_shapes)\n",
    "    \n",
    "    for shape_index, shape in enumerate(list_shapes):\n",
    "        shape_type = shape[0]\n",
    "        print(\"\\n-----------------------------------------\")\n",
    "        print(\"Shape_ID : \" + str(shape_index) + \" with shape type : \" + str(shape_type))\n",
    "        print(str(len(shape)) + \" shapes with list of Shape :\", shape)\n",
    "        print(\"The shape starts from index 1 : \", shape[1:])\n",
    "        \n",
    "        args = [start]\n",
    "        \n",
    "        # More than one shape\n",
    "        if len(shape) > 1:\n",
    "            args += shape[1:]\n",
    "        \n",
    "        # Append 0 for the \"role_start\" in \"house\" function\n",
    "        args += [0]\n",
    "        print(\"\\nThe list of arguments :\", args)\n",
    "        # *args parameter to send a non-keyworded variable-length argument list to function, 1-2 parameters in this case\n",
    "        print(\"The first item in list of arguments :\", args[0])\n",
    "        print(\"The second item in list of arguments :\", args[1])\n",
    "        \n",
    "        # Creating the \"house\" motif\n",
    "        graph_s, roles_graph_s = eval(shape_type)(*args)\n",
    "        n_s = nx.number_of_nodes(graph_s)\n",
    "        \n",
    "        try:\n",
    "             # Get the last seen label from first index\n",
    "            col_start = seen_shapes[shape_type][0]\n",
    "        except:\n",
    "            # Get the max label value 1\n",
    "            col_start = np.max(role_id) + 1\n",
    "            # Add the new shape_type to the seen_shapes dictionary\n",
    "            seen_shapes[shape_type] = [col_start, n_s]\n",
    "        print(\"Column start :\", col_start)\n",
    "        print(\"Observe seen_shapes : \", seen_shapes)\n",
    "        \n",
    "        \n",
    "        # Attach the shape to the basis, BA graph\n",
    "        basis.add_nodes_from(graph_s.nodes())\n",
    "        basis.add_edges_from(graph_s.edges())\n",
    "        # Connecting the motif to the BA graph from node 20 to 0, 25 to 6 and 30 to 12\n",
    "        basis.add_edges_from([(start, plugins[shape_index])])\n",
    "#         if shape_type == \"cycle\":\n",
    "#             if np.random.random() > 0.5:\n",
    "#                 a = np.random.randint(1, 4)\n",
    "#                 b = np.random.randint(1, 4)\n",
    "#                 basis.add_edges_from([(a + start, b + plugins[shape_id])])\n",
    "\n",
    "        # start = 0; col_start = 1; roles_graph_s = [0, 0, 1, 1, 2]\n",
    "        temp_labels = [r + col_start for r in roles_graph_s]\n",
    "        # temp_labels increment roles_graph_s by col_start\n",
    "\n",
    "        # temp_labels[0] += 100 * seen_shapes[shape_type][0]\n",
    "        \n",
    "        # role_id is [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        # Append labels of motif to the labels of BA graph\n",
    "        role_id += temp_labels\n",
    "        print(\"Labels of BA graph with attached motifs :\\n\", role_id)\n",
    "        print(\"No. of nodes in attached graph : \", nx.number_of_nodes(basis))\n",
    "        start += n_s\n",
    "        print(\"With attached motif nodes, index starts from : \", start)\n",
    "\n",
    "#     if add_random_edges > 0:\n",
    "#         # add random edges between nodes:\n",
    "#         for p in range(add_random_edges):\n",
    "#             src, dest = np.random.choice(nx.number_of_nodes(basis), 2, replace=False)\n",
    "#             print(src, dest)\n",
    "#             basis.add_edges_from([(src, dest)])\n",
    "\n",
    "    # Plotting the basis \"BA\" graph\n",
    "    # plt.figure(figsize=(8, 6), dpi=300)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.title('BA graph'.upper(), y=1.0, fontsize=14)\n",
    "    nx.draw(basis, with_labels=True, font_weight='bold')\n",
    "\n",
    "    # Plot the motif \"house\" graph\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.title('\"House\" motif', y=1.0, fontsize=12)\n",
    "    nx.draw(graph_s, with_labels=True, font_weight='bold')\n",
    "    print(\"\\nInformation of the motif graph :\\n\", nx.info(graph_s))\n",
    "    \n",
    "    plt.show()\n",
    "            \n",
    "    return basis, role_id, plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureGen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating node features\n",
    "import abc\n",
    "\n",
    "class FeatureGen(metaclass=abc.ABCMeta):\n",
    "    # Feature Generator base class from Abstract Base Classes\n",
    "    @abc.abstractmethod\n",
    "    def gen_node_features(self, G):\n",
    "        pass\n",
    "\n",
    "class ConstFeatureGen(FeatureGen):\n",
    "    # Generate constant node features in class\n",
    "    def __init__(self, val):\n",
    "        print(\"Values in Constant Feature Generator : \", val)\n",
    "        self.val = val\n",
    "\n",
    "    def gen_node_features(self, G):\n",
    "        print(\"Generate node features for \" + str(len(G.nodes())) + \" nodes.\")\n",
    "        feat_dict = {i:{'feat': np.array(self.val, dtype=np.float32)} for i in G.nodes()}\n",
    "        print('Values of feat_dict[0][\"feat\"]:', feat_dict[0]['feat'])\n",
    "        \n",
    "        # Set node attributes with values in feature dictionary of values '1's\n",
    "        nx.set_node_attributes(G, feat_dict)\n",
    "        print('Node attributes of node \\'0\\', G.nodes[0][\"feat\"]:', G.nodes[0]['feat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic BA graph with \"house\" motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gengraph.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up graph and create its adjacency matrix\n",
    "\"\"\"\n",
    "Perturb the list of (sparse) graphs by adding/removing edges.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "graph_list           :      the list of graphs to be perturbed\n",
    "p                    :      proportion of added edges based on current number of edges.\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "perturbed_graph_list :      the list of graphs that are perturbed from the original graphs.\n",
    "\"\"\"\n",
    "def perturb(graph_list, p):\n",
    "    perturbed_graph_list = []\n",
    "    for G_original in graph_list:\n",
    "        G = G_original.copy()\n",
    "        edge_count = int(G.number_of_edges() * p)\n",
    "        # randomly add the edges between a pair of nodes without an edge.\n",
    "        for _ in range(edge_count):\n",
    "            while True:\n",
    "                u = np.random.randint(0, G.number_of_nodes())\n",
    "                v = np.random.randint(0, G.number_of_nodes())\n",
    "                if (not G.has_edge(u, v)) and (u != v):\n",
    "                    break\n",
    "            G.add_edge(u, v)\n",
    "        perturbed_graph_list.append(G)\n",
    "    return perturbed_graph_list\n",
    "\n",
    "\"\"\"\n",
    "Load an existing graph to be converted for the experiments.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "G                        :      Networkx graph is the input for preprocessing\n",
    "labels                   :      corresponding node labels\n",
    "normalize_adj            :      Boolean\n",
    "                                returns a normalized adjacency matrix (True)\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "{\"adj\", \"feat\" \"labels\"} :  dictionary containing adjacency, node features and labels\n",
    "\"\"\"\n",
    "def preprocess_input_graph(G, labels, normalize_adj=False):\n",
    "    # Create the adjacency matrix for graph\n",
    "    adj = np.array(nx.to_numpy_matrix(G))\n",
    "    print(\"------ Preprocess Input graph ------\")\n",
    "    print(\"The shape of the adjacency matrix ('dxd') of input graph :\", adj.shape)\n",
    "\n",
    "    # If normalization is required\n",
    "#     if normalize_adj:\n",
    "#         # Create a diagonal array\n",
    "#         sqrt_deg = np.diag(1.0 / np.sqrt(np.sum(adj, axis=0, dtype=float).squeeze()))\n",
    "#         adj = np.matmul(np.matmul(sqrt_deg, adj), sqrt_deg)\n",
    "\n",
    "    # last index from 0 - 34\n",
    "    existing_node = list(G.nodes)[-1]\n",
    "    # Dimension of features\n",
    "    feat_dim = G.nodes[existing_node][\"feat\"].shape[0]\n",
    "    print(\"Feature dimensions of the last node '\" + str(existing_node) + \"' : \" + str(feat_dim))\n",
    "\n",
    "    # Initialize feature ndarray (dimension of number_of_nodes x feat_dim) \n",
    "    features = np.zeros((G.number_of_nodes(), feat_dim), dtype=float)\n",
    "    for idx, node_id in enumerate(G.nodes()):\n",
    "        features[idx, :] = G.nodes[node_id][\"feat\"]\n",
    "\n",
    "    # add batch dim by expanding the shape horizontally\n",
    "    adj = np.expand_dims(adj, axis=0)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)    \n",
    "    print(\"The shape of the adjacency matrix after expansion :\", adj.shape)\n",
    "    print(\"The shape of the features matrix after expansion :\", features.shape)\n",
    "    print(\"The shape of the labels matrix after expansion :\", labels.shape)\n",
    "    \n",
    "    return {\"adj\": adj, \"feat\": features, \"labels\": labels}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generating Synthetic Graph for experimentation :\n",
    "- Barabasi-Albert base graph and attach the no. of \"house\" motifs\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "nb_shapes         :  the no. of shapes ('house' motifs) that should be added to the\n",
    "                     base graph\n",
    "width_basis       :  the no. of nodes of the basis graph (ie. 'BA' graph)\n",
    "feature_generator :  a `Feature Generator` for node features\n",
    "                     addition of constant features to nodes ('None')\n",
    "m                 :  no. of edges to be attached to existing node (for 'BA' graph)\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "G                 :  a generated networkx \"ba\" graph with attached \"house\" motifs\n",
    "role_id           :  a list with total number of nodes in the entire graph (base graph\n",
    "                     and  motifs).  role_id[i] is the ID of the role of node i.\n",
    "                     It is also the label used for training and predictions\n",
    "name              :  a graph identifier\n",
    "\"\"\"\n",
    "def gen_syn1(nb_shapes=3, width_basis=20, feature_generator=None, m=5):\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"house\"]] * nb_shapes\n",
    "\n",
    "    # synthetic_structsim\n",
    "    G, role_id, _ = build_graph(width_basis, basis_type, list_shapes, start=0, m=5)\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        # feature generator\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    \n",
    "    # Generate node features\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)\n",
    "    \n",
    "    print(\"------ Generated the Synthetic BA graph with 'House' motifs ------\")\n",
    "    print(\"Name of generated graph :\", name)\n",
    "    return G, role_id, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This is the basic Graph Convolution Network class inherited from torch.nn module\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        add_self=False,\n",
    "        normalize_embedding=False,\n",
    "        dropout=0.0,\n",
    "        bias=True,\n",
    "        gpu=True,\n",
    "        att=False,\n",
    "    ):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.att = att\n",
    "        self.add_self = add_self\n",
    "        self.dropout = dropout\n",
    "        if dropout > 0.001:\n",
    "            self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.normalize_embedding = normalize_embedding\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        if not gpu:\n",
    "            self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
    "            if add_self:\n",
    "                self.self_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, output_dim)\n",
    "                )\n",
    "            if att:\n",
    "                self.att_weight = nn.Parameter(torch.FloatTensor(input_dim, input_dim))\n",
    "        else:\n",
    "            self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim).cuda())\n",
    "            if add_self:\n",
    "                self.self_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, output_dim).cuda()\n",
    "                )\n",
    "            if att:\n",
    "                self.att_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, input_dim).cuda()\n",
    "                )\n",
    "        if bias:\n",
    "            if not gpu:\n",
    "                self.bias = nn.Parameter(torch.FloatTensor(output_dim))\n",
    "            else:\n",
    "                self.bias = nn.Parameter(torch.FloatTensor(output_dim).cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        # self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        if self.dropout > 0.001:\n",
    "            x = self.dropout_layer(x)\n",
    "        # deg = torch.sum(adj, -1, keepdim=True)\n",
    "        if self.att:\n",
    "            x_att = torch.matmul(x, self.att_weight)\n",
    "            # import pdb\n",
    "            # pdb.set_trace()\n",
    "            att = x_att @ x_att.permute(0, 2, 1)\n",
    "            # att = self.softmax(att)\n",
    "            adj = adj * att\n",
    "\n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.add_self:\n",
    "            self_emb = torch.matmul(x, self.self_weight)\n",
    "            y += self_emb\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        if self.normalize_embedding:\n",
    "            y = F.normalize(y, p=2, dim=2)\n",
    "            # print(y[0][0])\n",
    "        return y, adj\n",
    "\n",
    "    \n",
    "# Build the convolution layers for the GCN Graph Encoder\n",
    "# This is where the node masks and embeddings are created with predictions in forward pass\n",
    "class GcnEncoderGraph(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        embedding_dim,           # output_dim\n",
    "        label_dim,               # num_classes\n",
    "        num_layers,              # num_gc_layers\n",
    "        pred_hidden_dims=[],\n",
    "        concat=True,\n",
    "        bn=True,\n",
    "        dropout=0.0,\n",
    "        add_self=False,\n",
    "        args=None,\n",
    "    ):\n",
    "      \n",
    "        super(GcnEncoderGraph, self).__init__()\n",
    "        self.concat = concat\n",
    "\n",
    "        # add_self = add_self\n",
    "        self.add_self = add_self\n",
    "\n",
    "        # This value will change from 'True' if it is provided by the caller function\n",
    "        self.bn = bn\n",
    "        self.num_layers = num_layers\n",
    "        self.num_aggs = 1\n",
    "\n",
    "        self.bias = True        \n",
    "        self.gpu = args.gpu\n",
    "        print(\"*** Check received batch_size argument :\", args.batch_size)\n",
    "        print(\"*** Batch normalization from caller (default : False) :\", bn)\n",
    "\n",
    "        if args.method == \"att\":\n",
    "            self.att = True\n",
    "        else:\n",
    "            self.att = False\n",
    "        if args is not None:\n",
    "            self.bias = args.bias\n",
    "\n",
    "        self.conv_first, self.conv_block, self.conv_last = self.build_conv_layers(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            num_layers,\n",
    "            add_self,\n",
    "            normalize=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        if concat:\n",
    "            self.pred_input_dim = hidden_dim * (num_layers - 1) + embedding_dim\n",
    "        else:\n",
    "            self.pred_input_dim = embedding_dim\n",
    "        self.pred_model = self.build_pred_layers(\n",
    "            self.pred_input_dim, pred_hidden_dims, label_dim, num_aggs=self.num_aggs\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, GraphConv):\n",
    "                init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain(\"relu\"))\n",
    "                if m.att:\n",
    "                    init.xavier_uniform_(\n",
    "                        m.att_weight.data, gain=nn.init.calculate_gain(\"relu\")\n",
    "                    )\n",
    "                if m.add_self:\n",
    "                    init.xavier_uniform_(\n",
    "                        m.self_weight.data, gain=nn.init.calculate_gain(\"relu\")\n",
    "                    )\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    def build_conv_layers(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        embedding_dim,\n",
    "        num_layers,\n",
    "        add_self,\n",
    "        normalize=False,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        conv_first = GraphConv(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=hidden_dim,\n",
    "            add_self=add_self,\n",
    "            normalize_embedding=normalize,\n",
    "            bias=self.bias,\n",
    "            gpu=self.gpu,\n",
    "            att=self.att,\n",
    "        )\n",
    "        conv_block = nn.ModuleList(\n",
    "            [\n",
    "                GraphConv(\n",
    "                    input_dim=hidden_dim,\n",
    "                    output_dim=hidden_dim,\n",
    "                    add_self=add_self,\n",
    "                    normalize_embedding=normalize,\n",
    "                    dropout=dropout,\n",
    "                    bias=self.bias,\n",
    "                    gpu=self.gpu,\n",
    "                    att=self.att,\n",
    "                )\n",
    "                for i in range(num_layers - 2)\n",
    "            ]\n",
    "        )\n",
    "        conv_last = GraphConv(\n",
    "            input_dim=hidden_dim,\n",
    "            output_dim=embedding_dim,\n",
    "            add_self=add_self,\n",
    "            normalize_embedding=normalize,\n",
    "            bias=self.bias,\n",
    "            gpu=self.gpu,\n",
    "            att=self.att,\n",
    "        )\n",
    "        return conv_first, conv_block, conv_last\n",
    "\n",
    "    def build_pred_layers(\n",
    "        self, pred_input_dim, pred_hidden_dims, label_dim, num_aggs=1\n",
    "    ):\n",
    "        pred_input_dim = pred_input_dim * num_aggs\n",
    "        if len(pred_hidden_dims) == 0:\n",
    "            pred_model = nn.Linear(pred_input_dim, label_dim)\n",
    "        else:\n",
    "            pred_layers = []\n",
    "            for pred_dim in pred_hidden_dims:\n",
    "                pred_layers.append(nn.Linear(pred_input_dim, pred_dim))\n",
    "                pred_layers.append(self.act)\n",
    "                pred_input_dim = pred_dim\n",
    "            pred_layers.append(nn.Linear(pred_dim, label_dim))\n",
    "            pred_model = nn.Sequential(*pred_layers)\n",
    "        return pred_model\n",
    "\n",
    "    \"\"\"\n",
    "    For each num_nodes in batch_num_nodes, the first num_nodes entries of the \n",
    "    corresponding column are 1's, and the rest are 0's (to be masked out).\n",
    "    Dimension of mask: [batch_size x max_nodes x 1]\n",
    "    \"\"\"\n",
    "    def construct_mask(self, max_nodes, batch_num_nodes):\n",
    "        # masks\n",
    "        packed_masks = [torch.ones(int(num)) for num in batch_num_nodes]\n",
    "        batch_size = len(batch_num_nodes)\n",
    "        out_tensor = torch.zeros(batch_size, max_nodes)\n",
    "        for i, mask in enumerate(packed_masks):\n",
    "            out_tensor[i, : batch_num_nodes[i]] = mask\n",
    "        return out_tensor.unsqueeze(2).cuda()\n",
    "\n",
    "    \"\"\"\n",
    "    Batch normalization of 3D tensor x\n",
    "    \"\"\"\n",
    "    def apply_bn(self, x):\n",
    "        bn_module = nn.BatchNorm1d(x.size()[1])\n",
    "        if self.gpu:\n",
    "            bn_module = bn_module.cuda()\n",
    "        return bn_module(x)\n",
    "\n",
    "    \"\"\"\n",
    "    Perform forward prop with graph convolution.\n",
    "    Returns:\n",
    "        Embedding matrix with dimension [batch_size x num_nodes x embedding]\n",
    "        The embedding dim is self.pred_input_dim\n",
    "    \"\"\"\n",
    "    def gcn_forward(\n",
    "        self, x, adj, conv_first, conv_block, conv_last, embedding_mask=None\n",
    "    ):\n",
    "\n",
    "        x, adj_att = conv_first(x, adj)\n",
    "        x = self.act(x)\n",
    "        if self.bn:\n",
    "            x = self.apply_bn(x)\n",
    "        x_all = [x]\n",
    "        adj_att_all = [adj_att]\n",
    "        # out_all = []\n",
    "        # out, _ = torch.max(x, dim=1)\n",
    "        # out_all.append(out)\n",
    "        for i in range(len(conv_block)):\n",
    "            x, _ = conv_block[i](x, adj)\n",
    "            x = self.act(x)\n",
    "            if self.bn:\n",
    "                x = self.apply_bn(x)\n",
    "            x_all.append(x)\n",
    "            adj_att_all.append(adj_att)\n",
    "        x, adj_att = conv_last(x, adj)\n",
    "        x_all.append(x)\n",
    "        adj_att_all.append(adj_att)\n",
    "        # x_tensor: [batch_size x num_nodes x embedding]\n",
    "        x_tensor = torch.cat(x_all, dim=2)\n",
    "        if embedding_mask is not None:\n",
    "            x_tensor = x_tensor * embedding_mask\n",
    "        self.embedding_tensor = x_tensor\n",
    "\n",
    "        # adj_att_tensor: [batch_size x num_nodes x num_nodes x num_gc_layers]\n",
    "        adj_att_tensor = torch.stack(adj_att_all, dim=3)\n",
    "        return x_tensor, adj_att_tensor\n",
    "\n",
    "    def forward(self, x, adj, batch_num_nodes=None, **kwargs):\n",
    "        # Embedding mask\n",
    "        max_num_nodes = adj.size()[1]\n",
    "        if batch_num_nodes is not None:\n",
    "            self.embedding_mask = self.construct_mask(max_num_nodes, batch_num_nodes)\n",
    "        else:\n",
    "            self.embedding_mask = None\n",
    "\n",
    "        # Convolution\n",
    "        x, adj_att = self.conv_first(x, adj)\n",
    "        x = self.act(x)\n",
    "        if self.bn:\n",
    "            x = self.apply_bn(x)\n",
    "        out_all = []\n",
    "        out, _ = torch.max(x, dim=1)\n",
    "        out_all.append(out)\n",
    "        adj_att_all = [adj_att]\n",
    "        for i in range(self.num_layers - 2):\n",
    "            x, adj_att = self.conv_block[i](x, adj)\n",
    "            x = self.act(x)\n",
    "            if self.bn:\n",
    "                x = self.apply_bn(x)\n",
    "            out, _ = torch.max(x, dim=1)\n",
    "            out_all.append(out)\n",
    "            if self.num_aggs == 2:\n",
    "                out = torch.sum(x, dim=1)\n",
    "                out_all.append(out)\n",
    "            adj_att_all.append(adj_att)\n",
    "        x, adj_att = self.conv_last(x, adj)\n",
    "        adj_att_all.append(adj_att)\n",
    "        # x = self.act(x)\n",
    "        out, _ = torch.max(x, dim=1)\n",
    "        out_all.append(out)\n",
    "        if self.num_aggs == 2:\n",
    "            out = torch.sum(x, dim=1)\n",
    "            out_all.append(out)\n",
    "        if self.concat:\n",
    "            output = torch.cat(out_all, dim=1)\n",
    "        else:\n",
    "            output = out\n",
    "\n",
    "        # adj_att_tensor: [batch_size x num_nodes x num_nodes x num_gc_layers]\n",
    "        adj_att_tensor = torch.stack(adj_att_all, dim=3)\n",
    "\n",
    "        self.embedding_tensor = output\n",
    "        ypred = self.pred_model(output)\n",
    "        # print(output.size())\n",
    "        return ypred, adj_att_tensor\n",
    "\n",
    "#     def loss(self, pred, label, type=\"softmax\"):\n",
    "#         # softmax + CE\n",
    "#         if type == \"softmax\":\n",
    "#             return F.cross_entropy(pred, label, size_average=True)\n",
    "#         elif type == \"margin\":\n",
    "#             batch_size = pred.size()[0]\n",
    "#             label_onehot = torch.zeros(batch_size, self.label_dim).long().cuda()\n",
    "#             label_onehot.scatter_(1, label.view(-1, 1), 1)\n",
    "#             return torch.nn.MultiLabelMarginLoss()(pred, label_onehot)\n",
    "\n",
    "        # return F.binary_cross_entropy(F.sigmoid(pred[:,0]), label.float())\n",
    "\n",
    "# GCN Encoding of the nodes\n",
    "class GcnEncoderNode(GcnEncoderGraph):    \n",
    "    def __init__(self, input_dim, hidden_dim, embedding_dim, label_dim, num_layers,\n",
    "                 pred_hidden_dims=[], concat=True,\n",
    "                 bn=True, dropout=0.0, args=None,):\n",
    "        super(GcnEncoderNode, self).__init__(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            label_dim,\n",
    "            num_layers,\n",
    "            pred_hidden_dims,\n",
    "            concat,\n",
    "            bn,\n",
    "            dropout,\n",
    "            args=args,\n",
    "        )\n",
    "        \n",
    "        if hasattr(args, \"loss_weight\"):\n",
    "            print(\"Loss weight: \", args.loss_weight)\n",
    "            self.celoss = nn.CrossEntropyLoss(weight=args.loss_weight)\n",
    "        else:\n",
    "            self.celoss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, adj, batch_num_nodes=None, **kwargs):\n",
    "        # Embedding masks\n",
    "        max_num_nodes = adj.size()[1]\n",
    "        if batch_num_nodes is not None:\n",
    "            embedding_mask = self.construct_mask(max_num_nodes, batch_num_nodes)\n",
    "        else:\n",
    "            embedding_mask = None\n",
    "\n",
    "        self.adj_atts = []\n",
    "        self.embedding_tensor, adj_att = self.gcn_forward(\n",
    "            x, adj, self.conv_first, self.conv_block, self.conv_last, embedding_mask\n",
    "        )\n",
    "        pred = self.pred_model(self.embedding_tensor)\n",
    "        return pred, adj_att\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        pred = torch.transpose(pred, 1, 2)\n",
    "        return self.celoss(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate node classifications\n",
    "def evaluate_node(ypred, labels, train_idx, test_idx):\n",
    "    _, pred_labels = torch.max(ypred, 2)\n",
    "    pred_labels = pred_labels.numpy()\n",
    "\n",
    "    pred_train = np.ravel(pred_labels[:, train_idx])\n",
    "    pred_test = np.ravel(pred_labels[:, test_idx])\n",
    "    labels_train = np.ravel(labels[:, train_idx])\n",
    "    labels_test = np.ravel(labels[:, test_idx])\n",
    "\n",
    "    result_train = {\n",
    "        \"prec\": metrics.precision_score(labels_train, pred_train, average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(labels_train, pred_train, average=\"macro\"),\n",
    "        \"acc\": metrics.accuracy_score(labels_train, pred_train),\n",
    "        \"conf_mat\": metrics.confusion_matrix(labels_train, pred_train),\n",
    "    }\n",
    "    result_test = {\n",
    "        \"prec\": metrics.precision_score(labels_test, pred_test, average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(labels_test, pred_test, average=\"macro\"),\n",
    "        \"acc\": metrics.accuracy_score(labels_test, pred_test),\n",
    "        \"conf_mat\": metrics.confusion_matrix(labels_test, pred_test),\n",
    "    }\n",
    "    return result_train, result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train node classifier and save the prediction results\n",
    "def train_node_classifier(G, labels, model, args, writer=None):\n",
    "    # train/test split only for nodes\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    \n",
    "    # Training data with 80% ratio, labels_train.size()\n",
    "    num_train = int(num_nodes * args.train_ratio)\n",
    "    idx = [i for i in range(num_nodes)]\n",
    "\n",
    "    # Shuffle for training\n",
    "    np.random.shuffle(idx)\n",
    "    train_idx = idx[:num_train]\n",
    "    test_idx = idx[num_train:]\n",
    "\n",
    "    # data = gengraph.preprocess_input_graph(G, labels)\n",
    "    data = preprocess_input_graph(G, labels)\n",
    "    labels_train = torch.tensor(data[\"labels\"][:, train_idx], dtype=torch.long)\n",
    "    adj = torch.tensor(data[\"adj\"], dtype=torch.float)\n",
    "    x = torch.tensor(data[\"feat\"], requires_grad=True, dtype=torch.float)\n",
    "\n",
    "    \n",
    "#     scheduler, optimizer = train_utils.build_optimizer(\n",
    "#         args, model.parameters(), weight_decay=args.weight_decay\n",
    "#     )\n",
    "    # list(testModel.parameters()) and list(filter_fn) to show contents\n",
    "    # train_utils.build_optimizer \n",
    "    filter_fn = filter(lambda p : p.requires_grad, model.parameters())\n",
    "\n",
    "    # args.opt == 'adam':\n",
    "    optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=0.0)\n",
    "    scheduler = None\n",
    "\n",
    "    # Sets the module in training mode\n",
    "    model.train()\n",
    "    ypred = None\n",
    "    for epoch in range(args.num_epochs):\n",
    "        begin_time = time.time()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if args.gpu:\n",
    "            ypred, adj_att = model(x.cuda(), adj.cuda())\n",
    "        else:\n",
    "            ypred, adj_att = model(x, adj)\n",
    "        ypred_train = ypred[:, train_idx, :]\n",
    "        if args.gpu:\n",
    "            loss = model.loss(ypred_train, labels_train.cuda())\n",
    "        else:\n",
    "            loss = model.loss(ypred_train, labels_train)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        #for param_group in optimizer.param_groups:\n",
    "        #    print(param_group[\"lr\"])\n",
    "        elapsed = time.time() - begin_time\n",
    "\n",
    "        # Obtain with Confusion matrices for Train and Test results\n",
    "        result_train, result_test = evaluate_node(\n",
    "            ypred.cpu(), data[\"labels\"], train_idx, test_idx\n",
    "        )\n",
    "        \n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"loss/avg_loss\", loss, epoch)\n",
    "            writer.add_scalars(\n",
    "                \"prec\",\n",
    "                {\"train\": result_train[\"prec\"], \"test\": result_test[\"prec\"]},\n",
    "                epoch,\n",
    "            )\n",
    "            writer.add_scalars(\n",
    "                \"recall\",\n",
    "                {\"train\": result_train[\"recall\"], \"test\": result_test[\"recall\"]},\n",
    "                epoch,\n",
    "            )\n",
    "            writer.add_scalars(\n",
    "                \"acc\", {\"train\": result_train[\"acc\"], \"test\": result_test[\"acc\"]}, epoch\n",
    "            )\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\n",
    "                \"epoch: \",\n",
    "                epoch,\n",
    "                \"; loss: \",\n",
    "                loss.item(),\n",
    "                \"; train_acc: \",\n",
    "                result_train[\"acc\"],\n",
    "                \"; test_acc: \",\n",
    "                result_test[\"acc\"],\n",
    "                \"; train_prec: \",\n",
    "                result_train[\"prec\"],\n",
    "                \"; test_prec: \",\n",
    "                result_test[\"prec\"],\n",
    "                \"; epoch time: \",\n",
    "                \"{0:0.2f}\".format(elapsed),\n",
    "            )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    print(\"Confusion Matrix of train result :\\n\", result_train[\"conf_mat\"])\n",
    "    print(\"Confusion Matrix of test result :\\n\", result_test[\"conf_mat\"])\n",
    "\n",
    "    # Sets the module in evaluation mode for computational graph\n",
    "    model.eval()\n",
    "    if args.gpu:\n",
    "        ypred, _ = model(x.cuda(), adj.cuda())\n",
    "    else:\n",
    "        ypred, _ = model(x, adj)\n",
    "\n",
    "    cg_data = {\n",
    "        \"adj\": data[\"adj\"],\n",
    "        \"feat\": data[\"feat\"],\n",
    "        \"label\": data[\"labels\"],\n",
    "        \"pred\": ypred.cpu().detach().numpy(),\n",
    "        \"train_idx\": train_idx,\n",
    "    }\n",
    "    \n",
    "    print(\"Labels of the Computational graph :\\n\", cg_data['label'])\n",
    "    print(\"Prediction result of the Computational graph :\\n\", cg_data['pred'])\n",
    "    print(\"Train index of the Computational graph data :\\n\", cg_data['train_idx'])\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    \n",
    "    #io_utils.save_checkpoint\n",
    "    save_checkpoint(model, optimizer, args, num_epochs=-1, cg_dict=cg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# (1) GcnEncoderNode(GcnEncoderGraph) -> build_conv_layers -> GraphConv\n",
    "# build_conv_layers return conv_first, conv_block, conv_last\n",
    "# (2) GcnEncoderNode(GcnEncoderGraph) -> self.pred_model = self.build_pred_layers\n",
    "# build_pred_layers return pred_model\n",
    "# (3) syn_task1 -> train_node_classifier -> save_checkpoint\n",
    "#####################################################################################\n",
    "# Create the GCN model and encoding the nodes\n",
    "def syn_task1(args, writer=None):\n",
    "    # featgen.ConstFeatureGen\n",
    "    # np.ones(input_dim, dtype=float) = [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]\n",
    "    constant_feature = ConstFeatureGen(np.ones(args.input_dim, dtype=float))\n",
    "    print(\"Constant feature generator : \", constant_feature.val)\n",
    "    \n",
    "    #feat_dict = {i:{'feat': np.array(constant_feature.val, dtype=np.float32)} for i in G.nodes()}\n",
    "    #print ('Values of feat_dict[0][\"feat\"]:', feat_dict[0]['feat'])\n",
    "\n",
    "    #nx.set_node_attributes(G, feat_dict)\n",
    "    #print('Node attributes of node \\'0\\', G.nodes[0][\"feat\"]:', G.nodes[0]['feat'])\n",
    "\n",
    "    # gengraph.gen_syn1\n",
    "    # Create the BA graph with the \"house\" motifs\n",
    "    G, labels, name = gen_syn1(feature_generator=constant_feature)\n",
    "\n",
    "    # No .of classes from [0-3] for BA graph with house motifs\n",
    "    num_classes = max(labels) + 1\n",
    "    # Update number of classes in argument for training (Out of bounds error)\n",
    "    args.num_classes = num_classes\n",
    "    \n",
    "    # GcnEncoderNode model\n",
    "    print(\"------------ GCNEncoderNode Model ------------\")\n",
    "    print(\"Input dimensions :\", args.input_dim)\n",
    "    print(\"Hidden dimensions :\", args.hidden_dim)\n",
    "    print(\"Output dimensions :\", args.output_dim)\n",
    "    print(\"Number of classes in args :\", args.num_classes)\n",
    "    print(\"Number of GCN layers :\", args.num_gc_layers)\n",
    "    print(\"Method : \", args.method)\n",
    "\n",
    "    model = GcnEncoderNode(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                           args.num_classes, args.num_gc_layers, bn=args.bn, args=args)\n",
    "    \n",
    "    print(\"GcnEncoderNode model :\\n\", model)\n",
    "    \n",
    "\n",
    "#     if args.method == \"att\":\n",
    "#         print(\"Method: att\")\n",
    "#         model = models.GcnEncoderNode(\n",
    "#             args.input_dim,\n",
    "#             args.hidden_dim,\n",
    "#             args.output_dim,\n",
    "#             num_classes,\n",
    "#             args.num_gc_layers,\n",
    "#             bn=args.bn,\n",
    "#             args=args,\n",
    "#         )\n",
    "#     else:\n",
    "#         print(\"Method:\", args.method)\n",
    "#         model = models.GcnEncoderNode(\n",
    "#             args.input_dim,\n",
    "#             args.hidden_dim,\n",
    "#             args.output_dim,\n",
    "#             num_classes,\n",
    "#             args.num_gc_layers,\n",
    "#             bn=args.bn,\n",
    "#             args=args,\n",
    "#         )\n",
    "    if args.gpu:\n",
    "        model = model.cuda()\n",
    "\n",
    "    #train_node_classifier(G, labels, model, args, writer=writer)\n",
    "    \n",
    "    # To be removed after testing\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "# Call flow 1 : syn_task1 -> gen_syn1 -> build_graph -> ba\n",
    "# Call flow 2 : syn_task1 -> GcnEncoderNode, train_node_classifier -> preprocess_input_graph\n",
    "model = syn_task1(prog_args, writer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for PyTorch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn-model-explainer/utils/io_utils.py\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda\n",
    "#prog_args.bn\n",
    "# Use `zero_division` parameter to control this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "## transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "## download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "## download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "#print(len(trainset))\n",
    "#print(trainset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 28x28x1 => 26x26x32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
    "        self.d2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # flatten => 32 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        #x = x.view(32, -1)\n",
    "\n",
    "        # 32 x (32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.ones((2,2))\n",
    "\n",
    "ta = torch.tensor(a, dtype=float).to('cuda:0')\n",
    "tb = torch.ones(2,2, dtype=float).to('cuda:0')\n",
    "\n",
    "print(ta)\n",
    "print(tb)\n",
    "print(ta @ tb) # dot product; element-wise product\n",
    "\n",
    "# This takes awhile for CUDA configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Current device : \", device)\n",
    "\n",
    "model = MyModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    ## training step\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ## forward + backprop + loss\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ## update model params\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += (torch.argmax(logits, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "    \n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "          %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += (torch.argmax(outputs, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "    preds = torch.argmax(outputs, 1).flatten().cpu().numpy()\n",
    "        \n",
    "print('Test Accuracy: %.2f'%(test_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, task='node'):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.task = task\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
    "        self.lns = nn.ModuleList()\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        for l in range(2):\n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        if not (self.task == 'node' or self.task == 'graph'):\n",
    "            raise RuntimeError('Unknown task.')\n",
    "\n",
    "        self.dropout = 0.25\n",
    "        self.num_layers = 3\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        if self.task == 'node':\n",
    "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        else:\n",
    "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                                  nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if data.num_node_features == 0:\n",
    "          x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            if not i == self.num_layers - 1:\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        if self.task == 'graph':\n",
    "            x = pyg_nn.global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        return emb, F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.lin_self = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Removes every self-loop in the graph given by edge_index\n",
    "        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n",
    "\n",
    "        # Transform node feature matrix.\n",
    "        self_x = self.lin_self(x)\n",
    "        #x = self.lin(x)\n",
    "\n",
    "        return self_x + self.propagate(edge_index, size=(x.size(0), x.size(0)), x=self.lin(x))\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index, size):\n",
    "        # Compute messages\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, task, writer):\n",
    "    if task == 'graph':\n",
    "        data_size = len(dataset)\n",
    "        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size=64, shuffle=True)\n",
    "        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size=64, shuffle=True)\n",
    "    else:\n",
    "        test_loader = loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes, task=task)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # train\n",
    "    for epoch in range(200):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            #print(batch.train_mask, '----')\n",
    "            opt.zero_grad()\n",
    "            embedding, pred = model(batch)\n",
    "            label = batch.y\n",
    "            if task == 'node':\n",
    "                pred = pred[batch.train_mask]\n",
    "                label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
    "                epoch, total_loss, test_acc))\n",
    "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, is_validation=False):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "\n",
    "        if model.task == 'node':\n",
    "            mask = data.val_mask if is_validation else data.test_mask\n",
    "            # node classification: only evaluate on nodes in test set\n",
    "            pred = pred[mask]\n",
    "            label = data.y[mask]\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "    \n",
    "    if model.task == 'graph':\n",
    "        total = len(loader.dataset) \n",
    "    else:\n",
    "        total = 0\n",
    "        for data in loader.dataset:\n",
    "            total += torch.sum(data.test_mask).item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip3 install tensorboardX\n",
    "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "#!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().system_raw(\n",
    "#    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "#    .format(\"./log\")\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().system_raw('./ngrok http 6006 &')\n",
    "#!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "#    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset = dataset.shuffle()\n",
    "task = 'graph'\n",
    "\n",
    "print(\"Dataset :\", dataset)\n",
    "print(\"Length of dataset :\", len(dataset))\n",
    "print(\"Number of classes in dataset :\", dataset.num_classes)\n",
    "print(\"Number of node featues in dataset :\", dataset.num_node_features)\n",
    "\n",
    "# Have access to all 600 graphs in the datase\n",
    "data = dataset[0]\n",
    "print(\"\\nDataset :\", data)\n",
    "print(\"\\nIs the graph undirected :\", data.is_undirected())\n",
    "\n",
    "# Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
    "# Data(edge_index=[2, 44], x=[12, 3], y=[1])\n",
    "# The first graph in the dataset contains 12 nodes, each one having 3 features.\n",
    "# There are 44/2 = 22 undirected edges and the graph is assigned to exactly one class.\n",
    "# In addition, the data object is holding exactly one graph-level target.\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]\n",
    "print(\"Accessing dataset [0-539] for training :\", train_dataset)\n",
    "print(\"Accessing dataset [540-599] for testing :\", test_dataset)\n",
    "\n",
    "dataset = dataset.shuffle()\n",
    "# Equivalent of the following\n",
    "# perm = torch.randperm(len(dataset))\n",
    "# dataset = dataset[perm]\n",
    "print(\"Shuffle dataset :\", dataset)\n",
    "\n",
    "# Train model\n",
    "print(\"\\n----------- Model Training -----------\")\n",
    "model = train(dataset, task, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "count = 1\n",
    "total_graphs = 0\n",
    "for data in loader:\n",
    "    # User batch to average node features in the node dimension for each graph individually\n",
    "    x = scatter_mean(data.x, data.batch, dim=0)\n",
    "    \n",
    "    if count == 1:\n",
    "        print(\"------------------------------ No. : \" + str(count) + \" ------------------------------\")\n",
    "        print(\"Batch :\\n\", data)\n",
    "        print(\"No. of batch graphs :\", data.num_graphs)\n",
    "        print(\"Size of mean x in batch :\\n\", x.size())  \n",
    "    count += 1\n",
    "    total_graphs += data.num_graphs\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Total no. of graphs in dataset :\", total_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch is a column vector which maps each node to its respective graph in the batch:\n",
    "data.to_data_list()[0] # ['edge_index'] gives the mapping of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = Planetoid(root='/tmp/cora', name='cora')\n",
    "task = 'node'\n",
    "\n",
    "print(\"Dataset :\\n\", dataset)\n",
    "print(\"Length of dataset :\", len(dataset))\n",
    "print(\"Number of classes in dataset :\", dataset.num_classes)\n",
    "print(\"Number of node featues in dataset :\", dataset.num_node_features)\n",
    "\n",
    "# Get a single, undirected citation graph from dataset\n",
    "data = dataset[0]\n",
    "print(\"\\nDataset :\\n\", data)\n",
    "print(\"Is single citation graph undirected :\", data.is_undirected())\n",
    "\n",
    "# data object holds a label for each node, and additional attributes :\n",
    "# train_mask denotes against which nodes to train (140 nodes)\n",
    "print(\"Number of items in train mask :\", data.train_mask.sum().item())\n",
    "# val_mask denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes)\n",
    "print(\"Number of items in val mask :\", data.val_mask.sum().item())\n",
    "# test_mask denotes against which nodes to test (1000 nodes)\n",
    "print(\"Number of items in test mask :\", data.test_mask.sum().item())\n",
    "\n",
    "# Train model\n",
    "print(\"\\n----------- Model Training -----------\")\n",
    "model = train(dataset, task, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"red\", \"orange\", \"green\", \"blue\", \"purple\", \"brown\",\n",
    "              \"black\", \"yellow\", \"grey\", \"cyan\", \"pink\", \"magenta\"]\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "embs = []\n",
    "colors = []\n",
    "for batch in loader:\n",
    "    emb, pred = model(batch)\n",
    "    embs.append(emb)\n",
    "    colors += [color_list[y] for y in batch.y]\n",
    "embs = torch.cat(embs, dim=0)\n",
    "\n",
    "xs, ys = zip(*TSNE().fit_transform(embs.detach().numpy()))\n",
    "\n",
    "plt.figure(figsize=(24, 20))\n",
    "plt.scatter(xs, ys, color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph methods\n",
    "-  Graph Neural Network (GCN) <br>\n",
    "(http://tkipf.github.io/graph-convolutional-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_node_features, dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# A two-layer GCN\n",
    "# Non-linearity is not integrated in the conv calls and hence needs to be applied afterwards\n",
    "# Use ReLU as our intermediate non-linearity between and finally output a softmax distribution\n",
    "# over the number of classes\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Net().to(device)\n",
    "print(\"Current device : \", device)\n",
    "\n",
    "# Get a single, undirected citation graph from dataset\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Explainer (pytorch_geometric/examples/gnn_explainer.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from pytorch_geometric/torch_geometric/nn/models/gnn_explainer.py\n",
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "class GNNExplainer(torch.nn.Module):\n",
    "    r\"\"\"The GNN-Explainer model from the `\"GNNExplainer: Generating\n",
    "    Explanations for Graph Neural Networks\"\n",
    "    <https://arxiv.org/abs/1903.03894>`_ paper for identifying compact subgraph\n",
    "    structures and small subsets node features that play a crucial role in a\n",
    "    GNN’s node-predictions.\n",
    "    .. note::\n",
    "        For an example of using GNN-Explainer, see `examples/gnn_explainer.py\n",
    "        <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/\n",
    "        gnn_explainer.py>`_.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The GNN module to explain.\n",
    "        epochs (int, optional): The number of epochs to train.\n",
    "            (default: :obj:`100`)\n",
    "        lr (float, optional): The learning rate to apply.\n",
    "            (default: :obj:`0.01`)\n",
    "        log (bool, optional): If set to :obj:`False`, will not log any learning\n",
    "            progress. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    coeffs = {\n",
    "        'edge_size': 0.005,\n",
    "        'node_feat_size': 1.0,\n",
    "        'edge_ent': 1.0,\n",
    "        'node_feat_ent': 0.1,\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, epochs=100, lr=0.01, log=True):\n",
    "        super(GNNExplainer, self).__init__()\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.log = log\n",
    "\n",
    "    def __set_masks__(self, x, edge_index, init=\"normal\"):\n",
    "        (N, F), E = x.size(), edge_index.size(1)\n",
    "\n",
    "        std = 0.1\n",
    "        self.node_feat_mask = torch.nn.Parameter(torch.randn(F) * 0.1)\n",
    "\n",
    "        std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "        self.edge_mask = torch.nn.Parameter(torch.randn(E) * std)\n",
    "\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "\n",
    "    def __clear_masks__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.node_feat_masks = None\n",
    "        self.edge_mask = None\n",
    "\n",
    "    def __num_hops__(self):\n",
    "        num_hops = 0\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                num_hops += 1\n",
    "        return num_hops\n",
    "\n",
    "    def __flow__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def __subgraph__(self, node_idx, x, edge_index, **kwargs):\n",
    "        num_nodes, num_edges = x.size(0), edge_index.size(1)\n",
    "\n",
    "        subset, edge_index, edge_mask = k_hop_subgraph(\n",
    "            node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,\n",
    "            num_nodes=num_nodes, flow=self.__flow__())\n",
    "\n",
    "        x = x[subset]\n",
    "        for key, item in kwargs:\n",
    "            if torch.is_tensor(item) and item.size(0) == num_nodes:\n",
    "                item = item[subset]\n",
    "            elif torch.is_tensor(item) and item.size(0) == num_edges:\n",
    "                item = item[edge_mask]\n",
    "            kwargs[key] = item\n",
    "\n",
    "        return x, edge_index, edge_mask, kwargs\n",
    "\n",
    "    def __loss__(self, node_idx, log_logits, pred_label):\n",
    "        loss = -log_logits[node_idx, pred_label[node_idx]]\n",
    "\n",
    "        m = self.edge_mask.sigmoid()\n",
    "        loss = loss + self.coeffs['edge_size'] * m.sum()\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['edge_ent'] * ent.mean()\n",
    "\n",
    "        m = self.node_feat_mask.sigmoid()\n",
    "        loss = loss + self.coeffs['node_feat_size'] * m.sum()\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['node_feat_ent'] * ent.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def explain_node(self, node_idx, x, edge_index, **kwargs):\n",
    "        r\"\"\"Learns and returns a node feature mask and an edge mask that play a\n",
    "        crucial role to explain the prediction made by the GNN for node\n",
    "        :attr:`node_idx`.\n",
    "        Args:\n",
    "            node_idx (int): The node to explain.\n",
    "            x (Tensor): The node feature matrix.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            **kwargs (optional): Additional arguments passed to the GNN module.\n",
    "        :rtype: (:class:`Tensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        num_edges = edge_index.size(1)\n",
    "\n",
    "        # Only operate on a k-hop subgraph around `node_idx`.\n",
    "        x, edge_index, hard_edge_mask, kwargs = self.__subgraph__(\n",
    "            node_idx, x, edge_index, **kwargs)\n",
    "\n",
    "        # Get the initial prediction.\n",
    "        with torch.no_grad():\n",
    "            log_logits = self.model(x=x, edge_index=edge_index, **kwargs)\n",
    "            pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index)\n",
    "        self.to(x.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam([self.node_feat_mask, self.edge_mask],\n",
    "                                     lr=self.lr)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description(f'Explain node {node_idx}')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.view(1, -1).sigmoid()\n",
    "            log_logits = self.model(x=h, edge_index=edge_index, **kwargs)\n",
    "            loss = self.__loss__(0, log_logits, pred_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if self.log:  # pragma: no cover\n",
    "                pbar.update(1)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar.close()\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid()\n",
    "        edge_mask = self.edge_mask.new_zeros(num_edges)\n",
    "        edge_mask[hard_edge_mask] = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        return node_feat_mask, edge_mask\n",
    "\n",
    "    def visualize_subgraph(self, node_idx, edge_index, edge_mask, y=None,\n",
    "                           threshold=None, **kwargs):\n",
    "        r\"\"\"Visualizes the subgraph around :attr:`node_idx` given an edge mask\n",
    "        :attr:`edge_mask`.\n",
    "        Args:\n",
    "            node_idx (int): The node id to explain.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            edge_mask (Tensor): The edge mask.\n",
    "            y (Tensor, optional): The ground-truth node-prediction labels used\n",
    "                as node colorings. (default: :obj:`None`)\n",
    "            threshold (float, optional): Sets a threshold for visualizing\n",
    "                important edges. If set to :obj:`None`, will visualize all\n",
    "                edges with transparancy indicating the importance of edges.\n",
    "                (default: :obj:`None`)\n",
    "            **kwargs (optional): Additional arguments passed to\n",
    "                :func:`nx.draw`.\n",
    "        :rtype: :class:`matplotlib.pyplot`\n",
    "        \"\"\"\n",
    "\n",
    "        assert edge_mask.size(0) == edge_index.size(1)\n",
    "\n",
    "        # Only operate on a k-hop subgraph around `node_idx`.\n",
    "        subset, edge_index, hard_edge_mask = k_hop_subgraph(\n",
    "            node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,\n",
    "            num_nodes=None, flow=self.__flow__())\n",
    "\n",
    "        edge_mask = edge_mask[hard_edge_mask]\n",
    "\n",
    "        if threshold is not None:\n",
    "            edge_mask = (edge_mask >= threshold).to(torch.float)\n",
    "\n",
    "        if y is None:\n",
    "            y = torch.zeros(edge_index.max().item() + 1,\n",
    "                            device=edge_index.device)\n",
    "        else:\n",
    "            y = y[subset].to(torch.float) / y.max().item()\n",
    "\n",
    "        data = Data(edge_index=edge_index, att=edge_mask, y=y,\n",
    "                    num_nodes=y.size(0)).to('cpu')\n",
    "        G = to_networkx(data, node_attrs=['y'], edge_attrs=['att'])\n",
    "        mapping = {k: i for k, i in enumerate(subset.tolist())}\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        kwargs['with_labels'] = kwargs.get('with_labels') or True\n",
    "        kwargs['font_size'] = kwargs.get('font_size') or 10\n",
    "        kwargs['node_size'] = kwargs.get('node_size') or 800\n",
    "        kwargs['cmap'] = kwargs.get('cmap') or 'cool'\n",
    "\n",
    "        pos = nx.spring_layout(G)\n",
    "        ax = plt.gca()\n",
    "        for source, target, data in G.edges(data=True):\n",
    "            ax.annotate(\n",
    "                '', xy=pos[target], xycoords='data', xytext=pos[source],\n",
    "                textcoords='data', arrowprops=dict(\n",
    "                    arrowstyle=\"->\",\n",
    "                    alpha=max(data['att'], 0.1),\n",
    "                    shrinkA=sqrt(kwargs['node_size']) / 2.0,\n",
    "                    shrinkB=sqrt(kwargs['node_size']) / 2.0,\n",
    "                    connectionstyle=\"arc3,rad=0.1\",\n",
    "                ))\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=y.tolist(), **kwargs)\n",
    "        nx.draw_networkx_labels(G, pos, **kwargs)\n",
    "        plt.axis('off')\n",
    "        return plt\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from pytorch_geometric/torch_geometric/utils/subgraph.py\n",
    "def maybe_num_nodes(index, num_nodes=None):\n",
    "    return index.max().item() + 1 if num_nodes is None else num_nodes\n",
    "\n",
    "def k_hop_subgraph(node_idx, num_hops, edge_index, relabel_nodes=False,\n",
    "                   num_nodes=None, flow='source_to_target'):\n",
    "    r\"\"\"Computes the :math:`k`-hop subgraph of :obj:`edge_index` around node\n",
    "    :attr:`node_idx`.\n",
    "    It returns (1) the nodes involved in the subgraph, (2) the filtered\n",
    "    :obj`edge_index` connectivity, and (3) the edge mask indicating which edges\n",
    "    were preserved.\n",
    "    Args:\n",
    "        node_idx (int): The central node.\n",
    "        num_hops: (int): The number of hops :math:`k`.\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting\n",
    "            :obj:`edge_index` will be relabeled to hold consecutive indices\n",
    "            starting from zero. (default: :obj:`False`)\n",
    "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
    "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
    "        flow (string, optional): The flow direction of :math:`k`-hop\n",
    "            aggregation (:obj:`\"source_to_target\"` or\n",
    "            :obj:`\"target_to_source\"`). (default: :obj:`\"source_to_target\"`)\n",
    "    :rtype: (:class:`LongTensor`, :class:`LongTensor`, :class:`BoolTensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    subsets = [torch.tensor([node_idx], device=row.device).flatten()]\n",
    "    for _ in range(num_hops):\n",
    "        node_mask.fill_(False)\n",
    "        node_mask[subsets[-1]] = True\n",
    "        torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "        subsets.append(col[edge_mask])\n",
    "    subset = torch.cat(subsets).unique()\n",
    "    # Add `node_idx` to the beginning of `subset`.\n",
    "    subset = subset[subset != node_idx]\n",
    "    subset = torch.cat([torch.tensor([node_idx], device=row.device), subset])\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes, ), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Sequential, Linear\n",
    "\n",
    "dataset = 'Cora'\n",
    "path = '/tmp/cora'\n",
    "\n",
    "dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "\n",
    "# Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n",
    "data = dataset[0]\n",
    "print(\"Data before sent to device :\\n\", data)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin = Sequential(Linear(10, 10))\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device : \", device)\n",
    "\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "print(\"Data to device :\\n\", data)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "x, edge_index = data.x, data.edge_index\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    log_logits = model(x, edge_index)\n",
    "    loss = F.nll_loss(log_logits[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "explainer = GNNExplainer(model, epochs=200)\n",
    "node_idx = 10\n",
    "node_feat_mask, edge_mask = explainer.explain_node(node_idx, x, edge_index)\n",
    "plt = explainer.visualize_subgraph(node_idx, edge_index, edge_mask, y=data.y)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder for unsupervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = pyg_nn.GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "def unsupervised_train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    writer.add_scalar(\"loss\", loss.item(), epoch)\n",
    "\n",
    "def unsupervised_test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = Planetoid(\"/tmp/citeseer\", \"Citeseer\", T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "channels = 16\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA availability:', torch.cuda.is_available())\n",
    "\n",
    "# encoder: written by us; decoder: default (inner product)\n",
    "model = pyg_nn.GAE(Encoder(dataset.num_features, channels)).to(dev)\n",
    "labels = data.y\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "\n",
    "#data = model.split_edges(data)\n",
    "data = pyg_utils.train_test_split_edges(data)\n",
    "\n",
    "x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    unsupervised_train(epoch)\n",
    "    auc, ap = unsupervised_test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    writer.add_scalar(\"AUC\", auc, epoch)\n",
    "    writer.add_scalar(\"AP\", ap, epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z = model.encode(x, train_pos_edge_index)\n",
    "colors = [color_list[y] for y in labels]\n",
    "\n",
    "xs, ys = zip(*TSNE().fit_transform(z.cpu().detach().numpy()))\n",
    "\n",
    "plt.figure(figsize=(24, 20))\n",
    "plt.scatter(xs, ys, color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
