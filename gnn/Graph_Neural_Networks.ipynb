{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup in GCP\n",
    "- apt-get --purge remove \"cublas\" \"cuda*\"\n",
    "- reboot\n",
    "- sudo curl -O http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
    "- sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
    "- sudo apt-get install cuda-10-1\n",
    "- pip3 install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-geometric\n",
    "\n",
    "** Both the PyTorch and torch_sparse CUDA version must matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import torch; print(torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.243\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# This notebook works with Pytorch geometric GNNExplainer for explaining node predictions\n",
    "# of Cora dataset and/or BA Graph with house motifs\n",
    "# Created by : Au Jit Seah\n",
    "# File owners : Au Jit Seah\n",
    "##########################################################################################\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all required arguments\n",
    "class gnn_args:\n",
    "    def __init__(self):\n",
    "        self.datadir = \"data\"        # Directory where benchmark is stored (io_parser)\n",
    "        self.logdir = \"log\"          # Tensorboard log directory\n",
    "        self.ckptdir = \"ckpt\"        # Model checkpoint directory\n",
    "        self.dataset = \"BAGraph\"     # Synthetic dataset, syn1\n",
    "        self.opt = \"adam\"            # opt_parser\n",
    "        self.opt_scheduler = \"none\"  # Optimizer scheduler\n",
    "        self.max_nodes = 100         # Maximum number of nodes\n",
    "                                     # (ignore graphs with nodes exceeding the number)\n",
    "        self.cuda = \"0\"              # CUDA value\n",
    "        self.feature_type = \"default\"# Feature used for encoder with possible values : id, deg\n",
    "        self.lr = 0.001              # Learning rate\n",
    "        self.clip = 2.0\n",
    "        \n",
    "        self.batch_size = 20         # Batch size\n",
    "        self.num_epochs = 1000       # Number of epochs to train data\n",
    "        self.train_ratio = 0.8       # Ratio of number of training set to all graphs\n",
    "        self.test_ratio = 0.1\n",
    "        self.num_workers = 1         # Number of workers to load data\n",
    "        self.input_dim = 10          # Input feature dimension\n",
    "        self.hidden_dim = 20         # Hidden layer dimension\n",
    "        self.output_dim = 20         # Output layer dimension\n",
    "        self.num_classes = 2         # Number of label classes\n",
    "        self.num_gc_layers = 3       # Number of graph convolution layers before each pooling\n",
    "        \n",
    "        self.dropout = 0.0           # Dropout rate\n",
    "        self.weight_decay = 0.005    # Weight decay regularization constant\n",
    "        self.method = \"base\"         # Method used with possible values : base\n",
    "        self.name_suffix = \"\"        # Suffix added to the output filename\n",
    "        self.assign_ratio = 0.1      # Ratio of number of nodes in consecutive layers\n",
    "        \n",
    "        self.bias = True             # \"Whether to add bias\n",
    "        \n",
    "        self.gpu = False             # Whether to use GPU\n",
    "        self.linkpred = False        # Whether link prediction side objective is used\n",
    "        self.bn = False              # Whether batch normalization is used\n",
    "        self.bmname = None           # Name of the benchmark datase\n",
    "\n",
    "prog_args = gnn_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic graphs for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the BA-shape with house motifs and setting roles that will be used as labels\n",
    "\"\"\"\n",
    "Builds a BA preferential attachment graph, with \"node index\" starting from \"start\"\n",
    "parameter and \"role_ids\" from \"role_start\" parameter\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "start       :    starting index of the shape\n",
    "width       :    int size of the graph (no. of nodes)\n",
    "role_start  :    starting index for the roles\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "graph       :    a ba graph, with ids beginning from start\n",
    "roles       :    list of the roles of the nodes (indexed starting from\n",
    "                 role_start) that will be used as labels\n",
    "\"\"\"\n",
    "def ba(start, width, role_start=0, m=5):\n",
    "    graph = nx.barabasi_albert_graph(width, m)\n",
    "    graph.add_nodes_from(range(start, start + width))\n",
    "    nids = sorted(graph)\n",
    "    mapping = {nid: start + i for i, nid in enumerate(nids)}\n",
    "    graph = nx.relabel_nodes(graph, mapping)\n",
    "    roles = [role_start for i in range(width)]\n",
    "    return graph, roles\n",
    "\n",
    "\"\"\"\n",
    "Builds a house-like graph/motif, with \"node index\" starting from \"start\"\n",
    "parameter and \"role_ids\" from \"role_start\" parameter\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "start       :    starting index for the shape\n",
    "role_start  :    starting index for the roles\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "graph       :    a house-like graph/motif, with ids beginning from start\n",
    "roles       :    list of the roles of the nodes (indexed starting at\n",
    "                 role_start) that will be used as labels\n",
    "\"\"\"\n",
    "def house(start, role_start=0):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(start, start + 5))\n",
    "    graph.add_edges_from(\n",
    "        [\n",
    "            (start, start + 1),\n",
    "            (start + 1, start + 2),\n",
    "            (start + 2, start + 3),\n",
    "            (start + 3, start),\n",
    "        ]\n",
    "    )\n",
    "    # graph.add_edges_from([(start, start + 2), (start + 1, start + 3)])\n",
    "    graph.add_edges_from([(start + 4, start), (start + 4, start + 1)])\n",
    "    roles = [role_start, role_start, role_start + 1, role_start + 1, role_start + 2]\n",
    "    return graph, roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a basis graph and attaches elements of the type in the list randomly along the basis.\n",
    "Possibility to add random edges afterwards.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "width_basis       :      width (in terms of number of nodes) of the basis\n",
    "basis_type        :      \"ba\"\n",
    "shapes            :      list of shape list\n",
    "                         (1st arg  : type of shape,\n",
    "                         next args : args for building the shape except for the start)\n",
    "start             :      initial node label for the first node\n",
    "rdm_basis_plugins :      Boolean\n",
    "                         For the shapes to be attached randomly (True) or\n",
    "                         regularly (False) to the basis graph\n",
    "add_random_edges  :      no. of edges to randomly add on the structure\n",
    "m                 :      no. of new edges to attach to existing node (for BA graph)\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "basis             :      a networkx graph with the particular shape used as the base\n",
    "role_id           :      label for each role (eg. representing basis or edges)\n",
    "plugins           :      node ids whereby the motif graph will be attached to the basis\n",
    "\"\"\"\n",
    "# Eg. build_graph(20, \"ba\", [[\"house\"]], start=0, m=5)\n",
    "def build_graph(width_basis, basis_type, list_shapes, start=0,\n",
    "                rdm_basis_plugins=False,add_random_edges=0, m=5):\n",
    "    print(\"------ Building the Synthetic BA graph with 'House' motifs ------\")\n",
    "    # Build the BA graph start with 0 and number of nodes (width basis)\n",
    "    if basis_type == \"ba\":\n",
    "        # Drawing of a house motif\n",
    "        basis, role_id = eval(basis_type)(start, width_basis, m=m)\n",
    "        print(\"Role Id of the BA graph :\\n\", role_id)\n",
    "#     else:\n",
    "#         # Drawing other type of motif\n",
    "#         basis, role_id = eval(basis_type)(start, width_basis)\n",
    "\n",
    "    n_basis, n_shapes = nx.number_of_nodes(basis), len(list_shapes)\n",
    "    start += n_basis  # indicator of the id of the next node\n",
    "    print(\"Indicator of the id of the next node :\", start)\n",
    "    \n",
    "    # role_id are '0's for all the nodes of the basis, BA graph\n",
    "    print(\"Number of nodes in the BA graph : \", n_basis)\n",
    "    print(\"Number of motifs : \", n_shapes)\n",
    "\n",
    "    print(\"List of shapes :\", list_shapes)\n",
    "    print(\"No. of shapes :\", len(list_shapes))\n",
    "\n",
    "    # Sample (with replacement) where to attach the new motifs\n",
    "    if rdm_basis_plugins is True:\n",
    "        plugins = np.random.choice(n_basis, n_shapes, replace=False)\n",
    "    else:\n",
    "        spacing = math.floor(n_basis / n_shapes)\n",
    "        print(\"Spacing : \", spacing)\n",
    "        plugins = [int(k * spacing) for k in range(n_shapes)]\n",
    "        print(\"Plugins : \", plugins)\n",
    "    seen_shapes = {\"basis\": [0, n_basis]}\n",
    "    print(\"seen_shapes : \", seen_shapes)\n",
    "    \n",
    "    for shape_index, shape in enumerate(list_shapes):\n",
    "        shape_type = shape[0]\n",
    "        print(\"\\n-----------------------------------------\")\n",
    "        print(\"Shape_ID : \" + str(shape_index) + \" with shape type : \" + str(shape_type))\n",
    "        print(str(len(shape)) + \" shapes with list of Shape :\", shape)\n",
    "        print(\"The shape starts from index 1 : \", shape[1:])\n",
    "        \n",
    "        args = [start]\n",
    "        \n",
    "        # More than one shape\n",
    "        if len(shape) > 1:\n",
    "            args += shape[1:]\n",
    "        \n",
    "        # Append 0 for the \"role_start\" in \"house\" function\n",
    "        args += [0]\n",
    "        print(\"\\nThe list of arguments :\", args)\n",
    "        # *args parameter to send a non-keyworded variable-length argument list to function, 1-2 parameters in this case\n",
    "        print(\"The first item in list of arguments :\", args[0])\n",
    "        print(\"The second item in list of arguments :\", args[1])\n",
    "        \n",
    "        # Creating the \"house\" motif\n",
    "        graph_s, roles_graph_s = eval(shape_type)(*args)\n",
    "        n_s = nx.number_of_nodes(graph_s)\n",
    "        \n",
    "        try:\n",
    "             # Get the last seen label from first index\n",
    "            col_start = seen_shapes[shape_type][0]\n",
    "        except:\n",
    "            # Get the max label value 1\n",
    "            col_start = np.max(role_id) + 1\n",
    "            # Add the new shape_type to the seen_shapes dictionary\n",
    "            seen_shapes[shape_type] = [col_start, n_s]\n",
    "        print(\"Column start :\", col_start)\n",
    "        print(\"Observe seen_shapes : \", seen_shapes)\n",
    "        \n",
    "        \n",
    "        # Attach the shape to the basis, BA graph\n",
    "        basis.add_nodes_from(graph_s.nodes())\n",
    "        basis.add_edges_from(graph_s.edges())\n",
    "        # Connecting the motif to the BA graph from node 20 to 0, 25 to 6 and 30 to 12\n",
    "        basis.add_edges_from([(start, plugins[shape_index])])\n",
    "#         if shape_type == \"cycle\":\n",
    "#             if np.random.random() > 0.5:\n",
    "#                 a = np.random.randint(1, 4)\n",
    "#                 b = np.random.randint(1, 4)\n",
    "#                 basis.add_edges_from([(a + start, b + plugins[shape_id])])\n",
    "\n",
    "        # start = 0; col_start = 1; roles_graph_s = [0, 0, 1, 1, 2]\n",
    "        temp_labels = [r + col_start for r in roles_graph_s]\n",
    "        # temp_labels increment roles_graph_s by col_start\n",
    "\n",
    "        # temp_labels[0] += 100 * seen_shapes[shape_type][0]\n",
    "        \n",
    "        # role_id is [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        # Append labels of motif to the labels of BA graph\n",
    "        role_id += temp_labels\n",
    "        print(\"Labels of BA graph with attached motifs :\\n\", role_id)\n",
    "        print(\"No. of nodes in attached graph : \", nx.number_of_nodes(basis))\n",
    "        start += n_s\n",
    "        print(\"With attached motif nodes, index starts from : \", start)\n",
    "\n",
    "#     if add_random_edges > 0:\n",
    "#         # add random edges between nodes:\n",
    "#         for p in range(add_random_edges):\n",
    "#             src, dest = np.random.choice(nx.number_of_nodes(basis), 2, replace=False)\n",
    "#             print(src, dest)\n",
    "#             basis.add_edges_from([(src, dest)])\n",
    "\n",
    "    # Plotting the basis \"BA\" graph\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.title('BA graph'.upper(), y=1.0, fontsize=14)\n",
    "    nx.draw(basis, with_labels=True, font_weight='bold')\n",
    "\n",
    "    # Plot the motif \"house\" graph\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.title('\"House\" motif', y=1.0, fontsize=12)\n",
    "    nx.draw(graph_s, with_labels=True, font_weight='bold')\n",
    "    print(\"\\nInformation of the motif graph :\\n\", nx.info(graph_s))\n",
    "    \n",
    "    plt.show()\n",
    "            \n",
    "    return basis, role_id, plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating node features\n",
    "import abc\n",
    "\n",
    "class FeatureGen(metaclass=abc.ABCMeta):\n",
    "    # Feature Generator base class from Abstract Base Classes\n",
    "    @abc.abstractmethod\n",
    "    def gen_node_features(self, G):\n",
    "        pass\n",
    "\n",
    "class ConstFeatureGen(FeatureGen):\n",
    "    # Generate constant node features in class\n",
    "    def __init__(self, val):\n",
    "        print(\"Values in Constant Feature Generator : \", val)\n",
    "        self.val = val\n",
    "\n",
    "    def gen_node_features(self, G):\n",
    "        print(\"Generate node features for \" + str(len(G.nodes())) + \" nodes.\")\n",
    "        feat_dict = {i:{'feat': np.array(self.val, dtype=np.float32)} for i in G.nodes()}\n",
    "        print('Values of feat_dict[0][\"feat\"]:', feat_dict[0]['feat'])\n",
    "        \n",
    "        # Set node attributes with values in feature dictionary of values '1's\n",
    "        nx.set_node_attributes(G, feat_dict)\n",
    "        print('Node attributes of node \\'0\\', G.nodes[0][\"feat\"]:', G.nodes[0]['feat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic BA graph with \"house\" motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up graph and create its adjacency matrix\n",
    "\"\"\"\n",
    "Perturb the list of (sparse) graphs by adding/removing edges.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "graph_list           :      the list of graphs to be perturbed\n",
    "p                    :      proportion of added edges based on current number of edges.\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "perturbed_graph_list :      the list of graphs that are perturbed from the original graphs.\n",
    "\"\"\"\n",
    "def perturb(graph_list, p):\n",
    "    perturbed_graph_list = []\n",
    "    for G_original in graph_list:\n",
    "        G = G_original.copy()\n",
    "        edge_count = int(G.number_of_edges() * p)\n",
    "        # randomly add the edges between a pair of nodes without an edge.\n",
    "        for _ in range(edge_count):\n",
    "            while True:\n",
    "                u = np.random.randint(0, G.number_of_nodes())\n",
    "                v = np.random.randint(0, G.number_of_nodes())\n",
    "                if (not G.has_edge(u, v)) and (u != v):\n",
    "                    break\n",
    "            G.add_edge(u, v)\n",
    "        perturbed_graph_list.append(G)\n",
    "    return perturbed_graph_list\n",
    "\n",
    "\"\"\"\n",
    "Load an existing graph to be converted for the experiments.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "G                        :      Networkx graph is the input for preprocessing\n",
    "labels                   :      corresponding node labels\n",
    "normalize_adj            :      Boolean\n",
    "                                returns a normalized adjacency matrix (True)\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "{\"adj\", \"feat\" \"labels\"} :  dictionary containing adjacency, node features and labels\n",
    "\"\"\"\n",
    "def preprocess_input_graph(G, labels, normalize_adj=False):\n",
    "    # Create the adjacency matrix for graph\n",
    "    adj = np.array(nx.to_numpy_matrix(G))\n",
    "    print(\"------ Preprocess Input graph ------\")\n",
    "    print(\"The shape of the adjacency matrix ('dxd') of input graph :\", adj.shape)\n",
    "\n",
    "    # If normalization is required\n",
    "#     if normalize_adj:\n",
    "#         # Create a diagonal array\n",
    "#         sqrt_deg = np.diag(1.0 / np.sqrt(np.sum(adj, axis=0, dtype=float).squeeze()))\n",
    "#         adj = np.matmul(np.matmul(sqrt_deg, adj), sqrt_deg)\n",
    "\n",
    "    # last index from 0 - 34\n",
    "    existing_node = list(G.nodes)[-1]\n",
    "    # Dimension of features\n",
    "    feat_dim = G.nodes[existing_node][\"feat\"].shape[0]\n",
    "    print(\"Feature dimensions of the last node '\" + str(existing_node) + \"' : \" + str(feat_dim))\n",
    "\n",
    "    # Initialize feature ndarray (dimension of number_of_nodes x feat_dim) \n",
    "    features = np.zeros((G.number_of_nodes(), feat_dim), dtype=float)\n",
    "    for idx, node_id in enumerate(G.nodes()):\n",
    "        features[idx, :] = G.nodes[node_id][\"feat\"]\n",
    "\n",
    "    # add batch dim by expanding the shape horizontally\n",
    "    adj = np.expand_dims(adj, axis=0)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)    \n",
    "    print(\"The shape of the adjacency matrix after expansion :\", adj.shape)\n",
    "    print(\"The shape of the features matrix after expansion :\", features.shape)\n",
    "    print(\"The shape of the labels matrix after expansion :\", labels.shape)\n",
    "    \n",
    "    return {\"adj\": adj, \"feat\": features, \"labels\": labels}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generating Synthetic Graph for experimentation :\n",
    "- Barabasi-Albert base graph and attach the no. of \"house\" motifs\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "nb_shapes         :  the no. of shapes ('house' motifs) that should be added to the\n",
    "                     base graph\n",
    "width_basis       :  the no. of nodes of the basis graph (ie. 'BA' graph)\n",
    "feature_generator :  a `Feature Generator` for node features\n",
    "                     addition of constant features to nodes ('None')\n",
    "m                 :  no. of edges to be attached to existing node (for 'BA' graph)\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "G                 :  a generated networkx \"ba\" graph with attached \"house\" motifs\n",
    "role_id           :  a list with total number of nodes in the entire graph (base graph\n",
    "                     and  motifs).  role_id[i] is the ID of the role of node i.\n",
    "                     It is also the label used for training and predictions\n",
    "name              :  a graph identifier\n",
    "\"\"\"\n",
    "def gen_syn1(nb_shapes=3, width_basis=20, feature_generator=None, m=5):\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"house\"]] * nb_shapes\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    # synthetic_structsim\n",
    "    G, role_id, _ = build_graph(width_basis, basis_type, list_shapes, start=0, m=5)\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        # feature generator\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    \n",
    "    # Generate node features\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)\n",
    "    \n",
    "    print(\"------ Generated the Synthetic BA graph with 'House' motifs ------\")\n",
    "    print(\"Name of generated graph :\", name)\n",
    "    return G, role_id, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This is the basic Graph Convolution Network class inherited from torch.nn module\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        add_self=False,\n",
    "        normalize_embedding=False,\n",
    "        dropout=0.0,\n",
    "        bias=True,\n",
    "        gpu=True,\n",
    "        att=False,\n",
    "    ):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.att = att\n",
    "        self.add_self = add_self\n",
    "        self.dropout = dropout\n",
    "        if dropout > 0.001:\n",
    "            self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.normalize_embedding = normalize_embedding\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        if not gpu:\n",
    "            self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
    "            if add_self:\n",
    "                self.self_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, output_dim)\n",
    "                )\n",
    "            if att:\n",
    "                self.att_weight = nn.Parameter(torch.FloatTensor(input_dim, input_dim))\n",
    "        else:\n",
    "            self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim).cuda())\n",
    "            if add_self:\n",
    "                self.self_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, output_dim).cuda()\n",
    "                )\n",
    "            if att:\n",
    "                self.att_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, input_dim).cuda()\n",
    "                )\n",
    "        if bias:\n",
    "            if not gpu:\n",
    "                self.bias = nn.Parameter(torch.FloatTensor(output_dim))\n",
    "            else:\n",
    "                self.bias = nn.Parameter(torch.FloatTensor(output_dim).cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        # self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        if self.dropout > 0.001:\n",
    "            x = self.dropout_layer(x)\n",
    "        # deg = torch.sum(adj, -1, keepdim=True)\n",
    "        if self.att:\n",
    "            x_att = torch.matmul(x, self.att_weight)\n",
    "            # import pdb\n",
    "            # pdb.set_trace()\n",
    "            att = x_att @ x_att.permute(0, 2, 1)\n",
    "            # att = self.softmax(att)\n",
    "            adj = adj * att\n",
    "\n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.add_self:\n",
    "            self_emb = torch.matmul(x, self.self_weight)\n",
    "            y += self_emb\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        if self.normalize_embedding:\n",
    "            y = F.normalize(y, p=2, dim=2)\n",
    "            # print(y[0][0])\n",
    "        return y, adj\n",
    "\n",
    "    \n",
    "# Build the convolution layers for the GCN Graph Encoder\n",
    "# This is where the node masks and embeddings are created with predictions in forward pass\n",
    "class GcnEncoderGraph(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        embedding_dim,           # output_dim\n",
    "        label_dim,               # num_classes\n",
    "        num_layers,              # num_gc_layers\n",
    "        pred_hidden_dims=[],\n",
    "        concat=True,\n",
    "        bn=True,\n",
    "        dropout=0.0,\n",
    "        add_self=False,\n",
    "        args=None,\n",
    "    ):\n",
    "      \n",
    "        super(GcnEncoderGraph, self).__init__()\n",
    "        self.concat = concat\n",
    "\n",
    "        # add_self = add_self\n",
    "        self.add_self = add_self\n",
    "\n",
    "        # This value will change from 'True' if it is provided by the caller function\n",
    "        self.bn = bn\n",
    "        self.num_layers = num_layers\n",
    "        self.num_aggs = 1\n",
    "\n",
    "        self.bias = True        \n",
    "        self.gpu = args.gpu\n",
    "        print(\"*** Check received batch_size argument :\", args.batch_size)\n",
    "        print(\"*** Batch normalization from caller (default : False) :\", bn)\n",
    "\n",
    "        if args.method == \"att\":\n",
    "            self.att = True\n",
    "        else:\n",
    "            self.att = False\n",
    "        if args is not None:\n",
    "            self.bias = args.bias\n",
    "\n",
    "        self.conv_first, self.conv_block, self.conv_last = self.build_conv_layers(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            num_layers,\n",
    "            add_self,\n",
    "            normalize=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        if concat:\n",
    "            self.pred_input_dim = hidden_dim * (num_layers - 1) + embedding_dim\n",
    "        else:\n",
    "            self.pred_input_dim = embedding_dim\n",
    "        self.pred_model = self.build_pred_layers(\n",
    "            self.pred_input_dim, pred_hidden_dims, label_dim, num_aggs=self.num_aggs\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, GraphConv):\n",
    "                init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain(\"relu\"))\n",
    "                if m.att:\n",
    "                    init.xavier_uniform_(\n",
    "                        m.att_weight.data, gain=nn.init.calculate_gain(\"relu\")\n",
    "                    )\n",
    "                if m.add_self:\n",
    "                    init.xavier_uniform_(\n",
    "                        m.self_weight.data, gain=nn.init.calculate_gain(\"relu\")\n",
    "                    )\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    def build_conv_layers(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        embedding_dim,\n",
    "        num_layers,\n",
    "        add_self,\n",
    "        normalize=False,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        conv_first = GraphConv(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=hidden_dim,\n",
    "            add_self=add_self,\n",
    "            normalize_embedding=normalize,\n",
    "            bias=self.bias,\n",
    "            gpu=self.gpu,\n",
    "            att=self.att,\n",
    "        )\n",
    "        conv_block = nn.ModuleList(\n",
    "            [\n",
    "                GraphConv(\n",
    "                    input_dim=hidden_dim,\n",
    "                    output_dim=hidden_dim,\n",
    "                    add_self=add_self,\n",
    "                    normalize_embedding=normalize,\n",
    "                    dropout=dropout,\n",
    "                    bias=self.bias,\n",
    "                    gpu=self.gpu,\n",
    "                    att=self.att,\n",
    "                )\n",
    "                for i in range(num_layers - 2)\n",
    "            ]\n",
    "        )\n",
    "        conv_last = GraphConv(\n",
    "            input_dim=hidden_dim,\n",
    "            output_dim=embedding_dim,\n",
    "            add_self=add_self,\n",
    "            normalize_embedding=normalize,\n",
    "            bias=self.bias,\n",
    "            gpu=self.gpu,\n",
    "            att=self.att,\n",
    "        )\n",
    "        return conv_first, conv_block, conv_last\n",
    "\n",
    "    def build_pred_layers(\n",
    "        self, pred_input_dim, pred_hidden_dims, label_dim, num_aggs=1\n",
    "    ):\n",
    "        pred_input_dim = pred_input_dim * num_aggs\n",
    "        if len(pred_hidden_dims) == 0:\n",
    "            pred_model = nn.Linear(pred_input_dim, label_dim)\n",
    "        else:\n",
    "            pred_layers = []\n",
    "            for pred_dim in pred_hidden_dims:\n",
    "                pred_layers.append(nn.Linear(pred_input_dim, pred_dim))\n",
    "                pred_layers.append(self.act)\n",
    "                pred_input_dim = pred_dim\n",
    "            pred_layers.append(nn.Linear(pred_dim, label_dim))\n",
    "            pred_model = nn.Sequential(*pred_layers)\n",
    "        return pred_model\n",
    "\n",
    "    \"\"\"\n",
    "    For each num_nodes in batch_num_nodes, the first num_nodes entries of the \n",
    "    corresponding column are 1's, and the rest are 0's (to be masked out).\n",
    "    Dimension of mask: [batch_size x max_nodes x 1]\n",
    "    \"\"\"\n",
    "    def construct_mask(self, max_nodes, batch_num_nodes):\n",
    "        # masks\n",
    "        packed_masks = [torch.ones(int(num)) for num in batch_num_nodes]\n",
    "        batch_size = len(batch_num_nodes)\n",
    "        out_tensor = torch.zeros(batch_size, max_nodes)\n",
    "        for i, mask in enumerate(packed_masks):\n",
    "            out_tensor[i, : batch_num_nodes[i]] = mask\n",
    "        return out_tensor.unsqueeze(2).cuda()\n",
    "\n",
    "    \"\"\"\n",
    "    Batch normalization of 3D tensor x\n",
    "    \"\"\"\n",
    "    def apply_bn(self, x):\n",
    "        bn_module = nn.BatchNorm1d(x.size()[1])\n",
    "        if self.gpu:\n",
    "            bn_module = bn_module.cuda()\n",
    "        return bn_module(x)\n",
    "\n",
    "    \"\"\"\n",
    "    Perform forward prop with graph convolution.\n",
    "    Returns:\n",
    "        Embedding matrix with dimension [batch_size x num_nodes x embedding]\n",
    "        The embedding dim is self.pred_input_dim\n",
    "    \"\"\"\n",
    "    def gcn_forward(\n",
    "        self, x, adj, conv_first, conv_block, conv_last, embedding_mask=None\n",
    "    ):\n",
    "\n",
    "        x, adj_att = conv_first(x, adj)\n",
    "        x = self.act(x)\n",
    "        if self.bn:\n",
    "            x = self.apply_bn(x)\n",
    "        x_all = [x]\n",
    "        adj_att_all = [adj_att]\n",
    "        # out_all = []\n",
    "        # out, _ = torch.max(x, dim=1)\n",
    "        # out_all.append(out)\n",
    "        for i in range(len(conv_block)):\n",
    "            x, _ = conv_block[i](x, adj)\n",
    "            x = self.act(x)\n",
    "            if self.bn:\n",
    "                x = self.apply_bn(x)\n",
    "            x_all.append(x)\n",
    "            adj_att_all.append(adj_att)\n",
    "        x, adj_att = conv_last(x, adj)\n",
    "        x_all.append(x)\n",
    "        adj_att_all.append(adj_att)\n",
    "        # x_tensor: [batch_size x num_nodes x embedding]\n",
    "        x_tensor = torch.cat(x_all, dim=2)\n",
    "        if embedding_mask is not None:\n",
    "            x_tensor = x_tensor * embedding_mask\n",
    "        self.embedding_tensor = x_tensor\n",
    "\n",
    "        # adj_att_tensor: [batch_size x num_nodes x num_nodes x num_gc_layers]\n",
    "        adj_att_tensor = torch.stack(adj_att_all, dim=3)\n",
    "        return x_tensor, adj_att_tensor\n",
    "\n",
    "    def forward(self, x, adj, batch_num_nodes=None, **kwargs):\n",
    "        # Embedding mask\n",
    "        max_num_nodes = adj.size()[1]\n",
    "        if batch_num_nodes is not None:\n",
    "            self.embedding_mask = self.construct_mask(max_num_nodes, batch_num_nodes)\n",
    "        else:\n",
    "            self.embedding_mask = None\n",
    "\n",
    "        # Convolution\n",
    "        x, adj_att = self.conv_first(x, adj)\n",
    "        x = self.act(x)\n",
    "        if self.bn:\n",
    "            x = self.apply_bn(x)\n",
    "        out_all = []\n",
    "        out, _ = torch.max(x, dim=1)\n",
    "        out_all.append(out)\n",
    "        adj_att_all = [adj_att]\n",
    "        for i in range(self.num_layers - 2):\n",
    "            x, adj_att = self.conv_block[i](x, adj)\n",
    "            x = self.act(x)\n",
    "            if self.bn:\n",
    "                x = self.apply_bn(x)\n",
    "            out, _ = torch.max(x, dim=1)\n",
    "            out_all.append(out)\n",
    "            if self.num_aggs == 2:\n",
    "                out = torch.sum(x, dim=1)\n",
    "                out_all.append(out)\n",
    "            adj_att_all.append(adj_att)\n",
    "        x, adj_att = self.conv_last(x, adj)\n",
    "        adj_att_all.append(adj_att)\n",
    "        # x = self.act(x)\n",
    "        out, _ = torch.max(x, dim=1)\n",
    "        out_all.append(out)\n",
    "        if self.num_aggs == 2:\n",
    "            out = torch.sum(x, dim=1)\n",
    "            out_all.append(out)\n",
    "        if self.concat:\n",
    "            output = torch.cat(out_all, dim=1)\n",
    "        else:\n",
    "            output = out\n",
    "\n",
    "        # adj_att_tensor: [batch_size x num_nodes x num_nodes x num_gc_layers]\n",
    "        adj_att_tensor = torch.stack(adj_att_all, dim=3)\n",
    "\n",
    "        self.embedding_tensor = output\n",
    "        ypred = self.pred_model(output)\n",
    "        # print(output.size())\n",
    "        return ypred, adj_att_tensor\n",
    "\n",
    "#     def loss(self, pred, label, type=\"softmax\"):\n",
    "#         # softmax + CE\n",
    "#         if type == \"softmax\":\n",
    "#             return F.cross_entropy(pred, label, size_average=True)\n",
    "#         elif type == \"margin\":\n",
    "#             batch_size = pred.size()[0]\n",
    "#             label_onehot = torch.zeros(batch_size, self.label_dim).long().cuda()\n",
    "#             label_onehot.scatter_(1, label.view(-1, 1), 1)\n",
    "#             return torch.nn.MultiLabelMarginLoss()(pred, label_onehot)\n",
    "\n",
    "        # return F.binary_cross_entropy(F.sigmoid(pred[:,0]), label.float())\n",
    "\n",
    "# GCN Encoding of the nodes\n",
    "class GcnEncoderNode(GcnEncoderGraph):    \n",
    "    def __init__(self, input_dim, hidden_dim, embedding_dim, label_dim, num_layers,\n",
    "                 pred_hidden_dims=[], concat=True,\n",
    "                 bn=True, dropout=0.0, args=None,):\n",
    "        super(GcnEncoderNode, self).__init__(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            label_dim,\n",
    "            num_layers,\n",
    "            pred_hidden_dims,\n",
    "            concat,\n",
    "            bn,\n",
    "            dropout,\n",
    "            args=args,\n",
    "        )\n",
    "        \n",
    "        if hasattr(args, \"loss_weight\"):\n",
    "            print(\"Loss weight: \", args.loss_weight)\n",
    "            self.celoss = nn.CrossEntropyLoss(weight=args.loss_weight)\n",
    "        else:\n",
    "            self.celoss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, adj, batch_num_nodes=None, **kwargs):\n",
    "        # Embedding masks\n",
    "        max_num_nodes = adj.size()[1]\n",
    "        if batch_num_nodes is not None:\n",
    "            embedding_mask = self.construct_mask(max_num_nodes, batch_num_nodes)\n",
    "        else:\n",
    "            embedding_mask = None\n",
    "\n",
    "        self.adj_atts = []\n",
    "        self.embedding_tensor, adj_att = self.gcn_forward(\n",
    "            x, adj, self.conv_first, self.conv_block, self.conv_last, embedding_mask\n",
    "        )\n",
    "        pred = self.pred_model(self.embedding_tensor)\n",
    "        return pred, adj_att\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        pred = torch.transpose(pred, 1, 2)\n",
    "        return self.celoss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# (1) GcnEncoderNode(GcnEncoderGraph) -> build_conv_layers -> GraphConv\n",
    "# build_conv_layers return conv_first, conv_block, conv_last\n",
    "# (2) GcnEncoderNode(GcnEncoderGraph) -> self.pred_model = self.build_pred_layers\n",
    "# build_pred_layers return pred_model\n",
    "# (3) syn_task1 -> train_node_classifier -> save_checkpoint\n",
    "#####################################################################################\n",
    "# Create the GCN mode and encoding the nodes\n",
    "def syn_task1(args, writer=None):\n",
    "    # featgen.ConstFeatureGen\n",
    "    # np.ones(input_dim, dtype=float) = [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]\n",
    "    constant_feature = ConstFeatureGen(np.ones(args.input_dim, dtype=float))\n",
    "    print(\"Constant feature generator : \", constant_feature.val)\n",
    "    \n",
    "    #feat_dict = {i:{'feat': np.array(constant_feature.val, dtype=np.float32)} for i in G.nodes()}\n",
    "    #print ('Values of feat_dict[0][\"feat\"]:', feat_dict[0]['feat'])\n",
    "\n",
    "    #nx.set_node_attributes(G, feat_dict)\n",
    "    #print('Node attributes of node \\'0\\', G.nodes[0][\"feat\"]:', G.nodes[0]['feat'])\n",
    "\n",
    "    # gengraph.gen_syn1\n",
    "    # Create the BA graph with the \"house\" motifs\n",
    "    G, labels, name = gen_syn1(feature_generator=constant_feature)\n",
    "\n",
    "    # No .of classes from [0-3] for BA graph with house motifs\n",
    "    num_classes = max(labels) + 1\n",
    "    # Update number of classes in argument for training (Out of bounds error)\n",
    "    args.num_classes = num_classes\n",
    "    \n",
    "    # GcnEncoderNode model\n",
    "    print(\"------------ GCNEncoderNode Model ------------\")\n",
    "    print(\"Input dimensions :\", args.input_dim)\n",
    "    print(\"Hidden dimensions :\", args.hidden_dim)\n",
    "    print(\"Output dimensions :\", args.output_dim)\n",
    "    print(\"Number of classes in args :\", args.num_classes)\n",
    "    print(\"Number of GCN layers :\", args.num_gc_layers)\n",
    "    print(\"Method : \", args.method)\n",
    "\n",
    "    model = GcnEncoderNode(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                           args.num_classes, args.num_gc_layers, bn=args.bn, args=args)\n",
    "    \n",
    "    print(\"GcnEncoderNode model :\\n\", model)\n",
    "    \n",
    "\n",
    "#     if args.method == \"att\":\n",
    "#         print(\"Method: att\")\n",
    "#         model = models.GcnEncoderNode(\n",
    "#             args.input_dim,\n",
    "#             args.hidden_dim,\n",
    "#             args.output_dim,\n",
    "#             num_classes,\n",
    "#             args.num_gc_layers,\n",
    "#             bn=args.bn,\n",
    "#             args=args,\n",
    "#         )\n",
    "#     else:\n",
    "#         print(\"Method:\", args.method)\n",
    "#         model = models.GcnEncoderNode(\n",
    "#             args.input_dim,\n",
    "#             args.hidden_dim,\n",
    "#             args.output_dim,\n",
    "#             num_classes,\n",
    "#             args.num_gc_layers,\n",
    "#             bn=args.bn,\n",
    "#             args=args,\n",
    "#         )\n",
    "    if args.gpu:\n",
    "        model = model.cuda()\n",
    "\n",
    "    train_node_classifier(G, labels, model, args, writer=writer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_node(ypred, labels, train_idx, test_idx):\n",
    "    _, pred_labels = torch.max(ypred, 2)\n",
    "    pred_labels = pred_labels.numpy()\n",
    "\n",
    "    pred_train = np.ravel(pred_labels[:, train_idx])\n",
    "    pred_test = np.ravel(pred_labels[:, test_idx])\n",
    "    labels_train = np.ravel(labels[:, train_idx])\n",
    "    labels_test = np.ravel(labels[:, test_idx])\n",
    "\n",
    "    result_train = {\n",
    "        \"prec\": metrics.precision_score(labels_train, pred_train, average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(labels_train, pred_train, average=\"macro\"),\n",
    "        \"acc\": metrics.accuracy_score(labels_train, pred_train),\n",
    "        \"conf_mat\": metrics.confusion_matrix(labels_train, pred_train),\n",
    "    }\n",
    "    result_test = {\n",
    "        \"prec\": metrics.precision_score(labels_test, pred_test, average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(labels_test, pred_test, average=\"macro\"),\n",
    "        \"acc\": metrics.accuracy_score(labels_test, pred_test),\n",
    "        \"conf_mat\": metrics.confusion_matrix(labels_test, pred_test),\n",
    "    }\n",
    "    return result_train, result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "'''\n",
    "Generate label prefix for a graph model.\n",
    "'''\n",
    "def gen_prefix(args):\n",
    "    if args.bmname is not None:\n",
    "        name = args.bmname\n",
    "    else:\n",
    "        name = args.dataset\n",
    "    name += \"_\" + args.method\n",
    "\n",
    "    name += \"_hdim\" + str(args.hidden_dim) + \"_odim\" + str(args.output_dim)\n",
    "    if not args.bias:\n",
    "        name += \"_nobias\"\n",
    "    if len(args.name_suffix) > 0:\n",
    "        name += \"_\" + args.name_suffix\n",
    "    return name\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create filename for saving.\n",
    "\n",
    "Args:\n",
    "    args        :  the arguments parsed in the parser\n",
    "    isbest      :  whether the saved model is the best-performing one\n",
    "    num_epochs  :  epoch number of the model (when isbest=False)\n",
    "\"\"\"\n",
    "def create_filename(save_dir, args, isbest=False, num_epochs=-1):\n",
    "    filename = os.path.join(\"./\", save_dir, gen_prefix(args))\n",
    "    os.makedirs(filename, exist_ok=True)\n",
    "\n",
    "    if isbest:\n",
    "        filename = os.path.join(filename, \"best\")\n",
    "    elif num_epochs > 0:\n",
    "        filename = os.path.join(filename, str(num_epochs))\n",
    "    else:\n",
    "        filename = os.path.join(filename, \"BA_graph\")\n",
    "\n",
    "    path_filename = filename + \"_model_dict.pth\" # \".pth.tar\"\n",
    "    print(\"Created filename with path : \", path_filename)\n",
    "    return path_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn-model-explainer/utils/io_utils.py\n",
    "\"\"\"\n",
    "Save pytorch model checkpoint.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "model         : The PyTorch model to save.\n",
    "optimizer     : The optimizer used to train the model.\n",
    "args          : A dict of meta-data about the model.\n",
    "num_epochs    : Number of training epochs.\n",
    "isbest        : True if the model has the highest accuracy so far.\n",
    "cg_dict       : A dictionary of the sampled computation graphs.\n",
    "\n",
    "Output :\n",
    "----------------------------------------------------------------------------------------\n",
    "filename      : File saved in \"ckpt\" subdirectory\n",
    "\"\"\"\n",
    "def save_checkpoint(model, optimizer, args, num_epochs=-1, isbest=False, cg_dict=None):\n",
    "    filename = create_filename(args.ckptdir, args, isbest, num_epochs=num_epochs)\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": num_epochs,\n",
    "            \"model_type\": args.method,\n",
    "            \"optimizer\": optimizer,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"cg\": cg_dict,\n",
    "        },\n",
    "        filename\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train node classifier and save the prediction results\n",
    "def train_node_classifier(G, labels, model, args, writer=None):\n",
    "    # train/test split only for nodes\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    \n",
    "    # Training data with 80% ratio, labels_train.size()\n",
    "    num_train = int(num_nodes * args.train_ratio)\n",
    "    idx = [i for i in range(num_nodes)]\n",
    "\n",
    "    # Shuffle for training\n",
    "    np.random.shuffle(idx)\n",
    "    train_idx = idx[:num_train]\n",
    "    test_idx = idx[num_train:]\n",
    "\n",
    "    # data = gengraph.preprocess_input_graph(G, labels)\n",
    "    data = preprocess_input_graph(G, labels)\n",
    "    labels_train = torch.tensor(data[\"labels\"][:, train_idx], dtype=torch.long)\n",
    "    adj = torch.tensor(data[\"adj\"], dtype=torch.float)\n",
    "    x = torch.tensor(data[\"feat\"], requires_grad=True, dtype=torch.float)\n",
    "\n",
    "    \n",
    "#     scheduler, optimizer = train_utils.build_optimizer(\n",
    "#         args, model.parameters(), weight_decay=args.weight_decay\n",
    "#     )\n",
    "    # list(testModel.parameters()) and list(filter_fn) to show contents\n",
    "    # train_utils.build_optimizer \n",
    "    filter_fn = filter(lambda p : p.requires_grad, model.parameters())\n",
    "\n",
    "    # args.opt == 'adam':\n",
    "    optimizer = optim.Adam(filter_fn, lr=prog_args.lr, weight_decay=0.0)\n",
    "    scheduler = None\n",
    "\n",
    "    # Sets the module in training mode\n",
    "    model.train()\n",
    "    ypred = None\n",
    "    for epoch in range(args.num_epochs):\n",
    "        begin_time = time.time()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if args.gpu:\n",
    "            ypred, adj_att = model(x.cuda(), adj.cuda())\n",
    "        else:\n",
    "            ypred, adj_att = model(x, adj)\n",
    "        ypred_train = ypred[:, train_idx, :]\n",
    "        if args.gpu:\n",
    "            loss = model.loss(ypred_train, labels_train.cuda())\n",
    "        else:\n",
    "            loss = model.loss(ypred_train, labels_train)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        #for param_group in optimizer.param_groups:\n",
    "        #    print(param_group[\"lr\"])\n",
    "        elapsed = time.time() - begin_time\n",
    "\n",
    "        # Obtain with Confusion matrices for Train and Test results\n",
    "        result_train, result_test = evaluate_node(\n",
    "            ypred.cpu(), data[\"labels\"], train_idx, test_idx\n",
    "        )\n",
    "        \n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"loss/avg_loss\", loss, epoch)\n",
    "            writer.add_scalars(\n",
    "                \"prec\",\n",
    "                {\"train\": result_train[\"prec\"], \"test\": result_test[\"prec\"]},\n",
    "                epoch,\n",
    "            )\n",
    "            writer.add_scalars(\n",
    "                \"recall\",\n",
    "                {\"train\": result_train[\"recall\"], \"test\": result_test[\"recall\"]},\n",
    "                epoch,\n",
    "            )\n",
    "            writer.add_scalars(\n",
    "                \"acc\", {\"train\": result_train[\"acc\"], \"test\": result_test[\"acc\"]}, epoch\n",
    "            )\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\n",
    "                \"epoch: \",\n",
    "                epoch,\n",
    "                \"; loss: \",\n",
    "                loss.item(),\n",
    "                \"; train_acc: \",\n",
    "                result_train[\"acc\"],\n",
    "                \"; test_acc: \",\n",
    "                result_test[\"acc\"],\n",
    "                \"; train_prec: \",\n",
    "                result_train[\"prec\"],\n",
    "                \"; test_prec: \",\n",
    "                result_test[\"prec\"],\n",
    "                \"; epoch time: \",\n",
    "                \"{0:0.2f}\".format(elapsed),\n",
    "            )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    print(\"Confusion Matrix of train result :\\n\", result_train[\"conf_mat\"])\n",
    "    print(\"Confusion Matrix of test result :\\n\", result_test[\"conf_mat\"])\n",
    "\n",
    "    # Sets the module in evaluation mode for computational graph\n",
    "    model.eval()\n",
    "    if args.gpu:\n",
    "        ypred, _ = model(x.cuda(), adj.cuda())\n",
    "    else:\n",
    "        ypred, _ = model(x, adj)\n",
    "\n",
    "    cg_data = {\n",
    "        \"adj\": data[\"adj\"],\n",
    "        \"feat\": data[\"feat\"],\n",
    "        \"label\": data[\"labels\"],\n",
    "        \"pred\": ypred.cpu().detach().numpy(),\n",
    "        \"train_idx\": train_idx,\n",
    "    }\n",
    "    \n",
    "    print(\"Labels of the Computational graph :\\n\", cg_data['label'])\n",
    "    print(\"Prediction result of the Computational graph :\\n\", cg_data['pred'])\n",
    "    print(\"Train index of the Computational graph data :\\n\", cg_data['train_idx'])\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    \n",
    "    #io_utils.save_checkpoint\n",
    "    save_checkpoint(model, optimizer, args, num_epochs=-1, cg_dict=cg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in Constant Feature Generator :  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Constant feature generator :  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "------ Building the Synthetic BA graph with 'House' motifs ------\n",
      "Role Id of the BA graph :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Indicator of the id of the next node : 20\n",
      "Number of nodes in the BA graph :  20\n",
      "Number of motifs :  3\n",
      "List of shapes : [['house'], ['house'], ['house']]\n",
      "No. of shapes : 3\n",
      "Spacing :  6\n",
      "Plugins :  [0, 6, 12]\n",
      "seen_shapes :  {'basis': [0, 20]}\n",
      "\n",
      "-----------------------------------------\n",
      "Shape_ID : 0 with shape type : house\n",
      "1 shapes with list of Shape : ['house']\n",
      "The shape starts from index 1 :  []\n",
      "\n",
      "The list of arguments : [20, 0]\n",
      "The first item in list of arguments : 20\n",
      "The second item in list of arguments : 0\n",
      "Column start : 1\n",
      "Observe seen_shapes :  {'basis': [0, 20], 'house': [1, 5]}\n",
      "Labels of BA graph with attached motifs :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3]\n",
      "No. of nodes in attached graph :  25\n",
      "With attached motif nodes, index starts from :  25\n",
      "\n",
      "-----------------------------------------\n",
      "Shape_ID : 1 with shape type : house\n",
      "1 shapes with list of Shape : ['house']\n",
      "The shape starts from index 1 :  []\n",
      "\n",
      "The list of arguments : [25, 0]\n",
      "The first item in list of arguments : 25\n",
      "The second item in list of arguments : 0\n",
      "Column start : 1\n",
      "Observe seen_shapes :  {'basis': [0, 20], 'house': [1, 5]}\n",
      "Labels of BA graph with attached motifs :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3]\n",
      "No. of nodes in attached graph :  30\n",
      "With attached motif nodes, index starts from :  30\n",
      "\n",
      "-----------------------------------------\n",
      "Shape_ID : 2 with shape type : house\n",
      "1 shapes with list of Shape : ['house']\n",
      "The shape starts from index 1 :  []\n",
      "\n",
      "The list of arguments : [30, 0]\n",
      "The first item in list of arguments : 30\n",
      "The second item in list of arguments : 0\n",
      "Column start : 1\n",
      "Observe seen_shapes :  {'basis': [0, 20], 'house': [1, 5]}\n",
      "Labels of BA graph with attached motifs :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3]\n",
      "No. of nodes in attached graph :  35\n",
      "With attached motif nodes, index starts from :  35\n",
      "\n",
      "Information of the motif graph :\n",
      " Name: \n",
      "Type: Graph\n",
      "Number of nodes: 5\n",
      "Number of edges: 6\n",
      "Average degree:   2.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate node features for 35 nodes.\n",
      "Values of feat_dict[0][\"feat\"]: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Node attributes of node '0', G.nodes[0][\"feat\"]: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "------ Generated the Synthetic BA graph with 'House' motifs ------\n",
      "Name of generated graph : ba_20_3\n",
      "------------ GCNEncoderNode Model ------------\n",
      "Input dimensions : 10\n",
      "Hidden dimensions : 20\n",
      "Output dimensions : 20\n",
      "Number of classes in args : 4\n",
      "Number of GCN layers : 3\n",
      "Method :  base\n",
      "*** Check received batch_size argument : 20\n",
      "*** Batch normalization from caller (default : False) : False\n",
      "GcnEncoderNode model :\n",
      " GcnEncoderNode(\n",
      "  (conv_first): GraphConv()\n",
      "  (conv_block): ModuleList(\n",
      "    (0): GraphConv()\n",
      "  )\n",
      "  (conv_last): GraphConv()\n",
      "  (act): ReLU()\n",
      "  (pred_model): Linear(in_features=60, out_features=4, bias=True)\n",
      "  (celoss): CrossEntropyLoss()\n",
      ")\n",
      "------ Preprocess Input graph ------\n",
      "The shape of the adjacency matrix ('dxd') of input graph : (35, 35)\n",
      "Feature dimensions of the last node '34' : 10\n",
      "The shape of the adjacency matrix after expansion : (1, 35, 35)\n",
      "The shape of the features matrix after expansion : (1, 35, 10)\n",
      "The shape of the labels matrix after expansion : (1, 35)\n",
      "epoch:  0 ; loss:  1.3622418642044067 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.02\n",
      "epoch:  10 ; loss:  1.2947776317596436 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  20 ; loss:  1.2439733743667603 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  30 ; loss:  1.2050397396087646 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  40 ; loss:  1.1767566204071045 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  50 ; loss:  1.1576430797576904 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  60 ; loss:  1.1457308530807495 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  70 ; loss:  1.1378761529922485 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  80 ; loss:  1.1309685707092285 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  90 ; loss:  1.1222500801086426 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  100 ; loss:  1.108876347541809 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  110 ; loss:  1.0856529474258423 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  120 ; loss:  1.0419684648513794 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  130 ; loss:  0.9590317606925964 ; train_acc:  0.5714285714285714 ; test_acc:  0.5714285714285714 ; train_prec:  0.14285714285714285 ; test_prec:  0.19047619047619047 ; epoch time:  0.00\n",
      "epoch:  140 ; loss:  0.8443032503128052 ; train_acc:  0.75 ; test_acc:  0.7142857142857143 ; train_prec:  0.42391304347826086 ; test_prec:  0.5555555555555555 ; epoch time:  0.00\n",
      "epoch:  150 ; loss:  0.7548710107803345 ; train_acc:  0.75 ; test_acc:  0.7142857142857143 ; train_prec:  0.34893048128342247 ; test_prec:  0.5555555555555555 ; epoch time:  0.00\n",
      "epoch:  160 ; loss:  0.6865271925926208 ; train_acc:  0.75 ; test_acc:  0.7142857142857143 ; train_prec:  0.34893048128342247 ; test_prec:  0.5555555555555555 ; epoch time:  0.00\n",
      "epoch:  170 ; loss:  0.63547283411026 ; train_acc:  0.75 ; test_acc:  0.7142857142857143 ; train_prec:  0.3541666666666667 ; test_prec:  0.4444444444444444 ; epoch time:  0.00\n",
      "epoch:  180 ; loss:  0.5953560471534729 ; train_acc:  0.7857142857142857 ; test_acc:  1.0 ; train_prec:  0.6136363636363636 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  190 ; loss:  0.5523858666419983 ; train_acc:  0.7857142857142857 ; test_acc:  1.0 ; train_prec:  0.6136363636363636 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  200 ; loss:  0.5063086748123169 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  210 ; loss:  0.46617236733436584 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  220 ; loss:  0.4332456886768341 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  230 ; loss:  0.40429696440696716 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  240 ; loss:  0.377938836812973 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  250 ; loss:  0.35434240102767944 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  260 ; loss:  0.3317485451698303 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  270 ; loss:  0.3114297091960907 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  280 ; loss:  0.29251018166542053 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  290 ; loss:  0.27538782358169556 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  300 ; loss:  0.25932925939559937 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  310 ; loss:  0.24440965056419373 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  320 ; loss:  0.23045744001865387 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  330 ; loss:  0.21793381869792938 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  340 ; loss:  0.20617100596427917 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  350 ; loss:  0.19519832730293274 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  360 ; loss:  0.18481110036373138 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  370 ; loss:  0.1756436824798584 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  380 ; loss:  0.16698257625102997 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  390 ; loss:  0.15904395282268524 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  400 ; loss:  0.15181894600391388 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  410 ; loss:  0.1446826308965683 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  420 ; loss:  0.13832806050777435 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  430 ; loss:  0.13228456676006317 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  440 ; loss:  0.12667196989059448 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  450 ; loss:  0.12144981324672699 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  460 ; loss:  0.11674461513757706 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  470 ; loss:  0.11191118508577347 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  480 ; loss:  0.10770219564437866 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  490 ; loss:  0.10372795164585114 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  500 ; loss:  0.09963341802358627 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  510 ; loss:  0.09608195722103119 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  520 ; loss:  0.09269904345273972 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  530 ; loss:  0.08933542668819427 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  540 ; loss:  0.0862848311662674 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  550 ; loss:  0.08321433514356613 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  560 ; loss:  0.0810583308339119 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  570 ; loss:  0.07786190509796143 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  580 ; loss:  0.07534899562597275 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  590 ; loss:  0.07287601381540298 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  600 ; loss:  0.07053159177303314 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  610 ; loss:  0.068255715072155 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  620 ; loss:  0.0663132295012474 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  630 ; loss:  0.06432954221963882 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  640 ; loss:  0.062463682144880295 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  650 ; loss:  0.06036490201950073 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  660 ; loss:  0.05862816795706749 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  670 ; loss:  0.05704851821064949 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  680 ; loss:  0.055176474153995514 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  690 ; loss:  0.05364498496055603 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  700 ; loss:  0.05214036628603935 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  710 ; loss:  0.050573546439409256 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  720 ; loss:  0.04925721883773804 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  730 ; loss:  0.04803294688463211 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  740 ; loss:  0.04665135219693184 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  750 ; loss:  0.04527999088168144 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  760 ; loss:  0.04399864748120308 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  770 ; loss:  0.042672205716371536 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  780 ; loss:  0.041601624339818954 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  790 ; loss:  0.04055366292595863 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  800 ; loss:  0.039323389530181885 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  810 ; loss:  0.03828858211636543 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  820 ; loss:  0.03742292895913124 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  830 ; loss:  0.03642075136303902 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  840 ; loss:  0.03544855862855911 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  850 ; loss:  0.03456023707985878 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  860 ; loss:  0.033696770668029785 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  870 ; loss:  0.03288218006491661 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  880 ; loss:  0.031986456364393234 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  890 ; loss:  0.03126898780465126 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  900 ; loss:  0.03034892864525318 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  910 ; loss:  0.029562221840023994 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  920 ; loss:  0.028885914012789726 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  930 ; loss:  0.028186770156025887 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  940 ; loss:  0.027482036501169205 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  950 ; loss:  0.026824573054909706 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  960 ; loss:  0.02631676383316517 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  970 ; loss:  0.02557031251490116 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  980 ; loss:  0.025097670033574104 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  990 ; loss:  0.024549487978219986 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "Confusion Matrix of train result :\n",
      " [[16  0  0  0]\n",
      " [ 0  4  0  0]\n",
      " [ 0  0  5  0]\n",
      " [ 0  0  0  3]]\n",
      "Confusion Matrix of test result :\n",
      " [[4 0 0]\n",
      " [0 2 0]\n",
      " [0 0 1]]\n",
      "Labels of the Computational graph :\n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 2 3 1 1 2 2 3 1 1 2 2 3]]\n",
      "Prediction result of the Computational graph :\n",
      " [[[ 3.6880116  -1.8634319  -4.6521597  -1.857554  ]\n",
      "  [ 2.8791656  -3.026917   -1.9441082  -1.2338057 ]\n",
      "  [ 3.8125472  -2.170339   -4.0677752  -2.072964  ]\n",
      "  [ 3.7933946  -2.071735   -4.278511   -2.0356224 ]\n",
      "  [ 3.7296023  -1.8619981  -4.437195   -2.0367234 ]\n",
      "  [ 3.5620112  -1.4199991  -4.5223403  -2.0777504 ]\n",
      "  [ 3.5465698  -1.4501098  -4.606793   -1.9918954 ]\n",
      "  [ 3.5914984  -1.5597553  -4.533949   -2.027777  ]\n",
      "  [ 3.6752992  -1.748188   -4.505007   -2.0182173 ]\n",
      "  [ 3.6497855  -1.6938872  -4.5049076  -2.0276995 ]\n",
      "  [ 3.7228189  -1.8266346  -4.426653   -2.0575428 ]\n",
      "  [ 3.7652445  -1.94332    -4.367439   -2.051338  ]\n",
      "  [ 3.738449   -2.0472186  -4.637885   -1.7909842 ]\n",
      "  [ 3.7031922  -1.7957475  -4.4435844  -2.0523942 ]\n",
      "  [ 3.7413917  -1.875031   -4.359559   -2.0821586 ]\n",
      "  [ 3.769998   -1.9832733  -4.352995   -2.0407157 ]\n",
      "  [ 3.7789097  -1.990744   -4.269009   -2.082248  ]\n",
      "  [ 3.7466464  -1.881511   -4.3812265  -2.0678337 ]\n",
      "  [ 3.7812104  -2.0027723  -4.2778754  -2.0714576 ]\n",
      "  [ 3.7946982  -2.0775676  -4.252959   -2.047068  ]\n",
      "  [ 0.24645677  3.1112852  -0.9826608  -2.5108454 ]\n",
      "  [-0.8095329   3.69558    -0.10935789 -1.9948609 ]\n",
      "  [-2.1586752   0.33937907  4.0165186   0.15394312]\n",
      "  [-2.0274925   0.08515246  4.1461444   0.02582674]\n",
      "  [-0.6153241  -2.7784867  -0.52659214  3.130222  ]\n",
      "  [ 0.4207528   2.8584437  -1.0563937  -2.5541623 ]\n",
      "  [-0.7537086   3.7343974  -0.05730524 -2.1257699 ]\n",
      "  [-2.1586752   0.33937907  4.0165186   0.15394312]\n",
      "  [-1.8068775  -0.0397559   4.0247383  -0.12231153]\n",
      "  [-0.36920917 -3.0454295  -0.7337562   3.0911553 ]\n",
      "  [ 0.18006054  3.1958942  -0.9011924  -2.5172617 ]\n",
      "  [-0.8256985   3.6834116  -0.12054339 -1.9588006 ]\n",
      "  [-2.1586752   0.33937907  4.0165186   0.15394312]\n",
      "  [-2.0909677   0.11779898  4.1721883   0.07663436]\n",
      "  [-0.6826423  -2.7044253  -0.45915076  3.133805  ]]]\n",
      "Train index of the Computational graph data :\n",
      " [14, 17, 28, 32, 5, 13, 24, 26, 31, 6, 18, 12, 27, 9, 2, 23, 29, 33, 21, 3, 11, 15, 0, 30, 10, 1, 4, 34]\n",
      "Created filename with path :  ./ckpt/BAGraph_base_hdim20_odim20/BA_graph_model_dict.pth\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "# Call flow 1 : syn_task1 -> gen_syn1 -> build_graph -> ba\n",
    "# Call flow 2 : syn_task1 -> GcnEncoderNode, train_node_classifier -> preprocess_input_graph\n",
    "model = syn_task1(prog_args, writer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GcnEncoderNode(\n",
       "  (conv_first): GraphConv()\n",
       "  (conv_block): ModuleList(\n",
       "    (0): GraphConv()\n",
       "  )\n",
       "  (conv_last): GraphConv()\n",
       "  (act): ReLU()\n",
       "  (pred_model): Linear(in_features=60, out_features=4, bias=True)\n",
       "  (celoss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv_first.weight \t torch.Size([10, 20])\n",
      "conv_first.bias \t torch.Size([20])\n",
      "conv_block.0.weight \t torch.Size([20, 20])\n",
      "conv_block.0.bias \t torch.Size([20])\n",
      "conv_last.weight \t torch.Size([20, 20])\n",
      "conv_last.bias \t torch.Size([20])\n",
      "pred_model.weight \t torch.Size([4, 60])\n",
      "pred_model.bias \t torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "# Print optimizer's state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optimizer.state_dict():\n",
    "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/io_utils.py\n",
    "'''\n",
    "Load a pre-trained pytorch model from checkpoint.\n",
    "'''\n",
    "def load_ckpt(args, isbest=False):\n",
    "\n",
    "    print(\"Attempt to load model...\")\n",
    "    filename = create_filename(args.ckptdir, args, isbest)\n",
    "    print(\"Loading file : \", filename)\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        ckpt = torch.load(filename)\n",
    "    else:\n",
    "        print(\"Checkpoint does not exist!\")\n",
    "        print(\"Check correct path for : {}\".format(filename))\n",
    "        print(\"Make sure you have provided the correct path!\")\n",
    "        print(\"Or you may have forgotten to train a model for this dataset.\")\n",
    "        print()\n",
    "        print(\"To train one of the models, run the following\")\n",
    "        print(\">> python train.py --dataset=DATASET_NAME\")\n",
    "        print()\n",
    "        raise Exception(\"File is not found.\")\n",
    "    return ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt to load model...\n",
      "Created filename with path :  ./ckpt/BAGraph_base_hdim20_odim20/BA_graph_model_dict.pth\n",
      "Loading file :  ./ckpt/BAGraph_base_hdim20_odim20/BA_graph_model_dict.pth\n",
      "=> loading checkpoint './ckpt/BAGraph_base_hdim20_odim20/BA_graph_model_dict.pth'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.001,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0.0,\n",
       "  'amsgrad': False,\n",
       "  'params': [140253693376480,\n",
       "   140253693374608,\n",
       "   140253693376048,\n",
       "   140253693374824,\n",
       "   140253693374680,\n",
       "   140253762697256,\n",
       "   140253693722560,\n",
       "   140253693719752]}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = load_ckpt(prog_args)\n",
    "model_optimizer = model_dict['optimizer']\n",
    "model_optimizer.state_dict()['param_groups']\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in loaded model dictionary : ['epoch', 'model_type', 'optimizer', 'model_state', 'optimizer_state', 'cg']\n",
      "Keys in loaded model optimizer dictionary: ['state', 'param_groups']\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys in loaded model dictionary :\",list(model_dict))\n",
    "print(\"Keys in loaded model optimizer dictionary:\",list(model_optimizer.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        2, 2, 3, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['cg']['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for PyTorch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gnn-model-explainer/utils/io_utils.py\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda\n",
    "#prog_args.bn\n",
    "# Use `zero_division` parameter to control this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "## transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "## download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "## download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "#print(len(trainset))\n",
    "#print(trainset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 28x28x1 => 26x26x32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
    "        self.d2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # flatten => 32 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        #x = x.view(32, -1)\n",
    "\n",
    "        # 32 x (32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.ones((2,2))\n",
    "\n",
    "ta = torch.tensor(a, dtype=float).to('cuda:0')\n",
    "tb = torch.ones(2,2, dtype=float).to('cuda:0')\n",
    "\n",
    "print(ta)\n",
    "print(tb)\n",
    "print(ta @ tb) # dot product; element-wise product\n",
    "\n",
    "# This takes awhile for CUDA configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Current device : \", device)\n",
    "\n",
    "model = MyModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    ## training step\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ## forward + backprop + loss\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ## update model params\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += (torch.argmax(logits, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "    \n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "          %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += (torch.argmax(outputs, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "    preds = torch.argmax(outputs, 1).flatten().cpu().numpy()\n",
    "        \n",
    "print('Test Accuracy: %.2f'%(test_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, task='node'):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.task = task\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
    "        self.lns = nn.ModuleList()\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        for l in range(2):\n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        if not (self.task == 'node' or self.task == 'graph'):\n",
    "            raise RuntimeError('Unknown task.')\n",
    "\n",
    "        self.dropout = 0.25\n",
    "        self.num_layers = 3\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        if self.task == 'node':\n",
    "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        else:\n",
    "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                                  nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if data.num_node_features == 0:\n",
    "          x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            if not i == self.num_layers - 1:\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        if self.task == 'graph':\n",
    "            x = pyg_nn.global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        return emb, F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.lin_self = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Removes every self-loop in the graph given by edge_index\n",
    "        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n",
    "\n",
    "        # Transform node feature matrix.\n",
    "        self_x = self.lin_self(x)\n",
    "        #x = self.lin(x)\n",
    "\n",
    "        return self_x + self.propagate(edge_index, size=(x.size(0), x.size(0)), x=self.lin(x))\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index, size):\n",
    "        # Compute messages\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, task, writer):\n",
    "    if task == 'graph':\n",
    "        data_size = len(dataset)\n",
    "        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size=64, shuffle=True)\n",
    "        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size=64, shuffle=True)\n",
    "    else:\n",
    "        test_loader = loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes, task=task)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # train\n",
    "    for epoch in range(200):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            #print(batch.train_mask, '----')\n",
    "            opt.zero_grad()\n",
    "            embedding, pred = model(batch)\n",
    "            label = batch.y\n",
    "            if task == 'node':\n",
    "                pred = pred[batch.train_mask]\n",
    "                label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
    "                epoch, total_loss, test_acc))\n",
    "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, is_validation=False):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "\n",
    "        if model.task == 'node':\n",
    "            mask = data.val_mask if is_validation else data.test_mask\n",
    "            # node classification: only evaluate on nodes in test set\n",
    "            pred = pred[mask]\n",
    "            label = data.y[mask]\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "    \n",
    "    if model.task == 'graph':\n",
    "        total = len(loader.dataset) \n",
    "    else:\n",
    "        total = 0\n",
    "        for data in loader.dataset:\n",
    "            total += torch.sum(data.test_mask).item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip3 install tensorboardX\n",
    "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "#!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().system_raw(\n",
    "#    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "#    .format(\"./log\")\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().system_raw('./ngrok http 6006 &')\n",
    "#!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "#    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset = dataset.shuffle()\n",
    "task = 'graph'\n",
    "\n",
    "print(\"Dataset :\", dataset)\n",
    "print(\"Length of dataset :\", len(dataset))\n",
    "print(\"Number of classes in dataset :\", dataset.num_classes)\n",
    "print(\"Number of node featues in dataset :\", dataset.num_node_features)\n",
    "\n",
    "# Have access to all 600 graphs in the datase\n",
    "data = dataset[0]\n",
    "print(\"\\nDataset :\", data)\n",
    "print(\"\\nIs the graph undirected :\", data.is_undirected())\n",
    "\n",
    "# Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
    "# Data(edge_index=[2, 44], x=[12, 3], y=[1])\n",
    "# The first graph in the dataset contains 12 nodes, each one having 3 features.\n",
    "# There are 44/2 = 22 undirected edges and the graph is assigned to exactly one class.\n",
    "# In addition, the data object is holding exactly one graph-level target.\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]\n",
    "print(\"Accessing dataset [0-539] for training :\", train_dataset)\n",
    "print(\"Accessing dataset [540-599] for testing :\", test_dataset)\n",
    "\n",
    "dataset = dataset.shuffle()\n",
    "# Equivalent of the following\n",
    "# perm = torch.randperm(len(dataset))\n",
    "# dataset = dataset[perm]\n",
    "print(\"Shuffle dataset :\", dataset)\n",
    "\n",
    "# Train model\n",
    "print(\"\\n----------- Model Training -----------\")\n",
    "model = train(dataset, task, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "count = 1\n",
    "total_graphs = 0\n",
    "for data in loader:\n",
    "    # User batch to average node features in the node dimension for each graph individually\n",
    "    x = scatter_mean(data.x, data.batch, dim=0)\n",
    "    \n",
    "    if count == 1:\n",
    "        print(\"------------------------------ No. : \" + str(count) + \" ------------------------------\")\n",
    "        print(\"Batch :\\n\", data)\n",
    "        print(\"No. of batch graphs :\", data.num_graphs)\n",
    "        print(\"Size of mean x in batch :\\n\", x.size())  \n",
    "    count += 1\n",
    "    total_graphs += data.num_graphs\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Total no. of graphs in dataset :\", total_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch is a column vector which maps each node to its respective graph in the batch:\n",
    "data.to_data_list()[0] # ['edge_index'] gives the mapping of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = Planetoid(root='/tmp/cora', name='cora')\n",
    "task = 'node'\n",
    "\n",
    "print(\"Dataset :\\n\", dataset)\n",
    "print(\"Length of dataset :\", len(dataset))\n",
    "print(\"Number of classes in dataset :\", dataset.num_classes)\n",
    "print(\"Number of node featues in dataset :\", dataset.num_node_features)\n",
    "\n",
    "# Get a single, undirected citation graph from dataset\n",
    "data = dataset[0]\n",
    "print(\"\\nDataset :\\n\", data)\n",
    "print(\"Is single citation graph undirected :\", data.is_undirected())\n",
    "\n",
    "# data object holds a label for each node, and additional attributes :\n",
    "# train_mask denotes against which nodes to train (140 nodes)\n",
    "print(\"Number of items in train mask :\", data.train_mask.sum().item())\n",
    "# val_mask denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes)\n",
    "print(\"Number of items in val mask :\", data.val_mask.sum().item())\n",
    "# test_mask denotes against which nodes to test (1000 nodes)\n",
    "print(\"Number of items in test mask :\", data.test_mask.sum().item())\n",
    "\n",
    "# Train model\n",
    "print(\"\\n----------- Model Training -----------\")\n",
    "model = train(dataset, task, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"red\", \"orange\", \"green\", \"blue\", \"purple\", \"brown\",\n",
    "              \"black\", \"yellow\", \"grey\", \"cyan\", \"pink\", \"magenta\"]\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "embs = []\n",
    "colors = []\n",
    "for batch in loader:\n",
    "    emb, pred = model(batch)\n",
    "    embs.append(emb)\n",
    "    colors += [color_list[y] for y in batch.y]\n",
    "embs = torch.cat(embs, dim=0)\n",
    "\n",
    "xs, ys = zip(*TSNE().fit_transform(embs.detach().numpy()))\n",
    "\n",
    "plt.figure(figsize=(24, 20))\n",
    "plt.scatter(xs, ys, color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph methods\n",
    "-  Graph Neural Network (GCN) <br>\n",
    "(http://tkipf.github.io/graph-convolutional-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_node_features, dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# A two-layer GCN\n",
    "# Non-linearity is not integrated in the conv calls and hence needs to be applied afterwards\n",
    "# Use ReLU as our intermediate non-linearity between and finally output a softmax distribution\n",
    "# over the number of classes\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Net().to(device)\n",
    "print(\"Current device : \", device)\n",
    "\n",
    "# Get a single, undirected citation graph from dataset\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Explainer (pytorch_geometric/examples/gnn_explainer.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from pytorch_geometric/torch_geometric/nn/models/gnn_explainer.py\n",
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "class GNNExplainer(torch.nn.Module):\n",
    "    r\"\"\"The GNN-Explainer model from the `\"GNNExplainer: Generating\n",
    "    Explanations for Graph Neural Networks\"\n",
    "    <https://arxiv.org/abs/1903.03894>`_ paper for identifying compact subgraph\n",
    "    structures and small subsets node features that play a crucial role in a\n",
    "    GNNs node-predictions.\n",
    "    .. note::\n",
    "        For an example of using GNN-Explainer, see `examples/gnn_explainer.py\n",
    "        <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/\n",
    "        gnn_explainer.py>`_.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The GNN module to explain.\n",
    "        epochs (int, optional): The number of epochs to train.\n",
    "            (default: :obj:`100`)\n",
    "        lr (float, optional): The learning rate to apply.\n",
    "            (default: :obj:`0.01`)\n",
    "        log (bool, optional): If set to :obj:`False`, will not log any learning\n",
    "            progress. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    coeffs = {\n",
    "        'edge_size': 0.005,\n",
    "        'node_feat_size': 1.0,\n",
    "        'edge_ent': 1.0,\n",
    "        'node_feat_ent': 0.1,\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, epochs=100, lr=0.01, log=True):\n",
    "        super(GNNExplainer, self).__init__()\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.log = log\n",
    "\n",
    "    def __set_masks__(self, x, edge_index, init=\"normal\"):\n",
    "        (N, F), E = x.size(), edge_index.size(1)\n",
    "\n",
    "        std = 0.1\n",
    "        self.node_feat_mask = torch.nn.Parameter(torch.randn(F) * 0.1)\n",
    "\n",
    "        std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "        self.edge_mask = torch.nn.Parameter(torch.randn(E) * std)\n",
    "\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "\n",
    "    def __clear_masks__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.node_feat_masks = None\n",
    "        self.edge_mask = None\n",
    "\n",
    "    def __num_hops__(self):\n",
    "        num_hops = 0\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                num_hops += 1\n",
    "        return num_hops\n",
    "\n",
    "    def __flow__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def __subgraph__(self, node_idx, x, edge_index, **kwargs):\n",
    "        num_nodes, num_edges = x.size(0), edge_index.size(1)\n",
    "\n",
    "        subset, edge_index, edge_mask = k_hop_subgraph(\n",
    "            node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,\n",
    "            num_nodes=num_nodes, flow=self.__flow__())\n",
    "\n",
    "        x = x[subset]\n",
    "        for key, item in kwargs:\n",
    "            if torch.is_tensor(item) and item.size(0) == num_nodes:\n",
    "                item = item[subset]\n",
    "            elif torch.is_tensor(item) and item.size(0) == num_edges:\n",
    "                item = item[edge_mask]\n",
    "            kwargs[key] = item\n",
    "\n",
    "        return x, edge_index, edge_mask, kwargs\n",
    "\n",
    "    def __loss__(self, node_idx, log_logits, pred_label):\n",
    "        loss = -log_logits[node_idx, pred_label[node_idx]]\n",
    "\n",
    "        m = self.edge_mask.sigmoid()\n",
    "        loss = loss + self.coeffs['edge_size'] * m.sum()\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['edge_ent'] * ent.mean()\n",
    "\n",
    "        m = self.node_feat_mask.sigmoid()\n",
    "        loss = loss + self.coeffs['node_feat_size'] * m.sum()\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['node_feat_ent'] * ent.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def explain_node(self, node_idx, x, edge_index, **kwargs):\n",
    "        r\"\"\"Learns and returns a node feature mask and an edge mask that play a\n",
    "        crucial role to explain the prediction made by the GNN for node\n",
    "        :attr:`node_idx`.\n",
    "        Args:\n",
    "            node_idx (int): The node to explain.\n",
    "            x (Tensor): The node feature matrix.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            **kwargs (optional): Additional arguments passed to the GNN module.\n",
    "        :rtype: (:class:`Tensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        num_edges = edge_index.size(1)\n",
    "\n",
    "        # Only operate on a k-hop subgraph around `node_idx`.\n",
    "        x, edge_index, hard_edge_mask, kwargs = self.__subgraph__(\n",
    "            node_idx, x, edge_index, **kwargs)\n",
    "\n",
    "        # Get the initial prediction.\n",
    "        with torch.no_grad():\n",
    "            log_logits = self.model(x=x, edge_index=edge_index, **kwargs)\n",
    "            pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index)\n",
    "        self.to(x.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam([self.node_feat_mask, self.edge_mask],\n",
    "                                     lr=self.lr)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description(f'Explain node {node_idx}')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.view(1, -1).sigmoid()\n",
    "            log_logits = self.model(x=h, edge_index=edge_index, **kwargs)\n",
    "            loss = self.__loss__(0, log_logits, pred_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if self.log:  # pragma: no cover\n",
    "                pbar.update(1)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar.close()\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid()\n",
    "        edge_mask = self.edge_mask.new_zeros(num_edges)\n",
    "        edge_mask[hard_edge_mask] = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        return node_feat_mask, edge_mask\n",
    "\n",
    "    def visualize_subgraph(self, node_idx, edge_index, edge_mask, y=None,\n",
    "                           threshold=None, **kwargs):\n",
    "        r\"\"\"Visualizes the subgraph around :attr:`node_idx` given an edge mask\n",
    "        :attr:`edge_mask`.\n",
    "        Args:\n",
    "            node_idx (int): The node id to explain.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            edge_mask (Tensor): The edge mask.\n",
    "            y (Tensor, optional): The ground-truth node-prediction labels used\n",
    "                as node colorings. (default: :obj:`None`)\n",
    "            threshold (float, optional): Sets a threshold for visualizing\n",
    "                important edges. If set to :obj:`None`, will visualize all\n",
    "                edges with transparancy indicating the importance of edges.\n",
    "                (default: :obj:`None`)\n",
    "            **kwargs (optional): Additional arguments passed to\n",
    "                :func:`nx.draw`.\n",
    "        :rtype: :class:`matplotlib.pyplot`\n",
    "        \"\"\"\n",
    "\n",
    "        assert edge_mask.size(0) == edge_index.size(1)\n",
    "\n",
    "        # Only operate on a k-hop subgraph around `node_idx`.\n",
    "        subset, edge_index, hard_edge_mask = k_hop_subgraph(\n",
    "            node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,\n",
    "            num_nodes=None, flow=self.__flow__())\n",
    "\n",
    "        edge_mask = edge_mask[hard_edge_mask]\n",
    "\n",
    "        if threshold is not None:\n",
    "            edge_mask = (edge_mask >= threshold).to(torch.float)\n",
    "\n",
    "        if y is None:\n",
    "            y = torch.zeros(edge_index.max().item() + 1,\n",
    "                            device=edge_index.device)\n",
    "        else:\n",
    "            y = y[subset].to(torch.float) / y.max().item()\n",
    "\n",
    "        data = Data(edge_index=edge_index, att=edge_mask, y=y,\n",
    "                    num_nodes=y.size(0)).to('cpu')\n",
    "        G = to_networkx(data, node_attrs=['y'], edge_attrs=['att'])\n",
    "        mapping = {k: i for k, i in enumerate(subset.tolist())}\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        kwargs['with_labels'] = kwargs.get('with_labels') or True\n",
    "        kwargs['font_size'] = kwargs.get('font_size') or 10\n",
    "        kwargs['node_size'] = kwargs.get('node_size') or 800\n",
    "        kwargs['cmap'] = kwargs.get('cmap') or 'cool'\n",
    "\n",
    "        pos = nx.spring_layout(G)\n",
    "        ax = plt.gca()\n",
    "        for source, target, data in G.edges(data=True):\n",
    "            ax.annotate(\n",
    "                '', xy=pos[target], xycoords='data', xytext=pos[source],\n",
    "                textcoords='data', arrowprops=dict(\n",
    "                    arrowstyle=\"->\",\n",
    "                    alpha=max(data['att'], 0.1),\n",
    "                    shrinkA=sqrt(kwargs['node_size']) / 2.0,\n",
    "                    shrinkB=sqrt(kwargs['node_size']) / 2.0,\n",
    "                    connectionstyle=\"arc3,rad=0.1\",\n",
    "                ))\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=y.tolist(), **kwargs)\n",
    "        nx.draw_networkx_labels(G, pos, **kwargs)\n",
    "        plt.axis('off')\n",
    "        return plt\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from pytorch_geometric/torch_geometric/utils/subgraph.py\n",
    "def maybe_num_nodes(index, num_nodes=None):\n",
    "    return index.max().item() + 1 if num_nodes is None else num_nodes\n",
    "\n",
    "def k_hop_subgraph(node_idx, num_hops, edge_index, relabel_nodes=False,\n",
    "                   num_nodes=None, flow='source_to_target'):\n",
    "    r\"\"\"Computes the :math:`k`-hop subgraph of :obj:`edge_index` around node\n",
    "    :attr:`node_idx`.\n",
    "    It returns (1) the nodes involved in the subgraph, (2) the filtered\n",
    "    :obj`edge_index` connectivity, and (3) the edge mask indicating which edges\n",
    "    were preserved.\n",
    "    Args:\n",
    "        node_idx (int): The central node.\n",
    "        num_hops: (int): The number of hops :math:`k`.\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting\n",
    "            :obj:`edge_index` will be relabeled to hold consecutive indices\n",
    "            starting from zero. (default: :obj:`False`)\n",
    "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
    "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
    "        flow (string, optional): The flow direction of :math:`k`-hop\n",
    "            aggregation (:obj:`\"source_to_target\"` or\n",
    "            :obj:`\"target_to_source\"`). (default: :obj:`\"source_to_target\"`)\n",
    "    :rtype: (:class:`LongTensor`, :class:`LongTensor`, :class:`BoolTensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    subsets = [torch.tensor([node_idx], device=row.device).flatten()]\n",
    "    for _ in range(num_hops):\n",
    "        node_mask.fill_(False)\n",
    "        node_mask[subsets[-1]] = True\n",
    "        torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "        subsets.append(col[edge_mask])\n",
    "    subset = torch.cat(subsets).unique()\n",
    "    # Add `node_idx` to the beginning of `subset`.\n",
    "    subset = subset[subset != node_idx]\n",
    "    subset = torch.cat([torch.tensor([node_idx], device=row.device), subset])\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes, ), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Sequential, Linear\n",
    "\n",
    "dataset = 'Cora'\n",
    "path = '/tmp/cora'\n",
    "\n",
    "dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "\n",
    "# Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n",
    "data = dataset[0]\n",
    "print(\"Data before sent to device :\\n\", data)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin = Sequential(Linear(10, 10))\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device : \", device)\n",
    "\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "print(\"Data to device :\\n\", data)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "x, edge_index = data.x, data.edge_index\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    log_logits = model(x, edge_index)\n",
    "    loss = F.nll_loss(log_logits[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "explainer = GNNExplainer(model, epochs=200)\n",
    "node_idx = 10\n",
    "node_feat_mask, edge_mask = explainer.explain_node(node_idx, x, edge_index)\n",
    "plt = explainer.visualize_subgraph(node_idx, edge_index, edge_mask, y=data.y)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder for unsupervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = pyg_nn.GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "def unsupervised_train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    writer.add_scalar(\"loss\", loss.item(), epoch)\n",
    "\n",
    "def unsupervised_test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = Planetoid(\"/tmp/citeseer\", \"Citeseer\", T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "channels = 16\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA availability:', torch.cuda.is_available())\n",
    "\n",
    "# encoder: written by us; decoder: default (inner product)\n",
    "model = pyg_nn.GAE(Encoder(dataset.num_features, channels)).to(dev)\n",
    "labels = data.y\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "\n",
    "#data = model.split_edges(data)\n",
    "data = pyg_utils.train_test_split_edges(data)\n",
    "\n",
    "x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    unsupervised_train(epoch)\n",
    "    auc, ap = unsupervised_test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    writer.add_scalar(\"AUC\", auc, epoch)\n",
    "    writer.add_scalar(\"AP\", ap, epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z = model.encode(x, train_pos_edge_index)\n",
    "colors = [color_list[y] for y in labels]\n",
    "\n",
    "xs, ys = zip(*TSNE().fit_transform(z.cpu().detach().numpy()))\n",
    "\n",
    "plt.figure(figsize=(24, 20))\n",
    "plt.scatter(xs, ys, color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
