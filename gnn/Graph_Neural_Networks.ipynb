{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup in GCP\n",
    "- apt-get --purge remove \"cublas\" \"cuda*\"\n",
    "- reboot\n",
    "- sudo curl -O http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
    "- sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
    "- sudo apt-get install cuda-10-1\n",
    "- pip3 install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
    "- pip3 install torch-geometric\n",
    "\n",
    "** Both the PyTorch and torch_sparse CUDA version must matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import torch; print(torch.version.cuda)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.243\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer parameters\n",
    "def parse_optimizer(parser):\n",
    "    opt_parser = parser.add_argument_group()\n",
    "    opt_parser.add_argument('--opt', dest='opt', type=str,\n",
    "                            help='Type of optimizer')\n",
    "    opt_parser.add_argument('--opt-scheduler', dest='opt_scheduler', type=str,\n",
    "                            help='Type of optimizer scheduler. By default none')\n",
    "    opt_parser.add_argument('--opt-restart', dest='opt_restart', type=int,\n",
    "                            help='Number of epochs before restart (by default set to 0 which means no restart)')\n",
    "    opt_parser.add_argument('--opt-decay-step', dest='opt_decay_step', type=int,\n",
    "                            help='Number of epochs before decay')\n",
    "    opt_parser.add_argument('--opt-decay-rate', dest='opt_decay_rate', type=float,\n",
    "                            help='Learning rate decay ratio')\n",
    "    opt_parser.add_argument('--lr', dest='lr', type=float,\n",
    "                            help='Learning rate.')\n",
    "    opt_parser.add_argument('--clip', dest='clip', type=float,\n",
    "                            help='Gradient clipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all required arguments\n",
    "class gnn_args:\n",
    "    def __init__(self):\n",
    "        self.datadir = \"data\"        # Directory where benchmark is stored (io_parser)\n",
    "        self.logdir = \"log\"          # Tensorboard log directory\n",
    "        self.ckptdir = \"ckpt\"        # Model checkpoint directory\n",
    "        self.dataset = \"BAGraph\"     # Synthetic dataset, syn1\n",
    "        self.opt = \"adam\"            # opt_parser\n",
    "        self.opt_scheduler = \"none\"  # Optimizer scheduler\n",
    "        self.max_nodes = 100         # Maximum number of nodes\n",
    "                                     # (ignore graphs with nodes exceeding the number)\n",
    "        self.cuda = \"0\"              # CUDA value\n",
    "        self.feature_type = \"default\"# Feature used for encoder with possible values : id, deg\n",
    "        self.lr = 0.001              # Learning rate\n",
    "        self.clip = 2.0\n",
    "        \n",
    "        self.batch_size = 20         # Batch size\n",
    "        self.num_epochs = 1000       # Number of epochs to train data\n",
    "        self.train_ratio = 0.8       # Ratio of number of training set to all graphs\n",
    "        self.test_ratio = 0.1\n",
    "        self.num_workers = 1         # Number of workers to load data\n",
    "        self.input_dim = 10          # Input feature dimension\n",
    "        self.hidden_dim = 20         # Hidden layer dimension\n",
    "        self.output_dim = 20         # Output layer dimension\n",
    "        self.num_classes = 2         # Number of label classes\n",
    "        self.num_gc_layers = 3       # Number of graph convolution layers before each pooling\n",
    "        \n",
    "        self.dropout = 0.0           # Dropout rate\n",
    "        self.weight_decay = 0.005    # Weight decay regularization constant\n",
    "        self.method = \"base\"         # Method used with possible values : base\n",
    "        self.name_suffix = \"\"        # Suffix added to the output filename\n",
    "        self.assign_ratio = 0.1      # Ratio of number of nodes in consecutive layers\n",
    "        \n",
    "        self.bias = True             # \"Whether to add bias\n",
    "        \n",
    "        self.gpu = False             # Whether to use GPU\n",
    "        self.linkpred = False        # Whether link prediction side objective is used\n",
    "        self.bn = False              # Whether batch normalization is used\n",
    "        self.bmname = None           # Name of the benchmark datase\n",
    "        \n",
    "        # Parameters for explaining ndoe predictions\n",
    "        self.explainer_suffix=\"\"\n",
    "        self.explain_node = None\n",
    "        self.graph_idx=-1\n",
    "        self.mask_act=\"sigmoid\"\n",
    "        self.multigraph_class=-1\n",
    "        \n",
    "        self.graph_mode = False\n",
    "        self.mask_bias = False\n",
    "\n",
    "# Global variables\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "SUBGRAPH_FOLDER = \"explainSubgraphs\"\n",
    "\n",
    "prog_args = gnn_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start with these parsed program arguments :\n",
      " <__main__.gnn_args object at 0x7f19e4ae9f60>\n",
      "Values in Constant Feature Generator :  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Constant feature generator :  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "------ Building the Synthetic BA graph with 'House' motifs ------\n",
      "Role Id of the BA graph :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Indicator of the id of the next node : 20\n",
      "Number of nodes in the BA graph :  20\n",
      "Number of motifs :  3\n",
      "List of shapes : [['house'], ['house'], ['house']]\n",
      "No. of shapes : 3\n",
      "Spacing :  6\n",
      "Plugins :  [0, 6, 12]\n",
      "seen_shapes :  {'basis': [0, 20]}\n",
      "\n",
      "-----------------------------------------\n",
      "Shape_ID : 0 with shape type : house\n",
      "1 shapes with list of Shape : ['house']\n",
      "The shape starts from index 1 :  []\n",
      "\n",
      "The list of arguments : [20, 0]\n",
      "The first item in list of arguments : 20\n",
      "The second item in list of arguments : 0\n",
      "Column start : 1\n",
      "Observe seen_shapes :  {'basis': [0, 20], 'house': [1, 5]}\n",
      "Labels of BA graph with attached motifs :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3]\n",
      "No. of nodes in attached graph :  25\n",
      "With attached motif nodes, index starts from :  25\n",
      "\n",
      "-----------------------------------------\n",
      "Shape_ID : 1 with shape type : house\n",
      "1 shapes with list of Shape : ['house']\n",
      "The shape starts from index 1 :  []\n",
      "\n",
      "The list of arguments : [25, 0]\n",
      "The first item in list of arguments : 25\n",
      "The second item in list of arguments : 0\n",
      "Column start : 1\n",
      "Observe seen_shapes :  {'basis': [0, 20], 'house': [1, 5]}\n",
      "Labels of BA graph with attached motifs :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3]\n",
      "No. of nodes in attached graph :  30\n",
      "With attached motif nodes, index starts from :  30\n",
      "\n",
      "-----------------------------------------\n",
      "Shape_ID : 2 with shape type : house\n",
      "1 shapes with list of Shape : ['house']\n",
      "The shape starts from index 1 :  []\n",
      "\n",
      "The list of arguments : [30, 0]\n",
      "The first item in list of arguments : 30\n",
      "The second item in list of arguments : 0\n",
      "Column start : 1\n",
      "Observe seen_shapes :  {'basis': [0, 20], 'house': [1, 5]}\n",
      "Labels of BA graph with attached motifs :\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3]\n",
      "No. of nodes in attached graph :  35\n",
      "With attached motif nodes, index starts from :  35\n",
      "\n",
      "Information of the motif graph :\n",
      " Name: \n",
      "Type: Graph\n",
      "Number of nodes: 5\n",
      "Number of edges: 6\n",
      "Average degree:   2.4000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate node features for 35 nodes.\n",
      "Values of feat_dict[0][\"feat\"]: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Node attributes of node '0', G.nodes[0][\"feat\"]: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "------ Generated the Synthetic BA graph with 'House' motifs ------\n",
      "Name of generated graph : ba_20_3\n",
      "------------ GCNEncoderNode Model ------------\n",
      "Input dimensions : 10\n",
      "Hidden dimensions : 20\n",
      "Output dimensions : 20\n",
      "Number of classes in args : 4\n",
      "Number of GCN layers : 3\n",
      "Method :  base\n",
      "*** Check received batch_size argument : 20\n",
      "*** Batch normalization from caller (default : False) : False\n",
      "GcnEncoderNode model :\n",
      " GcnEncoderNode(\n",
      "  (conv_first): GraphConv()\n",
      "  (conv_block): ModuleList(\n",
      "    (0): GraphConv()\n",
      "  )\n",
      "  (conv_last): GraphConv()\n",
      "  (act): ReLU()\n",
      "  (pred_model): Linear(in_features=60, out_features=4, bias=True)\n",
      "  (celoss): CrossEntropyLoss()\n",
      ")\n",
      "------ Preprocess Input graph ------\n",
      "The shape of the adjacency matrix ('dxd') of input graph : (35, 35)\n",
      "Feature dimensions of the last node '34' : 10\n",
      "The shape of the adjacency matrix after expansion : (1, 35, 35)\n",
      "The shape of the features matrix after expansion : (1, 35, 10)\n",
      "The shape of the labels matrix after expansion : (1, 35)\n",
      "epoch:  0 ; loss:  1.4326508045196533 ; train_acc:  0.17857142857142858 ; test_acc:  0.14285714285714285 ; train_prec:  0.044642857142857144 ; test_prec:  0.047619047619047616 ; epoch time:  0.02\n",
      "epoch:  10 ; loss:  1.37400221824646 ; train_acc:  0.17857142857142858 ; test_acc:  0.14285714285714285 ; train_prec:  0.044642857142857144 ; test_prec:  0.047619047619047616 ; epoch time:  0.00\n",
      "epoch:  20 ; loss:  1.3205691576004028 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  30 ; loss:  1.2730048894882202 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n",
      "epoch:  40 ; loss:  1.234095573425293 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n",
      "epoch:  50 ; loss:  1.2067748308181763 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n",
      "epoch:  60 ; loss:  1.1879862546920776 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n",
      "epoch:  70 ; loss:  1.173762321472168 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n",
      "epoch:  80 ; loss:  1.1576004028320312 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n",
      "epoch:  90 ; loss:  1.1294547319412231 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n",
      "epoch:  100 ; loss:  1.0679856538772583 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n",
      "epoch:  110 ; loss:  0.9528407454490662 ; train_acc:  0.5357142857142857 ; test_acc:  0.7142857142857143 ; train_prec:  0.13392857142857142 ; test_prec:  0.2380952380952381 ; epoch time:  0.00\n",
      "epoch:  120 ; loss:  0.8288412094116211 ; train_acc:  0.8928571428571429 ; test_acc:  1.0 ; train_prec:  0.636904761904762 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  130 ; loss:  0.7479225993156433 ; train_acc:  0.8214285714285714 ; test_acc:  0.8571428571428571 ; train_prec:  0.625 ; test_prec:  0.5 ; epoch time:  0.00\n",
      "epoch:  140 ; loss:  0.685864269733429 ; train_acc:  0.8214285714285714 ; test_acc:  0.8571428571428571 ; train_prec:  0.625 ; test_prec:  0.5 ; epoch time:  0.00\n",
      "epoch:  150 ; loss:  0.6382390260696411 ; train_acc:  0.8928571428571429 ; test_acc:  1.0 ; train_prec:  0.65625 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  160 ; loss:  0.591508686542511 ; train_acc:  0.8928571428571429 ; test_acc:  1.0 ; train_prec:  0.65625 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  170 ; loss:  0.546737015247345 ; train_acc:  0.8928571428571429 ; test_acc:  1.0 ; train_prec:  0.65625 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  180 ; loss:  0.5021042823791504 ; train_acc:  0.8928571428571429 ; test_acc:  1.0 ; train_prec:  0.65625 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  190 ; loss:  0.46013155579566956 ; train_acc:  0.8928571428571429 ; test_acc:  1.0 ; train_prec:  0.65625 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  200 ; loss:  0.42579129338264465 ; train_acc:  0.8928571428571429 ; test_acc:  1.0 ; train_prec:  0.65625 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  210 ; loss:  0.3957742154598236 ; train_acc:  0.8928571428571429 ; test_acc:  1.0 ; train_prec:  0.65625 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  220 ; loss:  0.36762896180152893 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  230 ; loss:  0.34232810139656067 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  240 ; loss:  0.3191375732421875 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  250 ; loss:  0.2979947626590729 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  260 ; loss:  0.2787748873233795 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  270 ; loss:  0.2620331645011902 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  280 ; loss:  0.24619193375110626 ; train_acc:  1.0 ; test_acc:  1.0 ; train_prec:  1.0 ; test_prec:  1.0 ; epoch time:  0.00\n",
      "epoch:  290 ; loss:  0.23132875561714172 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samDev/ml/VirtualEnv/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  300 ; loss:  0.21850009262561798 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  310 ; loss:  0.20626404881477356 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  320 ; loss:  0.19548027217388153 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  330 ; loss:  0.18524549901485443 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  340 ; loss:  0.17582984268665314 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  350 ; loss:  0.16706274449825287 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  360 ; loss:  0.15959322452545166 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  370 ; loss:  0.15175452828407288 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  380 ; loss:  0.14484573900699615 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  390 ; loss:  0.13881976902484894 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  400 ; loss:  0.1323559433221817 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  410 ; loss:  0.12674103677272797 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  420 ; loss:  0.12134858220815659 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  430 ; loss:  0.1167222335934639 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  440 ; loss:  0.11174916476011276 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  450 ; loss:  0.10729708522558212 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  460 ; loss:  0.10321000963449478 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  470 ; loss:  0.0993046686053276 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  480 ; loss:  0.09562404453754425 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  490 ; loss:  0.0921136885881424 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  500 ; loss:  0.08899511396884918 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  510 ; loss:  0.0857347771525383 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  520 ; loss:  0.08282708376646042 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  530 ; loss:  0.07989431172609329 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  540 ; loss:  0.07712077349424362 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  550 ; loss:  0.07476789504289627 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  560 ; loss:  0.07238683849573135 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  570 ; loss:  0.06989208608865738 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  580 ; loss:  0.06783150136470795 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  590 ; loss:  0.0653751939535141 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  600 ; loss:  0.06330058723688126 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  610 ; loss:  0.061371058225631714 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  620 ; loss:  0.05949689820408821 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  630 ; loss:  0.05783718824386597 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  640 ; loss:  0.05620104447007179 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.75 ; epoch time:  0.00\n",
      "epoch:  650 ; loss:  0.054445017129182816 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.8333333333333334 ; epoch time:  0.00\n",
      "epoch:  660 ; loss:  0.053036920726299286 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.8333333333333334 ; epoch time:  0.00\n",
      "epoch:  670 ; loss:  0.051440443843603134 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.8333333333333334 ; epoch time:  0.00\n",
      "epoch:  680 ; loss:  0.05005526915192604 ; train_acc:  1.0 ; test_acc:  0.8571428571428571 ; train_prec:  1.0 ; test_prec:  0.8333333333333334 ; epoch time:  0.00\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "\n",
    "# Running from Jupyter notebook will bypass main() in train.py\n",
    "model = train.syn_task1(prog_args, writer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "# Print optimizer's state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optimizer.state_dict():\n",
    "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading previously saved computational graph data and explain node prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.io_utils as io_utils\n",
    "\n",
    "# Loading previously saved computational graph data (model checkpoint)\n",
    "model_dict = io_utils.load_ckpt(prog_args)\n",
    "model_optimizer = model_dict['optimizer']\n",
    "\n",
    "print(\"Model optimizer :\", model_optimizer)\n",
    "print(\"Model optimizer state dictionary :\\n\", model_optimizer.state_dict()['param_groups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_dict = model_dict['cg']\n",
    "\n",
    "# Create explainer\n",
    "from explainer import explain    \n",
    "explainer = explain.Explainer(\n",
    "    model=model,\n",
    "    adj=cg_dict[\"adj\"],\n",
    "    feat=cg_dict[\"feat\"],\n",
    "    label=cg_dict[\"label\"],\n",
    "    pred=cg_dict[\"pred\"],\n",
    "    train_idx=cg_dict[\"train_idx\"],\n",
    "    args=prog_args,\n",
    "    writer=None, # writer\n",
    "    print_training=True,\n",
    "    graph_mode=False,\n",
    "    graph_idx=prog_args.graph_idx,\n",
    ")\n",
    "\n",
    "# The number of epochs used for explanation training is much smaller than the 1K epochs used for node label\n",
    "# trainings and predictions in the GCN.  The former is trained only based on the k-hop labels which depends\n",
    "# on the number GCN layers (at a smaller scale, so the number of epochs can be lower without reducing the\n",
    "# accuracy). Whereas, the latter will affect the node predictions and thus, it will affect the accuracy of\n",
    "# the node explanations.\n",
    "prog_args.num_epochs = 100\n",
    "\n",
    "# Explain node prediction\n",
    "prog_args.explain_node = 25\n",
    "\n",
    "# Returned masked adjacency, edges and features of the subgraph\n",
    "masked_adj, masked_edges, masked_features = explainer.explain(prog_args.explain_node, unconstrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_args.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked_edges = explainerMod.mask.cpu().detach().numpy()\n",
    "#masked_features = explainerMod.feat_mask.cpu().detach().numpy()\n",
    "# explainerMod.mask.shape, masked_edges.shape, explainerMod.feat_mask.shape, masked_features.shape\n",
    "print(\"Returned masked adjacency matrix :\\n\", masked_adj)\n",
    "print(\"Returned masked edges matrix :\\n\", masked_edges)\n",
    "print(\"Returned masked features matrix :\\n\", masked_features)\n",
    "\n",
    "# ypred_detach = ypred.cpu().detach().numpy()\n",
    "# ypred_node = np.argmax(ypred_detach, axis=0) # labels\n",
    "# ypred = tensor([0.0119, 0.6456, 0.3307, 0.0118]\n",
    "# ypred, ypred_detach, ypred_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "coeffs = {\n",
    "    \"size\": 0.005,\n",
    "    \"feat_size\": 1.0,\n",
    "    \"ent\": 1.0,\n",
    "    \"feat_ent\": 0.1,\n",
    "    \"grad\": 0,\n",
    "    \"lap\": 1.0,\n",
    "}\n",
    "\n",
    "\n",
    "class Explainer:\n",
    "    def __init__(self, model, node_features, node_labels, edge_index=None, adj_matrix=None, edge_weight=None, adj_mode=True):\n",
    "        self.adj_mode = adj_mode\n",
    "        self.GNN_model = model\n",
    "        # self.data = data\n",
    "        self.node_features = np.asarray(node_features).squeeze()\n",
    "        self.labels = np.asarray(node_labels).squeeze()\n",
    "        self.num_nodes = np.size(self.node_features, 0)\n",
    "        self.edge_index = np.asarray(edge_index) if edge_index is not None else None\n",
    "        self.adj_matrix = np.asarray(adj_matrix).squeeze() if adj_matrix is not None else self.GenerateAdjacentMatrix()\n",
    "        self.neighbours = self.Generate_k_hop_Neighbours()\n",
    "\n",
    "    def GenerateAdjacentMatrix(self):\n",
    "        edge_index = self.edge_index\n",
    "        zeros = np.zeros((self.num_nodes, self.num_nodes))\n",
    "        for i in range(np.size(edge_index, 1)):\n",
    "            u = edge_index[0][i]\n",
    "            v = edge_index[1][i]\n",
    "            zeros[u][v] = 1\n",
    "        adj_matrix = zeros.copy()\n",
    "        return adj_matrix\n",
    "\n",
    "    def Generate_k_hop_Neighbours(self):\n",
    "        # walking from node to other nodes, maximum distance == n_hops (number of layers in GNN)\n",
    "        num_modules = 0\n",
    "        for _, _ in enumerate(self.GNN_model.modules()):\n",
    "            num_modules += 1\n",
    "        n_hops = 3\n",
    "        print('n_hops:', n_hops)\n",
    "        adj = torch.tensor(self.adj_matrix, dtype=float)\n",
    "        diag_mask = torch.ones(adj.shape[0], adj.shape[0]) - torch.eye(adj.shape[0])\n",
    "        adj = adj * diag_mask\n",
    "        hop_adj = pow_adj = adj\n",
    "        # find all the nodes that can be reached within n_hops fromm node_idx\n",
    "        print('adj.shape:',adj.shape)\n",
    "        print('adj:\\n',adj)\n",
    "        for i in range(n_hops-1):\n",
    "            pow_adj = pow_adj @ adj\n",
    "            hop_adj = hop_adj + pow_adj\n",
    "            # reset all values to one\n",
    "            hop_adj = (hop_adj > 0).float()\n",
    "\n",
    "        return hop_adj.cpu().numpy().astype(int)\n",
    "\n",
    "    def ExtractNeighbours(self, node_idx):\n",
    "        # neighbourhoods consisting of nbhs that can be reached within k_hops\n",
    "        print('self.neighbours.shape:',self.neighbours.shape)\n",
    "        neighbours = self.neighbours[node_idx]\n",
    "        num_of_nbhs = sum(neighbours)\n",
    "\n",
    "        new_node_idx_sub_adj = sum(neighbours[:node_idx])\n",
    "\n",
    "        # np.nonzero(nbh_indices)[1] returns the value type\n",
    "        nbh_indices = np.nonzero(neighbours)[0]\n",
    "        print('nbh_indices:', nbh_indices)\n",
    "\n",
    "        sub_node_feat = self.node_features[nbh_indices]\n",
    "\n",
    "        sub_labels = self.labels[nbh_indices]\n",
    "\n",
    "\n",
    "        sub_edge_index = []\n",
    "        if self.edge_index is not None:\n",
    "            u,v = self.edge_index\n",
    "            sub_edge_index = []\n",
    "            for i in len(u):\n",
    "                if u[i] in nbh_indices and v[i] in nbh_indices:\n",
    "                    sub_edge_index.append((u[i],v[i]))\n",
    "\n",
    "        # return ONLY matrix of nbhs of node_idx and their nbhs that are the nbhs of the node_idx\n",
    "        # computation matrix for GNNExplainer\n",
    "        sub_adj_matrix = self.adj_matrix[nbh_indices][:, nbh_indices]\n",
    "\n",
    "        return new_node_idx_sub_adj, sub_adj_matrix, sub_node_feat, \\\n",
    "               sub_labels, sub_edge_index, nbh_indices\n",
    "\n",
    "    def ExplainNode(self, node_idx, epochs=None):\n",
    "        print()\n",
    "        if epochs is None:\n",
    "            epochs = 200\n",
    "        # Find nbhs of node_idx\n",
    "        new_node_idx_sub_adj, sub_adj_matrix, sub_node_features, \\\n",
    "        sub_labels, sub_edge_index, nbh_indices = self.ExtractNeighbours(node_idx)\n",
    "\n",
    "        sub_node_features = np.expand_dims(sub_node_features, axis=0)\n",
    "        sub_adj_matrix =  np.expand_dims(sub_adj_matrix, axis=0)\n",
    "\n",
    "        x_features = torch.tensor(sub_node_features, dtype=torch.float)\n",
    "        computation_graph = torch.tensor(sub_adj_matrix, requires_grad=True, dtype=torch.float)\n",
    "        sub_labels = torch.tensor(sub_labels, dtype=torch.long)\n",
    "\n",
    "        # Create GNNExplainer Model\n",
    "        gnn_explainer = ExplainModule(computation_graph, x_features,\n",
    "                                      sub_labels, sub_edge_index,\n",
    "                                      new_node_idx_sub_adj, self.GNN_model,\n",
    "                                      adj_mode=self.adj_mode)\n",
    "\n",
    "        # evaluate the GNN_model\n",
    "        self.GNN_model.eval()\n",
    "        gnn_explainer.train()\n",
    "\n",
    "        # Get the predicted label from the GNN Model\n",
    "        # based on the computation graph and sub features selected\n",
    "        print('computation_graph.shape:',computation_graph.shape)\n",
    "        print('x_features.shape:',x_features.shape)\n",
    "        model_ypred, _ = self.GNN_model(x_features, computation_graph)\n",
    "        model_ypred = model_ypred.cpu().detach().numpy()\n",
    "        model_ypred = np.squeeze(model_ypred)\n",
    "        model_ypred_label = np.argmax(model_ypred, axis=1)[new_node_idx_sub_adj]\n",
    "        print('GNN_Model labels node {} as {}\\n'\n",
    "              'Now GNN_Model predicts the node {} as {} based on the computation graph and the node features'\n",
    "              .format(node_idx, self.labels[node_idx], node_idx, model_ypred_label))\n",
    "        compare = [self.labels[node_idx], model_ypred_label]\n",
    "\n",
    "        prev_ypred = None\n",
    "        for epoch in range(epochs):\n",
    "            gnn_explainer.zero_grad()\n",
    "            gnn_explainer.optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # use GNN_model predict the label after masking\n",
    "            # ypred is a 1D tensor of the pred for each label for node_idx\n",
    "            # node_feat is a 1D tensor of the node_idx features\n",
    "            ypred, node_feat = gnn_explainer(new_node_idx_sub_adj)\n",
    "\n",
    "            loss = gnn_explainer.loss(ypred, self.labels[node_idx], new_node_idx_sub_adj)\n",
    "            loss.backward()\n",
    "            gnn_explainer.optimizer.step()\n",
    "\n",
    "            # print('Epoch: {}, loss: {}, ypred: {}'.format(epoch, loss, ypred))\n",
    "\n",
    "            # if prev_ypred is not None:\n",
    "            #     if ypred[model_ypred_label] > 0.98 \\\n",
    "            #             and ypred[model_ypred_label] - prev_ypred[model_ypred_label] <= 0.0001:\n",
    "            #         print('difference: ',ypred[model_ypred_label] - prev_ypred[model_ypred_label])\n",
    "            #         break\n",
    "            prev_ypred = ypred\n",
    "\n",
    "        masked_edges = gnn_explainer.edge_mask.cpu().detach().numpy()\n",
    "        masked_feat = gnn_explainer.node_feat_mask.cpu().detach().numpy()\n",
    "        ypred = ypred.cpu().detach().numpy()\n",
    "        labels = np.argmax(ypred, axis=0)\n",
    "\n",
    "        masked_adj = gnn_explainer.masked_adj.cpu().detach().numpy().squeeze() \\\n",
    "                         * sub_adj_matrix.squeeze()\n",
    "\n",
    "        print('sub_adj_matrix: {}, masked_edges: {}, sub_node_features: {}'\n",
    "              .format(sub_adj_matrix.shape, masked_edges.shape, sub_node_features.squeeze().shape))\n",
    "\n",
    "        self.PlotSubGraph(masked_adj, masked_edges,\n",
    "                          sub_edge_index, new_node_idx_sub_adj, node_idx,\n",
    "                          feats=sub_node_features.squeeze(), labels=sub_labels.cpu().detach().numpy().squeeze(),\n",
    "                          threshold_num=12, adj_mode=self.adj_mode)\n",
    "        return masked_edges, masked_feat, compare\n",
    "\n",
    "    # Different variable names from python file codes\n",
    "    # new_node_idx_sub_adj = node_idx_new\n",
    "    # sub_adj_matrix = sub_adj\n",
    "    # sub_node_features = sub_feat\n",
    "    # sub_edge_index = ?\n",
    "    # nbh_indices = neighbors\n",
    "\n",
    "    # x_features = tensor_x\n",
    "    # computation_graph = tensor_adj\n",
    "    # sub_labels = tensor_label\n",
    "    ##\n",
    "    def PlotSubGraph(self, adj, masked_edges, edge_index, new_node_idx, node_idx, feats=None, labels=None, threshold_num=None, adj_mode=True):\n",
    "        G = nx.Graph()\n",
    "        G1 = nx.Graph()\n",
    "\n",
    "        weighted_edge_list = []\n",
    "        weighted_edge_list1 = []\n",
    "        if threshold_num is not None:\n",
    "            if adj_mode:\n",
    "                # this is for symmetric graphs: edges are repeated twice in adj\n",
    "                adj_threshold_num = threshold_num * 2\n",
    "                neigh_size = len(adj[adj > 0])\n",
    "                threshold_num = min(neigh_size, adj_threshold_num)\n",
    "                # sort in ascending and retrieve last threshold_num from the back\n",
    "                threshold = np.sort(adj[adj > 0])[-threshold_num]\n",
    "\n",
    "                num_nodes = len(adj[0])\n",
    "                weighted_edge_list = [\n",
    "                    (i, j, adj[i, j])\n",
    "                    for i in range(num_nodes)\n",
    "                    for j in range(num_nodes)\n",
    "                    # if adj[i, j] >= threshold\n",
    "                    if adj[i,j] > 0\n",
    "                ]\n",
    "\n",
    "                weighted_edge_list1 = [\n",
    "                    (i, j, adj[i, j])\n",
    "                    for i in range(num_nodes)\n",
    "                    for j in range(num_nodes)\n",
    "                    if adj[i, j] >= threshold\n",
    "                ]\n",
    "            else:\n",
    "                threshold = np.sort(masked_edges)[-threshold_num]\n",
    "                row, col = edge_index\n",
    "\n",
    "                for i in range(len(row)):\n",
    "                    if masked_edges[i] >= threshold:\n",
    "                        weighted_edge_list.append((row[i], col[i], masked_edges[i]))\n",
    "\n",
    "\n",
    "        G.add_weighted_edges_from(weighted_edge_list)\n",
    "\n",
    "        G1.add_weighted_edges_from(weighted_edge_list1)\n",
    "\n",
    "        if feats is not None:\n",
    "            for node in G.nodes():\n",
    "                G.nodes[node][\"feat\"] = feats[node]\n",
    "            for node in G1.nodes():\n",
    "                G1.nodes[node][\"feat\"] = feats[node]\n",
    "\n",
    "        node_labels = {}\n",
    "        node_labels1 = {}\n",
    "        if labels is not None:\n",
    "            for node in G.nodes():\n",
    "                G.nodes[node][\"label\"] = labels[node]\n",
    "                node_labels.update({node: labels[node]})\n",
    "            for node in G1.nodes():\n",
    "                G1.nodes[node][\"label\"] = labels[node]\n",
    "                node_labels1.update({node: labels[node]})\n",
    "\n",
    "        node_color = []\n",
    "        for node in G.nodes.data():\n",
    "            if node[0] == new_node_idx:\n",
    "                node_color.append('green')\n",
    "            else:\n",
    "                node_color.append('lightgrey')\n",
    "\n",
    "        node_color1 = []\n",
    "        for node in G1.nodes.data():\n",
    "            if node[0] == new_node_idx:\n",
    "                node_color1.append('orange')\n",
    "            else:\n",
    "                node_color1.append('grey')\n",
    "\n",
    "\n",
    "        edge_colors = [w for (u, v, w) in G.edges.data(\"weight\", default=1)]\n",
    "        edge_vmax = statistics.median_high(\n",
    "            [d for (u, v, d) in G.edges(data=\"weight\", default=1)]\n",
    "        )\n",
    "        min_color = min([d for (u, v, d) in G.edges(data=\"weight\", default=1)])\n",
    "        # color range: gray to black\n",
    "        edge_vmin = 2 * min_color - edge_vmax\n",
    "\n",
    "        edge_colors1 = [w for (u, v, w) in G1.edges.data(\"weight\", default=1)]\n",
    "        edge_vmax1 = statistics.median_high(\n",
    "            [d for (u, v, d) in G1.edges(data=\"weight\", default=1)]\n",
    "        )\n",
    "        min_color1 = min([d for (u, v, d) in G1.edges(data=\"weight\", default=1)])\n",
    "        # color range: gray to black\n",
    "        edge_vmin1 = 2 * min_color1 - edge_vmax1\n",
    "\n",
    "        #plt.close()\n",
    "        plt.figure()\n",
    "        pos = nx.spring_layout(G, k=0.5)\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=node_color)\n",
    "        nx.draw_networkx_edges(G, pos, edge_color=edge_colors, edge_cmap=plt.get_cmap(\"Greys\"),\n",
    "                               edge_vmin=edge_vmin, edge_vmax=edge_vmax)\n",
    "        nx.draw_networkx_labels(G, pos, labels=node_labels)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Create subdirectory if does not already exist\n",
    "        data_path = os.path.join(PROJECT_ROOT_DIR, SUBGRAPH_FOLDER)\n",
    "        if not os.path.isdir(data_path):\n",
    "            os.makedirs(data_path)\n",
    "        # plot G into plt and highlist node_idx in the explanation\n",
    "        plt.savefig('{}/subgraph_node_non_mask{}.png'.format(data_path, node_idx))\n",
    "\n",
    "        #plt.close()\n",
    "        plt.figure()\n",
    "        pos = nx.spring_layout(G1, k=0.5)\n",
    "        nx.draw_networkx_nodes(G1, pos, node_color=node_color1)\n",
    "        nx.draw_networkx_edges(G1, pos, edge_color=edge_colors1, edge_cmap=plt.get_cmap(\"Greys\"),\n",
    "                               edge_vmin=edge_vmin1, edge_vmax=edge_vmax1)\n",
    "        nx.draw_networkx_labels(G1, pos, labels=node_labels1)\n",
    "        plt.axis('off')\n",
    "        # plot G into plt and highlist node_idx to be explained as red\n",
    "        plt.savefig('{}/subgraph_node_masked_edges{}.png'.format(data_path, node_idx))\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "class ExplainModule(nn.Module):\n",
    "    def __init__(self, adj, node_features, labels, edge_index, node_idx, model, adj_mode=True):\n",
    "        super(ExplainModule, self).__init__()\n",
    "        self.adj_mode = adj_mode\n",
    "        # dim --> n*n, G_c\n",
    "        self.sub_adj = adj\n",
    "        # dim --> n*d, X_c\n",
    "        self.sub_node_feat = node_features\n",
    "        # dim --> n*1, Y_c\n",
    "        self.sub_labels = labels\n",
    "        # dim --> 2*E_s\n",
    "        self.sub_edge_index = edge_index\n",
    "        self.sub_node_idx = node_idx\n",
    "        self.GNN_model = model\n",
    "        self.lr = 0.1\n",
    "\n",
    "        # setup GNNExplainer\n",
    "        num_nodes = np.size(self.sub_adj, 1)\n",
    "        feat_dim = np.size(self.sub_node_feat, -1)\n",
    "        self.edge_mask = self.ConstructEdgeMask(num_nodes)\n",
    "        self.node_feat_mask = self.ConstructFeatureMask(feat_dim)\n",
    "        self.optimizer = torch.optim.Adam([self.node_feat_mask, self.edge_mask], lr=self.lr)\n",
    "\n",
    "        # used to remove self loops\n",
    "        self.masked_adj = None\n",
    "        self.diag_mask = torch.ones(num_nodes, num_nodes) - torch.eye(num_nodes)\n",
    "\n",
    "    def ConstructEdgeMask(self, num_nodes):\n",
    "        if self.adj_mode:\n",
    "            edge_mask = nn.Parameter(torch.FloatTensor(num_nodes, num_nodes))\n",
    "        else:\n",
    "            # uses edge_index\n",
    "            edge_mask = nn.Parameter(torch.FloatTensor(num_nodes))\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "                edge_mask.normal_(1.0, std)\n",
    "        return edge_mask\n",
    "\n",
    "    def ConstructFeatureMask(self, num_features):\n",
    "        if num_features < 1:\n",
    "            num_features = 1\n",
    "        feat_mask = nn.Parameter(torch.FloatTensor(num_features))\n",
    "        std = 0.1\n",
    "        with torch.no_grad():\n",
    "            feat_mask.normal_(1.0, std)\n",
    "        return feat_mask\n",
    "\n",
    "    def forward(self, node_idx):\n",
    "        edge_index = self.sub_edge_index\n",
    "        # mask features\n",
    "        masked_node_feat = self.MaskFeatures()\n",
    "\n",
    "        # get prediction based after masking using the GNN_Model\n",
    "        if self.adj_mode:\n",
    "            # print('hello:',self.sub_adjadj)\n",
    "            self.masked_adj = self.MaskEdges()\n",
    "            ypred, adj_att = self.GNN_model(masked_node_feat, self.masked_adj)\n",
    "        else:\n",
    "            edge_masks = self.MaskEdges()\n",
    "            # edge_index and edge_masks form the sub_masked_adj_matrix\n",
    "            ypred, adj_att = self.GNN_model(masked_node_feat, edge_index)\n",
    "\n",
    "        # node_idx_label_pred = ypred[node_idx,:]\n",
    "        # node_feat = feat[node_idx,:]\n",
    "        # # softmax rescale Tensor elements to range[0,1] that sums to 1\n",
    "        # node_idx_label_pred = nn.Softmax(dim=0)(node_idx_label_pred)\n",
    "\n",
    "        # softmax rescale Tensor elements to range[0,1] that sums to 1\n",
    "        model_ypred = ypred[-1][node_idx]\n",
    "        model_ypred = nn.Softmax(dim=0)(model_ypred)\n",
    "\n",
    "        return model_ypred, adj_att\n",
    "\n",
    "    def loss(self, ypred, model_pred_label, node_idx):\n",
    "        ypred = ypred.squeeze()\n",
    "        node_idx_pred = ypred\n",
    "\n",
    "        ypred_node_idx = node_idx_pred[model_pred_label]\n",
    "        # if predict well, value should be close to 1, otherwise 0\n",
    "        pred_loss = -torch.log(ypred_node_idx)\n",
    "\n",
    "        edge_mask = self.edge_mask.sigmoid()\n",
    "        edge_size_loss = coeffs[\"size\"] * torch.sum(edge_mask)\n",
    "        edge_mask_entropy = (-1) * edge_mask * torch.log(edge_mask) - (1-edge_mask) * torch.log(1-edge_mask)\n",
    "        edge_mask_entropy_loss = coeffs[\"ent\"] * torch.mean(edge_mask_entropy)\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.sigmoid()\n",
    "        node_feat_size_loss = coeffs[\"feat_size\"] * torch.mean(node_feat_mask)\n",
    "\n",
    "        # calculate Laplacian loss, do we actually need this?\n",
    "        # https://www.groundai.com/project/gnn-explainer-a-tool-for-post-hoc-explanation-of-graph-neural-networks/1#S3.E2\n",
    "        # Section 5.1 Laplacian regularization\n",
    "\n",
    "        loss = pred_loss + edge_size_loss + edge_mask_entropy_loss + node_feat_size_loss\n",
    "        return loss\n",
    "\n",
    "    def MaskEdges(self):\n",
    "        edge_mask = self.edge_mask\n",
    "        if not self.adj_mode:\n",
    "            edge_mask = torch.sigmoid(self.edge_mask)\n",
    "            return edge_mask\n",
    "        else:\n",
    "            # print('edge_mask:\\n', edge_mask)\n",
    "            edge_mask = torch.sigmoid(edge_mask)\n",
    "            # print('edge maskkk')\n",
    "            # print(edge_mask)\n",
    "            sym_edge_mask = (edge_mask + edge_mask.t()) / 2\n",
    "            # print('sym_edge_mask')\n",
    "            # print(sym_edge_mask)\n",
    "            # print(self.sub_adj * sym_edge_mask)\n",
    "            masked_adj = self.sub_adj * sym_edge_mask\n",
    "            return masked_adj * self.diag_mask\n",
    "\n",
    "    def MaskFeatures(self):\n",
    "        node_feat_mask = self.node_feat_mask\n",
    "        node_feat_mask = torch.sigmoid(node_feat_mask)\n",
    "        masked_node_feat = node_feat_mask * self.sub_node_feat\n",
    "        return masked_node_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cg_dict\n",
    "node_features = data['feat']\n",
    "node_labels = data['label']\n",
    "adj_matrix = data['adj']\n",
    "\n",
    "explainer = Explainer(model, node_features, node_labels, adj_matrix=adj_matrix, adj_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_args.explain_node, prog_args.num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, compare = explainer.ExplainNode(prog_args.explain_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = []\n",
    "house_tips = [24, 29, 34]\n",
    "house_BAconnectors = [20, 25, 30]\n",
    "sorted_union_node_idx = sorted(list(set(house_tips) | set(house_BAconnectors)))\n",
    "\n",
    "for i in sorted_union_node_idx: # range(20,25)\n",
    "    print(\"Explainer for node :\", i)\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    _, _, compare = explainer.ExplainNode(i)\n",
    "    comparison.append(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "for i in range(len(comparison)):\n",
    "    print(comparison[i][0], comparison [i][1])\n",
    "    if comparison[i][0] != comparison [i][1]:\n",
    "        error += 1\n",
    "error_rate = error / len(comparison)\n",
    "print('Model evaluating computational graph error rate:', error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All respective files are in placed to run the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# This notebook works with Pytorch geometric GNNExplainer for explaining node predictions\n",
    "# of Cora dataset and/or BA Graph with house motifs\n",
    "# Created by : Au Jit Seah\n",
    "# File owners : Au Jit Seah\n",
    "##########################################################################################\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic graphs for GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File : syntheticSim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the BA-shape with house motifs and setting roles that will be used as labels\n",
    "\"\"\"\n",
    "Builds a BA preferential attachment graph, with \"node index\" starting from \"start\"\n",
    "parameter and \"role_ids\" from \"role_start\" parameter\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "start       :    starting index of the shape\n",
    "width       :    int size of the graph (no. of nodes)\n",
    "role_start  :    starting index for the roles\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "graph       :    a ba graph, with ids beginning from start\n",
    "roles       :    list of the roles of the nodes (indexed starting from\n",
    "                 role_start) that will be used as labels\n",
    "\"\"\"\n",
    "def ba(start, width, role_start=0, m=5):\n",
    "    graph = nx.barabasi_albert_graph(width, m)\n",
    "    graph.add_nodes_from(range(start, start + width))\n",
    "    nids = sorted(graph)\n",
    "    mapping = {nid: start + i for i, nid in enumerate(nids)}\n",
    "    graph = nx.relabel_nodes(graph, mapping)\n",
    "    roles = [role_start for i in range(width)]\n",
    "    return graph, roles\n",
    "\n",
    "\"\"\"\n",
    "Builds a house-like graph/motif, with \"node index\" starting from \"start\"\n",
    "parameter and \"role_ids\" from \"role_start\" parameter\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "start       :    starting index for the shape\n",
    "role_start  :    starting index for the roles\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "graph       :    a house-like graph/motif, with ids beginning from start\n",
    "roles       :    list of the roles of the nodes (indexed starting at\n",
    "                 role_start) that will be used as labels\n",
    "\"\"\"\n",
    "def house(start, role_start=0):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(start, start + 5))\n",
    "    graph.add_edges_from(\n",
    "        [\n",
    "            (start, start + 1),\n",
    "            (start + 1, start + 2),\n",
    "            (start + 2, start + 3),\n",
    "            (start + 3, start),\n",
    "        ]\n",
    "    )\n",
    "    # graph.add_edges_from([(start, start + 2), (start + 1, start + 3)])\n",
    "    graph.add_edges_from([(start + 4, start), (start + 4, start + 1)])\n",
    "    roles = [role_start, role_start, role_start + 1, role_start + 1, role_start + 2]\n",
    "    return graph, roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a basis graph and attaches elements of the type in the list randomly along the basis.\n",
    "Possibility to add random edges afterwards.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "width_basis       :      width (in terms of number of nodes) of the basis\n",
    "basis_type        :      \"ba\"\n",
    "shapes            :      list of shape list\n",
    "                         (1st arg  : type of shape,\n",
    "                         next args : args for building the shape except for the start)\n",
    "start             :      initial node label for the first node\n",
    "rdm_basis_plugins :      Boolean\n",
    "                         For the shapes to be attached randomly (True) or\n",
    "                         regularly (False) to the basis graph\n",
    "add_random_edges  :      no. of edges to randomly add on the structure\n",
    "m                 :      no. of new edges to attach to existing node (for BA graph)\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "basis             :      a networkx graph with the particular shape used as the base\n",
    "role_id           :      label for each role (eg. representing basis or edges)\n",
    "plugins           :      node ids whereby the motif graph will be attached to the basis\n",
    "\"\"\"\n",
    "# Eg. build_graph(20, \"ba\", [[\"house\"]], start=0, m=5)\n",
    "def build_graph(width_basis, basis_type, list_shapes, start=0,\n",
    "                rdm_basis_plugins=False,add_random_edges=0, m=5):\n",
    "    print(\"------ Building the Synthetic BA graph with 'House' motifs ------\")\n",
    "    # Build the BA graph start with 0 and number of nodes (width basis)\n",
    "    if basis_type == \"ba\":\n",
    "        # Drawing of a house motif\n",
    "        basis, role_id = eval(basis_type)(start, width_basis, m=m)\n",
    "        print(\"Role Id of the BA graph :\\n\", role_id)\n",
    "#     else:\n",
    "#         # Drawing other type of motif\n",
    "#         basis, role_id = eval(basis_type)(start, width_basis)\n",
    "\n",
    "    n_basis, n_shapes = nx.number_of_nodes(basis), len(list_shapes)\n",
    "    start += n_basis  # indicator of the id of the next node\n",
    "    print(\"Indicator of the id of the next node :\", start)\n",
    "    \n",
    "    # role_id are '0's for all the nodes of the basis, BA graph\n",
    "    print(\"Number of nodes in the BA graph : \", n_basis)\n",
    "    print(\"Number of motifs : \", n_shapes)\n",
    "\n",
    "    print(\"List of shapes :\", list_shapes)\n",
    "    print(\"No. of shapes :\", len(list_shapes))\n",
    "\n",
    "    # Sample (with replacement) where to attach the new motifs\n",
    "    if rdm_basis_plugins is True:\n",
    "        plugins = np.random.choice(n_basis, n_shapes, replace=False)\n",
    "    else:\n",
    "        spacing = math.floor(n_basis / n_shapes)\n",
    "        print(\"Spacing : \", spacing)\n",
    "        plugins = [int(k * spacing) for k in range(n_shapes)]\n",
    "        print(\"Plugins : \", plugins)\n",
    "    seen_shapes = {\"basis\": [0, n_basis]}\n",
    "    print(\"seen_shapes : \", seen_shapes)\n",
    "    \n",
    "    for shape_index, shape in enumerate(list_shapes):\n",
    "        shape_type = shape[0]\n",
    "        print(\"\\n-----------------------------------------\")\n",
    "        print(\"Shape_ID : \" + str(shape_index) + \" with shape type : \" + str(shape_type))\n",
    "        print(str(len(shape)) + \" shapes with list of Shape :\", shape)\n",
    "        print(\"The shape starts from index 1 : \", shape[1:])\n",
    "        \n",
    "        args = [start]\n",
    "        \n",
    "        # More than one shape\n",
    "        if len(shape) > 1:\n",
    "            args += shape[1:]\n",
    "        \n",
    "        # Append 0 for the \"role_start\" in \"house\" function\n",
    "        args += [0]\n",
    "        print(\"\\nThe list of arguments :\", args)\n",
    "        # *args parameter to send a non-keyworded variable-length argument list to function, 1-2 parameters in this case\n",
    "        print(\"The first item in list of arguments :\", args[0])\n",
    "        print(\"The second item in list of arguments :\", args[1])\n",
    "        \n",
    "        # Creating the \"house\" motif\n",
    "        graph_s, roles_graph_s = eval(shape_type)(*args)\n",
    "        n_s = nx.number_of_nodes(graph_s)\n",
    "        \n",
    "        try:\n",
    "             # Get the last seen label from first index\n",
    "            col_start = seen_shapes[shape_type][0]\n",
    "        except:\n",
    "            # Get the max label value 1\n",
    "            col_start = np.max(role_id) + 1\n",
    "            # Add the new shape_type to the seen_shapes dictionary\n",
    "            seen_shapes[shape_type] = [col_start, n_s]\n",
    "        print(\"Column start :\", col_start)\n",
    "        print(\"Observe seen_shapes : \", seen_shapes)\n",
    "        \n",
    "        \n",
    "        # Attach the shape to the basis, BA graph\n",
    "        basis.add_nodes_from(graph_s.nodes())\n",
    "        basis.add_edges_from(graph_s.edges())\n",
    "        # Connecting the motif to the BA graph from node 20 to 0, 25 to 6 and 30 to 12\n",
    "        basis.add_edges_from([(start, plugins[shape_index])])\n",
    "#         if shape_type == \"cycle\":\n",
    "#             if np.random.random() > 0.5:\n",
    "#                 a = np.random.randint(1, 4)\n",
    "#                 b = np.random.randint(1, 4)\n",
    "#                 basis.add_edges_from([(a + start, b + plugins[shape_id])])\n",
    "\n",
    "        # start = 0; col_start = 1; roles_graph_s = [0, 0, 1, 1, 2]\n",
    "        temp_labels = [r + col_start for r in roles_graph_s]\n",
    "        # temp_labels increment roles_graph_s by col_start\n",
    "\n",
    "        # temp_labels[0] += 100 * seen_shapes[shape_type][0]\n",
    "        \n",
    "        # role_id is [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        # Append labels of motif to the labels of BA graph\n",
    "        role_id += temp_labels\n",
    "        print(\"Labels of BA graph with attached motifs :\\n\", role_id)\n",
    "        print(\"No. of nodes in attached graph : \", nx.number_of_nodes(basis))\n",
    "        start += n_s\n",
    "        print(\"With attached motif nodes, index starts from : \", start)\n",
    "\n",
    "#     if add_random_edges > 0:\n",
    "#         # add random edges between nodes:\n",
    "#         for p in range(add_random_edges):\n",
    "#             src, dest = np.random.choice(nx.number_of_nodes(basis), 2, replace=False)\n",
    "#             print(src, dest)\n",
    "#             basis.add_edges_from([(src, dest)])\n",
    "\n",
    "    # Plotting the basis \"BA\" graph\n",
    "    # plt.figure(figsize=(8, 6), dpi=300)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.title('BA graph'.upper(), y=1.0, fontsize=14)\n",
    "    nx.draw(basis, with_labels=True, font_weight='bold')\n",
    "\n",
    "    # Plot the motif \"house\" graph\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.title('\"House\" motif', y=1.0, fontsize=12)\n",
    "    nx.draw(graph_s, with_labels=True, font_weight='bold')\n",
    "    print(\"\\nInformation of the motif graph :\\n\", nx.info(graph_s))\n",
    "    \n",
    "    plt.show()\n",
    "            \n",
    "    return basis, role_id, plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File : featureGen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating node features\n",
    "import abc\n",
    "\n",
    "class FeatureGen(metaclass=abc.ABCMeta):\n",
    "    # Feature Generator base class from Abstract Base Classes\n",
    "    @abc.abstractmethod\n",
    "    def gen_node_features(self, G):\n",
    "        pass\n",
    "\n",
    "class ConstFeatureGen(FeatureGen):\n",
    "    # Generate constant node features in class\n",
    "    def __init__(self, val):\n",
    "        print(\"Values in Constant Feature Generator : \", val)\n",
    "        self.val = val\n",
    "\n",
    "    def gen_node_features(self, G):\n",
    "        print(\"Generate node features for \" + str(len(G.nodes())) + \" nodes.\")\n",
    "        feat_dict = {i:{'feat': np.array(self.val, dtype=np.float32)} for i in G.nodes()}\n",
    "        print('Values of feat_dict[0][\"feat\"]:', feat_dict[0]['feat'])\n",
    "        \n",
    "        # Set node attributes with values in feature dictionary of values '1's\n",
    "        nx.set_node_attributes(G, feat_dict)\n",
    "        print('Node attributes of node \\'0\\', G.nodes[0][\"feat\"]:', G.nodes[0]['feat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic BA graph with \"house\" motifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File : gengraph.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up graph and create its adjacency matrix\n",
    "\"\"\"\n",
    "Perturb the list of (sparse) graphs by adding/removing edges.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "graph_list           :      the list of graphs to be perturbed\n",
    "p                    :      proportion of added edges based on current number of edges.\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "perturbed_graph_list :      the list of graphs that are perturbed from the original graphs.\n",
    "\"\"\"\n",
    "def perturb(graph_list, p):\n",
    "    perturbed_graph_list = []\n",
    "    for G_original in graph_list:\n",
    "        G = G_original.copy()\n",
    "        edge_count = int(G.number_of_edges() * p)\n",
    "        # randomly add the edges between a pair of nodes without an edge.\n",
    "        for _ in range(edge_count):\n",
    "            while True:\n",
    "                u = np.random.randint(0, G.number_of_nodes())\n",
    "                v = np.random.randint(0, G.number_of_nodes())\n",
    "                if (not G.has_edge(u, v)) and (u != v):\n",
    "                    break\n",
    "            G.add_edge(u, v)\n",
    "        perturbed_graph_list.append(G)\n",
    "    return perturbed_graph_list\n",
    "\n",
    "\"\"\"\n",
    "Load an existing graph to be converted for the experiments.\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "G                        :      Networkx graph is the input for preprocessing\n",
    "labels                   :      corresponding node labels\n",
    "normalize_adj            :      Boolean\n",
    "                                returns a normalized adjacency matrix (True)\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "{\"adj\", \"feat\" \"labels\"} :  dictionary containing adjacency, node features and labels\n",
    "\"\"\"\n",
    "def preprocess_input_graph(G, labels, normalize_adj=False):\n",
    "    # Create the adjacency matrix for graph\n",
    "    adj = np.array(nx.to_numpy_matrix(G))\n",
    "    print(\"------ Preprocess Input graph ------\")\n",
    "    print(\"The shape of the adjacency matrix ('dxd') of input graph :\", adj.shape)\n",
    "\n",
    "    # If normalization is required\n",
    "#     if normalize_adj:\n",
    "#         # Create a diagonal array\n",
    "#         sqrt_deg = np.diag(1.0 / np.sqrt(np.sum(adj, axis=0, dtype=float).squeeze()))\n",
    "#         adj = np.matmul(np.matmul(sqrt_deg, adj), sqrt_deg)\n",
    "\n",
    "    # last index from 0 - 34\n",
    "    existing_node = list(G.nodes)[-1]\n",
    "    # Dimension of features\n",
    "    feat_dim = G.nodes[existing_node][\"feat\"].shape[0]\n",
    "    print(\"Feature dimensions of the last node '\" + str(existing_node) + \"' : \" + str(feat_dim))\n",
    "\n",
    "    # Initialize feature ndarray (dimension of number_of_nodes x feat_dim) \n",
    "    features = np.zeros((G.number_of_nodes(), feat_dim), dtype=float)\n",
    "    for idx, node_id in enumerate(G.nodes()):\n",
    "        features[idx, :] = G.nodes[node_id][\"feat\"]\n",
    "\n",
    "    # add batch dim by expanding the shape horizontally\n",
    "    adj = np.expand_dims(adj, axis=0)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)    \n",
    "    print(\"The shape of the adjacency matrix after expansion :\", adj.shape)\n",
    "    print(\"The shape of the features matrix after expansion :\", features.shape)\n",
    "    print(\"The shape of the labels matrix after expansion :\", labels.shape)\n",
    "    \n",
    "    return {\"adj\": adj, \"feat\": features, \"labels\": labels}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generating Synthetic Graph for experimentation :\n",
    "- Barabasi-Albert base graph and attach the no. of \"house\" motifs\n",
    "\n",
    "Input parameters :\n",
    "----------------------------------------------------------------------------------------\n",
    "nb_shapes         :  the no. of shapes ('house' motifs) that should be added to the\n",
    "                     base graph\n",
    "width_basis       :  the no. of nodes of the basis graph (ie. 'BA' graph)\n",
    "feature_generator :  a `Feature Generator` for node features\n",
    "                     addition of constant features to nodes ('None')\n",
    "m                 :  no. of edges to be attached to existing node (for 'BA' graph)\n",
    "\n",
    "Return values :\n",
    "----------------------------------------------------------------------------------------\n",
    "G                 :  a generated networkx \"ba\" graph with attached \"house\" motifs\n",
    "role_id           :  a list with total number of nodes in the entire graph (base graph\n",
    "                     and  motifs).  role_id[i] is the ID of the role of node i.\n",
    "                     It is also the label used for training and predictions\n",
    "name              :  a graph identifier\n",
    "\"\"\"\n",
    "def gen_syn1(nb_shapes=3, width_basis=20, feature_generator=None, m=5):\n",
    "    basis_type = \"ba\"\n",
    "    list_shapes = [[\"house\"]] * nb_shapes\n",
    "\n",
    "    # synthetic_structsim\n",
    "    G, role_id, _ = build_graph(width_basis, basis_type, list_shapes, start=0, m=5)\n",
    "    G = perturb([G], 0.01)[0]\n",
    "\n",
    "    if feature_generator is None:\n",
    "        # feature generator\n",
    "        feature_generator = ConstFeatureGen(1)\n",
    "    \n",
    "    # Generate node features\n",
    "    feature_generator.gen_node_features(G)\n",
    "\n",
    "    name = basis_type + \"_\" + str(width_basis) + \"_\" + str(nb_shapes)\n",
    "    \n",
    "    print(\"------ Generated the Synthetic BA graph with 'House' motifs ------\")\n",
    "    print(\"Name of generated graph :\", name)\n",
    "    return G, role_id, name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File : models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This is the basic Graph Convolution Network class inherited from torch.nn module\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        add_self=False,\n",
    "        normalize_embedding=False,\n",
    "        dropout=0.0,\n",
    "        bias=True,\n",
    "        gpu=True,\n",
    "        att=False,\n",
    "    ):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.att = att\n",
    "        self.add_self = add_self\n",
    "        self.dropout = dropout\n",
    "        if dropout > 0.001:\n",
    "            self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.normalize_embedding = normalize_embedding\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        if not gpu:\n",
    "            self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
    "            if add_self:\n",
    "                self.self_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, output_dim)\n",
    "                )\n",
    "            if att:\n",
    "                self.att_weight = nn.Parameter(torch.FloatTensor(input_dim, input_dim))\n",
    "        else:\n",
    "            self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim).cuda())\n",
    "            if add_self:\n",
    "                self.self_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, output_dim).cuda()\n",
    "                )\n",
    "            if att:\n",
    "                self.att_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, input_dim).cuda()\n",
    "                )\n",
    "        if bias:\n",
    "            if not gpu:\n",
    "                self.bias = nn.Parameter(torch.FloatTensor(output_dim))\n",
    "            else:\n",
    "                self.bias = nn.Parameter(torch.FloatTensor(output_dim).cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        # self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # This 'forward' has to be implemented to avoid unimplemented error in Convolution layers\n",
    "    def forward(self, x, adj):\n",
    "        if self.dropout > 0.001:\n",
    "            x = self.dropout_layer(x)\n",
    "        # deg = torch.sum(adj, -1, keepdim=True)\n",
    "        if self.att:\n",
    "            x_att = torch.matmul(x, self.att_weight)\n",
    "            # import pdb\n",
    "            # pdb.set_trace()\n",
    "            att = x_att @ x_att.permute(0, 2, 1)\n",
    "            # att = self.softmax(att)\n",
    "            adj = adj * att\n",
    "\n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.add_self:\n",
    "            self_emb = torch.matmul(x, self.self_weight)\n",
    "            y += self_emb\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        if self.normalize_embedding:\n",
    "            y = F.normalize(y, p=2, dim=2)\n",
    "            # print(y[0][0])\n",
    "        return y, adj\n",
    "\n",
    "    \n",
    "# Build the convolution layers for the GCN Graph Encoder\n",
    "# This is where the node masks and embeddings are created with predictions in forward pass\n",
    "class GcnEncoderGraph(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        embedding_dim,           # output_dim\n",
    "        label_dim,               # num_classes\n",
    "        num_layers,              # num_gc_layers\n",
    "        pred_hidden_dims=[],\n",
    "        concat=True,\n",
    "        bn=True,\n",
    "        dropout=0.0,\n",
    "        add_self=False,\n",
    "        args=None,\n",
    "    ):\n",
    "      \n",
    "        super(GcnEncoderGraph, self).__init__()\n",
    "        self.concat = concat\n",
    "\n",
    "        # add_self = add_self\n",
    "        self.add_self = add_self\n",
    "\n",
    "        # This value will change from 'True' if it is provided by the caller function\n",
    "        self.bn = bn\n",
    "        self.num_layers = num_layers\n",
    "        self.num_aggs = 1\n",
    "\n",
    "        self.bias = True        \n",
    "        self.gpu = args.gpu\n",
    "        print(\"*** Check received batch_size argument :\", args.batch_size)\n",
    "        print(\"*** Batch normalization from caller (default : False) :\", bn)\n",
    "\n",
    "        if args.method == \"att\":\n",
    "            self.att = True\n",
    "        else:\n",
    "            self.att = False\n",
    "        if args is not None:\n",
    "            self.bias = args.bias\n",
    "\n",
    "        self.conv_first, self.conv_block, self.conv_last = self.build_conv_layers(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            num_layers,\n",
    "            add_self,\n",
    "            normalize=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        if concat:\n",
    "            self.pred_input_dim = hidden_dim * (num_layers - 1) + embedding_dim\n",
    "        else:\n",
    "            self.pred_input_dim = embedding_dim\n",
    "        self.pred_model = self.build_pred_layers(\n",
    "            self.pred_input_dim, pred_hidden_dims, label_dim, num_aggs=self.num_aggs\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, GraphConv):\n",
    "                init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain(\"relu\"))\n",
    "                if m.att:\n",
    "                    init.xavier_uniform_(\n",
    "                        m.att_weight.data, gain=nn.init.calculate_gain(\"relu\")\n",
    "                    )\n",
    "                if m.add_self:\n",
    "                    init.xavier_uniform_(\n",
    "                        m.self_weight.data, gain=nn.init.calculate_gain(\"relu\")\n",
    "                    )\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    def build_conv_layers(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        embedding_dim,\n",
    "        num_layers,\n",
    "        add_self,\n",
    "        normalize=False,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        conv_first = GraphConv(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=hidden_dim,\n",
    "            add_self=add_self,\n",
    "            normalize_embedding=normalize,\n",
    "            bias=self.bias,\n",
    "            gpu=self.gpu,\n",
    "            att=self.att,\n",
    "        )\n",
    "        conv_block = nn.ModuleList(\n",
    "            [\n",
    "                GraphConv(\n",
    "                    input_dim=hidden_dim,\n",
    "                    output_dim=hidden_dim,\n",
    "                    add_self=add_self,\n",
    "                    normalize_embedding=normalize,\n",
    "                    dropout=dropout,\n",
    "                    bias=self.bias,\n",
    "                    gpu=self.gpu,\n",
    "                    att=self.att,\n",
    "                )\n",
    "                for i in range(num_layers - 2)\n",
    "            ]\n",
    "        )\n",
    "        conv_last = GraphConv(\n",
    "            input_dim=hidden_dim,\n",
    "            output_dim=embedding_dim,\n",
    "            add_self=add_self,\n",
    "            normalize_embedding=normalize,\n",
    "            bias=self.bias,\n",
    "            gpu=self.gpu,\n",
    "            att=self.att,\n",
    "        )\n",
    "        return conv_first, conv_block, conv_last\n",
    "\n",
    "    def build_pred_layers(\n",
    "        self, pred_input_dim, pred_hidden_dims, label_dim, num_aggs=1\n",
    "    ):\n",
    "        pred_input_dim = pred_input_dim * num_aggs\n",
    "        if len(pred_hidden_dims) == 0:\n",
    "            pred_model = nn.Linear(pred_input_dim, label_dim)\n",
    "        else:\n",
    "            pred_layers = []\n",
    "            for pred_dim in pred_hidden_dims:\n",
    "                pred_layers.append(nn.Linear(pred_input_dim, pred_dim))\n",
    "                pred_layers.append(self.act)\n",
    "                pred_input_dim = pred_dim\n",
    "            pred_layers.append(nn.Linear(pred_dim, label_dim))\n",
    "            pred_model = nn.Sequential(*pred_layers)\n",
    "        return pred_model\n",
    "\n",
    "    \"\"\"\n",
    "    For each num_nodes in batch_num_nodes, the first num_nodes entries of the \n",
    "    corresponding column are 1's, and the rest are 0's (to be masked out).\n",
    "    Dimension of mask: [batch_size x max_nodes x 1]\n",
    "    \"\"\"\n",
    "    def construct_mask(self, max_nodes, batch_num_nodes):\n",
    "        # masks\n",
    "        packed_masks = [torch.ones(int(num)) for num in batch_num_nodes]\n",
    "        batch_size = len(batch_num_nodes)\n",
    "        out_tensor = torch.zeros(batch_size, max_nodes)\n",
    "        for i, mask in enumerate(packed_masks):\n",
    "            out_tensor[i, : batch_num_nodes[i]] = mask\n",
    "        return out_tensor.unsqueeze(2).cuda()\n",
    "\n",
    "    \"\"\"\n",
    "    Batch normalization of 3D tensor x\n",
    "    \"\"\"\n",
    "    def apply_bn(self, x):\n",
    "        bn_module = nn.BatchNorm1d(x.size()[1])\n",
    "        if self.gpu:\n",
    "            bn_module = bn_module.cuda()\n",
    "        return bn_module(x)\n",
    "\n",
    "    \"\"\"\n",
    "    Perform forward prop with graph convolution.\n",
    "    Returns:\n",
    "        Embedding matrix with dimension [batch_size x num_nodes x embedding]\n",
    "        The embedding dim is self.pred_input_dim\n",
    "    \"\"\"\n",
    "    def gcn_forward(\n",
    "        self, x, adj, conv_first, conv_block, conv_last, embedding_mask=None\n",
    "    ):\n",
    "\n",
    "        x, adj_att = conv_first(x, adj)\n",
    "        x = self.act(x)\n",
    "        if self.bn:\n",
    "            x = self.apply_bn(x)\n",
    "        x_all = [x]\n",
    "        adj_att_all = [adj_att]\n",
    "        # out_all = []\n",
    "        # out, _ = torch.max(x, dim=1)\n",
    "        # out_all.append(out)\n",
    "        for i in range(len(conv_block)):\n",
    "            x, _ = conv_block[i](x, adj)\n",
    "            x = self.act(x)\n",
    "            if self.bn:\n",
    "                x = self.apply_bn(x)\n",
    "            x_all.append(x)\n",
    "            adj_att_all.append(adj_att)\n",
    "        x, adj_att = conv_last(x, adj)\n",
    "        x_all.append(x)\n",
    "        adj_att_all.append(adj_att)\n",
    "        # x_tensor: [batch_size x num_nodes x embedding]\n",
    "        x_tensor = torch.cat(x_all, dim=2)\n",
    "        if embedding_mask is not None:\n",
    "            x_tensor = x_tensor * embedding_mask\n",
    "        self.embedding_tensor = x_tensor\n",
    "\n",
    "        # adj_att_tensor: [batch_size x num_nodes x num_nodes x num_gc_layers]\n",
    "        adj_att_tensor = torch.stack(adj_att_all, dim=3)\n",
    "        return x_tensor, adj_att_tensor\n",
    "\n",
    "    # This 'forward' and 'loss' functions in 'GcnEncoderGraph' are not used\n",
    "#     def forward(self, x, adj, batch_num_nodes=None, **kwargs):\n",
    "#         # Embedding mask\n",
    "#         max_num_nodes = adj.size()[1]\n",
    "#         if batch_num_nodes is not None:\n",
    "#             self.embedding_mask = self.construct_mask(max_num_nodes, batch_num_nodes)\n",
    "#         else:\n",
    "#             self.embedding_mask = None\n",
    "\n",
    "#         # Convolution\n",
    "#         x, adj_att = self.conv_first(x, adj)\n",
    "#         x = self.act(x)\n",
    "#         if self.bn:\n",
    "#             x = self.apply_bn(x)\n",
    "#         out_all = []\n",
    "#         out, _ = torch.max(x, dim=1)\n",
    "#         out_all.append(out)\n",
    "#         adj_att_all = [adj_att]\n",
    "#         for i in range(self.num_layers - 2):\n",
    "#             x, adj_att = self.conv_block[i](x, adj)\n",
    "#             x = self.act(x)\n",
    "#             if self.bn:\n",
    "#                 x = self.apply_bn(x)\n",
    "#             out, _ = torch.max(x, dim=1)\n",
    "#             out_all.append(out)\n",
    "#             if self.num_aggs == 2:\n",
    "#                 out = torch.sum(x, dim=1)\n",
    "#                 out_all.append(out)\n",
    "#             adj_att_all.append(adj_att)\n",
    "#         x, adj_att = self.conv_last(x, adj)\n",
    "#         adj_att_all.append(adj_att)\n",
    "#         # x = self.act(x)\n",
    "#         out, _ = torch.max(x, dim=1)\n",
    "#         out_all.append(out)\n",
    "#         if self.num_aggs == 2:\n",
    "#             out = torch.sum(x, dim=1)\n",
    "#             out_all.append(out)\n",
    "#         if self.concat:\n",
    "#             output = torch.cat(out_all, dim=1)\n",
    "#         else:\n",
    "#             output = out\n",
    "\n",
    "#         # adj_att_tensor: [batch_size x num_nodes x num_nodes x num_gc_layers]\n",
    "#         adj_att_tensor = torch.stack(adj_att_all, dim=3)\n",
    "\n",
    "#         self.embedding_tensor = output\n",
    "#         ypred = self.pred_model(output)\n",
    "#         # print(output.size())\n",
    "#         return ypred, adj_att_tensor\n",
    "\n",
    "#     def loss(self, pred, label, type=\"softmax\"):\n",
    "#         # softmax + CE\n",
    "#         if type == \"softmax\":\n",
    "#             return F.cross_entropy(pred, label, size_average=True)\n",
    "#         elif type == \"margin\":\n",
    "#             batch_size = pred.size()[0]\n",
    "#             label_onehot = torch.zeros(batch_size, self.label_dim).long().cuda()\n",
    "#             label_onehot.scatter_(1, label.view(-1, 1), 1)\n",
    "#             return torch.nn.MultiLabelMarginLoss()(pred, label_onehot)\n",
    "\n",
    "        # return F.binary_cross_entropy(F.sigmoid(pred[:,0]), label.float())\n",
    "\n",
    "# GCN Encoding of the nodes\n",
    "class GcnEncoderNode(GcnEncoderGraph):    \n",
    "    def __init__(self, input_dim, hidden_dim, embedding_dim, label_dim, num_layers,\n",
    "                 pred_hidden_dims=[], concat=True,\n",
    "                 bn=True, dropout=0.0, args=None,):\n",
    "        super(GcnEncoderNode, self).__init__(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            label_dim,\n",
    "            num_layers,\n",
    "            pred_hidden_dims,\n",
    "            concat,\n",
    "            bn,\n",
    "            dropout,\n",
    "            args=args,\n",
    "        )\n",
    "        \n",
    "        if hasattr(args, \"loss_weight\"):\n",
    "            print(\"Loss weight: \", args.loss_weight)\n",
    "            self.celoss = nn.CrossEntropyLoss(weight=args.loss_weight)\n",
    "        else:\n",
    "            self.celoss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, adj, batch_num_nodes=None, **kwargs):\n",
    "        # Embedding masks\n",
    "        max_num_nodes = adj.size()[1]\n",
    "        if batch_num_nodes is not None:\n",
    "            embedding_mask = self.construct_mask(max_num_nodes, batch_num_nodes)\n",
    "        else:\n",
    "            embedding_mask = None\n",
    "\n",
    "        self.adj_atts = []\n",
    "        \n",
    "         # Using 'gcn_forward' rather than 'forward' in GcnEncoderGraph\n",
    "        self.embedding_tensor, adj_att = self.gcn_forward(\n",
    "            x, adj, self.conv_first, self.conv_block, self.conv_last, embedding_mask\n",
    "        )\n",
    "        pred = self.pred_model(self.embedding_tensor)\n",
    "        return pred, adj_att\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        pred = torch.transpose(pred, 1, 2)\n",
    "        return self.celoss(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File : train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate node classifications\n",
    "def evaluate_node(ypred, labels, train_idx, test_idx):\n",
    "    _, pred_labels = torch.max(ypred, 2)\n",
    "    pred_labels = pred_labels.numpy()\n",
    "\n",
    "    pred_train = np.ravel(pred_labels[:, train_idx])\n",
    "    pred_test = np.ravel(pred_labels[:, test_idx])\n",
    "    labels_train = np.ravel(labels[:, train_idx])\n",
    "    labels_test = np.ravel(labels[:, test_idx])\n",
    "\n",
    "    result_train = {\n",
    "        \"prec\": metrics.precision_score(labels_train, pred_train, average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(labels_train, pred_train, average=\"macro\"),\n",
    "        \"acc\": metrics.accuracy_score(labels_train, pred_train),\n",
    "        \"conf_mat\": metrics.confusion_matrix(labels_train, pred_train),\n",
    "    }\n",
    "    result_test = {\n",
    "        \"prec\": metrics.precision_score(labels_test, pred_test, average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(labels_test, pred_test, average=\"macro\"),\n",
    "        \"acc\": metrics.accuracy_score(labels_test, pred_test),\n",
    "        \"conf_mat\": metrics.confusion_matrix(labels_test, pred_test),\n",
    "    }\n",
    "    return result_train, result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train node classifier and save the prediction results\n",
    "def train_node_classifier(G, labels, model, args, writer=None):\n",
    "    # train/test split only for nodes\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    \n",
    "    # Training data with 80% ratio, labels_train.size()\n",
    "    num_train = int(num_nodes * args.train_ratio)\n",
    "    idx = [i for i in range(num_nodes)]\n",
    "\n",
    "    # Shuffle for training\n",
    "    np.random.shuffle(idx)\n",
    "    train_idx = idx[:num_train]\n",
    "    test_idx = idx[num_train:]\n",
    "\n",
    "    # data = gengraph.preprocess_input_graph(G, labels)\n",
    "    data = preprocess_input_graph(G, labels)\n",
    "    labels_train = torch.tensor(data[\"labels\"][:, train_idx], dtype=torch.long)\n",
    "    adj = torch.tensor(data[\"adj\"], dtype=torch.float)\n",
    "    x = torch.tensor(data[\"feat\"], requires_grad=True, dtype=torch.float)\n",
    "\n",
    "    \n",
    "#     scheduler, optimizer = train_utils.build_optimizer(\n",
    "#         args, model.parameters(), weight_decay=args.weight_decay\n",
    "#     )\n",
    "    # list(testModel.parameters()) and list(filter_fn) to show contents\n",
    "    # train_utils.build_optimizer \n",
    "    filter_fn = filter(lambda p : p.requires_grad, model.parameters())\n",
    "\n",
    "    # args.opt == 'adam':\n",
    "    optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=0.0)\n",
    "    scheduler = None\n",
    "\n",
    "    # Sets the module in training mode\n",
    "    model.train()\n",
    "    ypred = None\n",
    "    for epoch in range(args.num_epochs):\n",
    "        begin_time = time.time()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if args.gpu:\n",
    "            ypred, adj_att = model(x.cuda(), adj.cuda())\n",
    "        else:\n",
    "            ypred, adj_att = model(x, adj)\n",
    "        ypred_train = ypred[:, train_idx, :]\n",
    "        if args.gpu:\n",
    "            loss = model.loss(ypred_train, labels_train.cuda())\n",
    "        else:\n",
    "            loss = model.loss(ypred_train, labels_train)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        #for param_group in optimizer.param_groups:\n",
    "        #    print(param_group[\"lr\"])\n",
    "        elapsed = time.time() - begin_time\n",
    "\n",
    "        # Obtain with Confusion matrices for Train and Test results\n",
    "        result_train, result_test = evaluate_node(\n",
    "            ypred.cpu(), data[\"labels\"], train_idx, test_idx\n",
    "        )\n",
    "        \n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"loss/avg_loss\", loss, epoch)\n",
    "            writer.add_scalars(\n",
    "                \"prec\",\n",
    "                {\"train\": result_train[\"prec\"], \"test\": result_test[\"prec\"]},\n",
    "                epoch,\n",
    "            )\n",
    "            writer.add_scalars(\n",
    "                \"recall\",\n",
    "                {\"train\": result_train[\"recall\"], \"test\": result_test[\"recall\"]},\n",
    "                epoch,\n",
    "            )\n",
    "            writer.add_scalars(\n",
    "                \"acc\", {\"train\": result_train[\"acc\"], \"test\": result_test[\"acc\"]}, epoch\n",
    "            )\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\n",
    "                \"epoch: \",\n",
    "                epoch,\n",
    "                \"; loss: \",\n",
    "                loss.item(),\n",
    "                \"; train_acc: \",\n",
    "                result_train[\"acc\"],\n",
    "                \"; test_acc: \",\n",
    "                result_test[\"acc\"],\n",
    "                \"; train_prec: \",\n",
    "                result_train[\"prec\"],\n",
    "                \"; test_prec: \",\n",
    "                result_test[\"prec\"],\n",
    "                \"; epoch time: \",\n",
    "                \"{0:0.2f}\".format(elapsed),\n",
    "            )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    print(\"Confusion Matrix of train result :\\n\", result_train[\"conf_mat\"])\n",
    "    print(\"Confusion Matrix of test result :\\n\", result_test[\"conf_mat\"])\n",
    "\n",
    "    # Sets the module in evaluation mode for computational graph\n",
    "    model.eval()\n",
    "    if args.gpu:\n",
    "        ypred, _ = model(x.cuda(), adj.cuda())\n",
    "    else:\n",
    "        ypred, _ = model(x, adj)\n",
    "\n",
    "    cg_data = {\n",
    "        \"adj\": data[\"adj\"],\n",
    "        \"feat\": data[\"feat\"],\n",
    "        \"label\": data[\"labels\"],\n",
    "        \"pred\": ypred.cpu().detach().numpy(),\n",
    "        \"train_idx\": train_idx,\n",
    "    }\n",
    "    \n",
    "    print(\"Labels of the Computational graph :\\n\", cg_data['label'])\n",
    "    print(\"Prediction result of the Computational graph :\\n\", cg_data['pred'])\n",
    "    print(\"Train index of the Computational graph data :\\n\", cg_data['train_idx'])\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    \n",
    "    #io_utils.save_checkpoint\n",
    "    save_checkpoint(model, optimizer, args, num_epochs=-1, cg_dict=cg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# (1) GcnEncoderNode(GcnEncoderGraph) -> build_conv_layers -> GraphConv\n",
    "# build_conv_layers return conv_first, conv_block, conv_last\n",
    "# (2) GcnEncoderNode(GcnEncoderGraph) -> self.pred_model = self.build_pred_layers\n",
    "# build_pred_layers return pred_model\n",
    "# (3) syn_task1 -> train_node_classifier -> save_checkpoint\n",
    "#####################################################################################\n",
    "# Create the GCN model and encoding the nodes\n",
    "def syn_task1(args, writer=None):\n",
    "    # featgen.ConstFeatureGen\n",
    "    # np.ones(input_dim, dtype=float) = [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]\n",
    "    constant_feature = ConstFeatureGen(np.ones(args.input_dim, dtype=float))\n",
    "    print(\"Constant feature generator : \", constant_feature.val)\n",
    "    \n",
    "    #feat_dict = {i:{'feat': np.array(constant_feature.val, dtype=np.float32)} for i in G.nodes()}\n",
    "    #print ('Values of feat_dict[0][\"feat\"]:', feat_dict[0]['feat'])\n",
    "\n",
    "    #nx.set_node_attributes(G, feat_dict)\n",
    "    #print('Node attributes of node \\'0\\', G.nodes[0][\"feat\"]:', G.nodes[0]['feat'])\n",
    "\n",
    "    # gengraph.gen_syn1\n",
    "    # Create the BA graph with the \"house\" motifs\n",
    "    G, labels, name = gen_syn1(feature_generator=constant_feature)\n",
    "\n",
    "    # No .of classes from [0-3] for BA graph with house motifs\n",
    "    num_classes = max(labels) + 1\n",
    "    # Update number of classes in argument for training (Out of bounds error)\n",
    "    args.num_classes = num_classes\n",
    "    \n",
    "    # GcnEncoderNode model\n",
    "    print(\"------------ GCNEncoderNode Model ------------\")\n",
    "    print(\"Input dimensions :\", args.input_dim)\n",
    "    print(\"Hidden dimensions :\", args.hidden_dim)\n",
    "    print(\"Output dimensions :\", args.output_dim)\n",
    "    print(\"Number of classes in args :\", args.num_classes)\n",
    "    print(\"Number of GCN layers :\", args.num_gc_layers)\n",
    "    print(\"Method : \", args.method)\n",
    "\n",
    "    model = GcnEncoderNode(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                           args.num_classes, args.num_gc_layers, bn=args.bn, args=args)\n",
    "    \n",
    "    print(\"GcnEncoderNode model :\\n\", model)\n",
    "    \n",
    "\n",
    "#     if args.method == \"att\":\n",
    "#         print(\"Method: att\")\n",
    "#         model = models.GcnEncoderNode(\n",
    "#             args.input_dim,\n",
    "#             args.hidden_dim,\n",
    "#             args.output_dim,\n",
    "#             num_classes,\n",
    "#             args.num_gc_layers,\n",
    "#             bn=args.bn,\n",
    "#             args=args,\n",
    "#         )\n",
    "#     else:\n",
    "#         print(\"Method:\", args.method)\n",
    "#         model = models.GcnEncoderNode(\n",
    "#             args.input_dim,\n",
    "#             args.hidden_dim,\n",
    "#             args.output_dim,\n",
    "#             num_classes,\n",
    "#             args.num_gc_layers,\n",
    "#             bn=args.bn,\n",
    "#             args=args,\n",
    "#         )\n",
    "    if args.gpu:\n",
    "        model = model.cuda()\n",
    "\n",
    "    train_node_classifier(G, labels, model, args, writer=writer)\n",
    "    \n",
    "    # To be removed after testing\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "# Call flow 1 : syn_task1 -> gen_syn1 -> build_graph -> ba\n",
    "# Call flow 2 : syn_task1 -> GcnEncoderNode, train_node_classifier -> preprocess_input_graph\n",
    "model = syn_task1(prog_args, writer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for PyTorch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn-model-explainer/utils/io_utils.py\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda\n",
    "#prog_args.bn\n",
    "# Use `zero_division` parameter to control this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "## transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "## download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "## download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "#print(len(trainset))\n",
    "#print(trainset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 28x28x1 => 26x26x32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
    "        self.d2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # flatten => 32 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        #x = x.view(32, -1)\n",
    "\n",
    "        # 32 x (32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.ones((2,2))\n",
    "\n",
    "ta = torch.tensor(a, dtype=float).to('cuda:0')\n",
    "tb = torch.ones(2,2, dtype=float).to('cuda:0')\n",
    "\n",
    "print(ta)\n",
    "print(tb)\n",
    "print(ta @ tb) # dot product; element-wise product\n",
    "\n",
    "# This takes awhile for CUDA configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Current device : \", device)\n",
    "\n",
    "model = MyModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    ## training step\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ## forward + backprop + loss\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ## update model params\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += (torch.argmax(logits, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "    \n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "          %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += (torch.argmax(outputs, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "    preds = torch.argmax(outputs, 1).flatten().cpu().numpy()\n",
    "        \n",
    "print('Test Accuracy: %.2f'%(test_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, task='node'):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.task = task\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
    "        self.lns = nn.ModuleList()\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        for l in range(2):\n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        if not (self.task == 'node' or self.task == 'graph'):\n",
    "            raise RuntimeError('Unknown task.')\n",
    "\n",
    "        self.dropout = 0.25\n",
    "        self.num_layers = 3\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        if self.task == 'node':\n",
    "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        else:\n",
    "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                                  nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if data.num_node_features == 0:\n",
    "          x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            if not i == self.num_layers - 1:\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        if self.task == 'graph':\n",
    "            x = pyg_nn.global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        return emb, F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.lin_self = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Removes every self-loop in the graph given by edge_index\n",
    "        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n",
    "\n",
    "        # Transform node feature matrix.\n",
    "        self_x = self.lin_self(x)\n",
    "        #x = self.lin(x)\n",
    "\n",
    "        return self_x + self.propagate(edge_index, size=(x.size(0), x.size(0)), x=self.lin(x))\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index, size):\n",
    "        # Compute messages\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, task, writer):\n",
    "    if task == 'graph':\n",
    "        data_size = len(dataset)\n",
    "        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size=64, shuffle=True)\n",
    "        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size=64, shuffle=True)\n",
    "    else:\n",
    "        test_loader = loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes, task=task)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # train\n",
    "    for epoch in range(200):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            #print(batch.train_mask, '----')\n",
    "            opt.zero_grad()\n",
    "            embedding, pred = model(batch)\n",
    "            label = batch.y\n",
    "            if task == 'node':\n",
    "                pred = pred[batch.train_mask]\n",
    "                label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
    "                epoch, total_loss, test_acc))\n",
    "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, is_validation=False):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "\n",
    "        if model.task == 'node':\n",
    "            mask = data.val_mask if is_validation else data.test_mask\n",
    "            # node classification: only evaluate on nodes in test set\n",
    "            pred = pred[mask]\n",
    "            label = data.y[mask]\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "    \n",
    "    if model.task == 'graph':\n",
    "        total = len(loader.dataset) \n",
    "    else:\n",
    "        total = 0\n",
    "        for data in loader.dataset:\n",
    "            total += torch.sum(data.test_mask).item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip3 install tensorboardX\n",
    "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "#!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().system_raw(\n",
    "#    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "#    .format(\"./log\")\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().system_raw('./ngrok http 6006 &')\n",
    "#!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "#    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset = dataset.shuffle()\n",
    "task = 'graph'\n",
    "\n",
    "print(\"Dataset :\", dataset)\n",
    "print(\"Length of dataset :\", len(dataset))\n",
    "print(\"Number of classes in dataset :\", dataset.num_classes)\n",
    "print(\"Number of node featues in dataset :\", dataset.num_node_features)\n",
    "\n",
    "# Have access to all 600 graphs in the datase\n",
    "data = dataset[0]\n",
    "print(\"\\nDataset :\", data)\n",
    "print(\"\\nIs the graph undirected :\", data.is_undirected())\n",
    "\n",
    "# Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
    "# Data(edge_index=[2, 44], x=[12, 3], y=[1])\n",
    "# The first graph in the dataset contains 12 nodes, each one having 3 features.\n",
    "# There are 44/2 = 22 undirected edges and the graph is assigned to exactly one class.\n",
    "# In addition, the data object is holding exactly one graph-level target.\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]\n",
    "print(\"Accessing dataset [0-539] for training :\", train_dataset)\n",
    "print(\"Accessing dataset [540-599] for testing :\", test_dataset)\n",
    "\n",
    "dataset = dataset.shuffle()\n",
    "# Equivalent of the following\n",
    "# perm = torch.randperm(len(dataset))\n",
    "# dataset = dataset[perm]\n",
    "print(\"Shuffle dataset :\", dataset)\n",
    "\n",
    "# Train model\n",
    "print(\"\\n----------- Model Training -----------\")\n",
    "model = train(dataset, task, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "count = 1\n",
    "total_graphs = 0\n",
    "for data in loader:\n",
    "    # User batch to average node features in the node dimension for each graph individually\n",
    "    x = scatter_mean(data.x, data.batch, dim=0)\n",
    "    \n",
    "    if count == 1:\n",
    "        print(\"------------------------------ No. : \" + str(count) + \" ------------------------------\")\n",
    "        print(\"Batch :\\n\", data)\n",
    "        print(\"No. of batch graphs :\", data.num_graphs)\n",
    "        print(\"Size of mean x in batch :\\n\", x.size())  \n",
    "    count += 1\n",
    "    total_graphs += data.num_graphs\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"Total no. of graphs in dataset :\", total_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch is a column vector which maps each node to its respective graph in the batch:\n",
    "data.to_data_list()[0] # ['edge_index'] gives the mapping of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = Planetoid(root='/tmp/cora', name='cora')\n",
    "task = 'node'\n",
    "\n",
    "print(\"Dataset :\\n\", dataset)\n",
    "print(\"Length of dataset :\", len(dataset))\n",
    "print(\"Number of classes in dataset :\", dataset.num_classes)\n",
    "print(\"Number of node featues in dataset :\", dataset.num_node_features)\n",
    "\n",
    "# Get a single, undirected citation graph from dataset\n",
    "data = dataset[0]\n",
    "print(\"\\nDataset :\\n\", data)\n",
    "print(\"Is single citation graph undirected :\", data.is_undirected())\n",
    "\n",
    "# data object holds a label for each node, and additional attributes :\n",
    "# train_mask denotes against which nodes to train (140 nodes)\n",
    "print(\"Number of items in train mask :\", data.train_mask.sum().item())\n",
    "# val_mask denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes)\n",
    "print(\"Number of items in val mask :\", data.val_mask.sum().item())\n",
    "# test_mask denotes against which nodes to test (1000 nodes)\n",
    "print(\"Number of items in test mask :\", data.test_mask.sum().item())\n",
    "\n",
    "# Train model\n",
    "print(\"\\n----------- Model Training -----------\")\n",
    "model = train(dataset, task, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"red\", \"orange\", \"green\", \"blue\", \"purple\", \"brown\",\n",
    "              \"black\", \"yellow\", \"grey\", \"cyan\", \"pink\", \"magenta\"]\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "embs = []\n",
    "colors = []\n",
    "for batch in loader:\n",
    "    emb, pred = model(batch)\n",
    "    embs.append(emb)\n",
    "    colors += [color_list[y] for y in batch.y]\n",
    "embs = torch.cat(embs, dim=0)\n",
    "\n",
    "xs, ys = zip(*TSNE().fit_transform(embs.detach().numpy()))\n",
    "\n",
    "plt.figure(figsize=(24, 20))\n",
    "plt.scatter(xs, ys, color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph methods\n",
    "-  Graph Neural Network (GCN) <br>\n",
    "(http://tkipf.github.io/graph-convolutional-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_node_features, dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# A two-layer GCN\n",
    "# Non-linearity is not integrated in the conv calls and hence needs to be applied afterwards\n",
    "# Use ReLU as our intermediate non-linearity between and finally output a softmax distribution\n",
    "# over the number of classes\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Net().to(device)\n",
    "print(\"Current device : \", device)\n",
    "\n",
    "# Get a single, undirected citation graph from dataset\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Explainer (pytorch_geometric/examples/gnn_explainer.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from pytorch_geometric/torch_geometric/nn/models/gnn_explainer.py\n",
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "class GNNExplainer(torch.nn.Module):\n",
    "    r\"\"\"The GNN-Explainer model from the `\"GNNExplainer: Generating\n",
    "    Explanations for Graph Neural Networks\"\n",
    "    <https://arxiv.org/abs/1903.03894>`_ paper for identifying compact subgraph\n",
    "    structures and small subsets node features that play a crucial role in a\n",
    "    GNNs node-predictions.\n",
    "    .. note::\n",
    "        For an example of using GNN-Explainer, see `examples/gnn_explainer.py\n",
    "        <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/\n",
    "        gnn_explainer.py>`_.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The GNN module to explain.\n",
    "        epochs (int, optional): The number of epochs to train.\n",
    "            (default: :obj:`100`)\n",
    "        lr (float, optional): The learning rate to apply.\n",
    "            (default: :obj:`0.01`)\n",
    "        log (bool, optional): If set to :obj:`False`, will not log any learning\n",
    "            progress. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    coeffs = {\n",
    "        'edge_size': 0.005,\n",
    "        'node_feat_size': 1.0,\n",
    "        'edge_ent': 1.0,\n",
    "        'node_feat_ent': 0.1,\n",
    "    }\n",
    "\n",
    "    def __init__(self, model, epochs=100, lr=0.01, log=True):\n",
    "        super(GNNExplainer, self).__init__()\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.log = log\n",
    "\n",
    "    def __set_masks__(self, x, edge_index, init=\"normal\"):\n",
    "        (N, F), E = x.size(), edge_index.size(1)\n",
    "\n",
    "        std = 0.1\n",
    "        self.node_feat_mask = torch.nn.Parameter(torch.randn(F) * 0.1)\n",
    "\n",
    "        std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "        self.edge_mask = torch.nn.Parameter(torch.randn(E) * std)\n",
    "\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = True\n",
    "                module.__edge_mask__ = self.edge_mask\n",
    "\n",
    "    def __clear_masks__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "        self.node_feat_masks = None\n",
    "        self.edge_mask = None\n",
    "\n",
    "    def __num_hops__(self):\n",
    "        num_hops = 0\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                num_hops += 1\n",
    "        return num_hops\n",
    "\n",
    "    def __flow__(self):\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def __subgraph__(self, node_idx, x, edge_index, **kwargs):\n",
    "        num_nodes, num_edges = x.size(0), edge_index.size(1)\n",
    "\n",
    "        subset, edge_index, edge_mask = k_hop_subgraph(\n",
    "            node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,\n",
    "            num_nodes=num_nodes, flow=self.__flow__())\n",
    "\n",
    "        x = x[subset]\n",
    "        for key, item in kwargs:\n",
    "            if torch.is_tensor(item) and item.size(0) == num_nodes:\n",
    "                item = item[subset]\n",
    "            elif torch.is_tensor(item) and item.size(0) == num_edges:\n",
    "                item = item[edge_mask]\n",
    "            kwargs[key] = item\n",
    "\n",
    "        return x, edge_index, edge_mask, kwargs\n",
    "\n",
    "    def __loss__(self, node_idx, log_logits, pred_label):\n",
    "        loss = -log_logits[node_idx, pred_label[node_idx]]\n",
    "\n",
    "        m = self.edge_mask.sigmoid()\n",
    "        loss = loss + self.coeffs['edge_size'] * m.sum()\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['edge_ent'] * ent.mean()\n",
    "\n",
    "        m = self.node_feat_mask.sigmoid()\n",
    "        loss = loss + self.coeffs['node_feat_size'] * m.sum()\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['node_feat_ent'] * ent.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def explain_node(self, node_idx, x, edge_index, **kwargs):\n",
    "        r\"\"\"Learns and returns a node feature mask and an edge mask that play a\n",
    "        crucial role to explain the prediction made by the GNN for node\n",
    "        :attr:`node_idx`.\n",
    "        Args:\n",
    "            node_idx (int): The node to explain.\n",
    "            x (Tensor): The node feature matrix.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            **kwargs (optional): Additional arguments passed to the GNN module.\n",
    "        :rtype: (:class:`Tensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        num_edges = edge_index.size(1)\n",
    "\n",
    "        # Only operate on a k-hop subgraph around `node_idx`.\n",
    "        x, edge_index, hard_edge_mask, kwargs = self.__subgraph__(\n",
    "            node_idx, x, edge_index, **kwargs)\n",
    "\n",
    "        # Get the initial prediction.\n",
    "        with torch.no_grad():\n",
    "            log_logits = self.model(x=x, edge_index=edge_index, **kwargs)\n",
    "            pred_label = log_logits.argmax(dim=-1)\n",
    "\n",
    "        self.__set_masks__(x, edge_index)\n",
    "        self.to(x.device)\n",
    "\n",
    "        optimizer = torch.optim.Adam([self.node_feat_mask, self.edge_mask],\n",
    "                                     lr=self.lr)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description(f'Explain node {node_idx}')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.view(1, -1).sigmoid()\n",
    "            log_logits = self.model(x=h, edge_index=edge_index, **kwargs)\n",
    "            loss = self.__loss__(0, log_logits, pred_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if self.log:  # pragma: no cover\n",
    "                pbar.update(1)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar.close()\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid()\n",
    "        edge_mask = self.edge_mask.new_zeros(num_edges)\n",
    "        edge_mask[hard_edge_mask] = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        return node_feat_mask, edge_mask\n",
    "\n",
    "    def visualize_subgraph(self, node_idx, edge_index, edge_mask, y=None,\n",
    "                           threshold=None, **kwargs):\n",
    "        r\"\"\"Visualizes the subgraph around :attr:`node_idx` given an edge mask\n",
    "        :attr:`edge_mask`.\n",
    "        Args:\n",
    "            node_idx (int): The node id to explain.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            edge_mask (Tensor): The edge mask.\n",
    "            y (Tensor, optional): The ground-truth node-prediction labels used\n",
    "                as node colorings. (default: :obj:`None`)\n",
    "            threshold (float, optional): Sets a threshold for visualizing\n",
    "                important edges. If set to :obj:`None`, will visualize all\n",
    "                edges with transparancy indicating the importance of edges.\n",
    "                (default: :obj:`None`)\n",
    "            **kwargs (optional): Additional arguments passed to\n",
    "                :func:`nx.draw`.\n",
    "        :rtype: :class:`matplotlib.pyplot`\n",
    "        \"\"\"\n",
    "\n",
    "        assert edge_mask.size(0) == edge_index.size(1)\n",
    "\n",
    "        # Only operate on a k-hop subgraph around `node_idx`.\n",
    "        subset, edge_index, hard_edge_mask = k_hop_subgraph(\n",
    "            node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,\n",
    "            num_nodes=None, flow=self.__flow__())\n",
    "\n",
    "        edge_mask = edge_mask[hard_edge_mask]\n",
    "\n",
    "        if threshold is not None:\n",
    "            edge_mask = (edge_mask >= threshold).to(torch.float)\n",
    "\n",
    "        if y is None:\n",
    "            y = torch.zeros(edge_index.max().item() + 1,\n",
    "                            device=edge_index.device)\n",
    "        else:\n",
    "            y = y[subset].to(torch.float) / y.max().item()\n",
    "\n",
    "        data = Data(edge_index=edge_index, att=edge_mask, y=y,\n",
    "                    num_nodes=y.size(0)).to('cpu')\n",
    "        G = to_networkx(data, node_attrs=['y'], edge_attrs=['att'])\n",
    "        mapping = {k: i for k, i in enumerate(subset.tolist())}\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        kwargs['with_labels'] = kwargs.get('with_labels') or True\n",
    "        kwargs['font_size'] = kwargs.get('font_size') or 10\n",
    "        kwargs['node_size'] = kwargs.get('node_size') or 800\n",
    "        kwargs['cmap'] = kwargs.get('cmap') or 'cool'\n",
    "\n",
    "        pos = nx.spring_layout(G)\n",
    "        ax = plt.gca()\n",
    "        for source, target, data in G.edges(data=True):\n",
    "            ax.annotate(\n",
    "                '', xy=pos[target], xycoords='data', xytext=pos[source],\n",
    "                textcoords='data', arrowprops=dict(\n",
    "                    arrowstyle=\"->\",\n",
    "                    alpha=max(data['att'], 0.1),\n",
    "                    shrinkA=sqrt(kwargs['node_size']) / 2.0,\n",
    "                    shrinkB=sqrt(kwargs['node_size']) / 2.0,\n",
    "                    connectionstyle=\"arc3,rad=0.1\",\n",
    "                ))\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=y.tolist(), **kwargs)\n",
    "        nx.draw_networkx_labels(G, pos, **kwargs)\n",
    "        plt.axis('off')\n",
    "        return plt\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from pytorch_geometric/torch_geometric/utils/subgraph.py\n",
    "def maybe_num_nodes(index, num_nodes=None):\n",
    "    return index.max().item() + 1 if num_nodes is None else num_nodes\n",
    "\n",
    "def k_hop_subgraph(node_idx, num_hops, edge_index, relabel_nodes=False,\n",
    "                   num_nodes=None, flow='source_to_target'):\n",
    "    r\"\"\"Computes the :math:`k`-hop subgraph of :obj:`edge_index` around node\n",
    "    :attr:`node_idx`.\n",
    "    It returns (1) the nodes involved in the subgraph, (2) the filtered\n",
    "    :obj`edge_index` connectivity, and (3) the edge mask indicating which edges\n",
    "    were preserved.\n",
    "    Args:\n",
    "        node_idx (int): The central node.\n",
    "        num_hops: (int): The number of hops :math:`k`.\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting\n",
    "            :obj:`edge_index` will be relabeled to hold consecutive indices\n",
    "            starting from zero. (default: :obj:`False`)\n",
    "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
    "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
    "        flow (string, optional): The flow direction of :math:`k`-hop\n",
    "            aggregation (:obj:`\"source_to_target\"` or\n",
    "            :obj:`\"target_to_source\"`). (default: :obj:`\"source_to_target\"`)\n",
    "    :rtype: (:class:`LongTensor`, :class:`LongTensor`, :class:`BoolTensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    subsets = [torch.tensor([node_idx], device=row.device).flatten()]\n",
    "    for _ in range(num_hops):\n",
    "        node_mask.fill_(False)\n",
    "        node_mask[subsets[-1]] = True\n",
    "        torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "        subsets.append(col[edge_mask])\n",
    "    subset = torch.cat(subsets).unique()\n",
    "    # Add `node_idx` to the beginning of `subset`.\n",
    "    subset = subset[subset != node_idx]\n",
    "    subset = torch.cat([torch.tensor([node_idx], device=row.device), subset])\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes, ), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Sequential, Linear\n",
    "\n",
    "dataset = 'Cora'\n",
    "path = '/tmp/cora'\n",
    "\n",
    "dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "\n",
    "# Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n",
    "data = dataset[0]\n",
    "print(\"Data before sent to device :\\n\", data)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin = Sequential(Linear(10, 10))\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device : \", device)\n",
    "\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "print(\"Data to device :\\n\", data)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "x, edge_index = data.x, data.edge_index\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    log_logits = model(x, edge_index)\n",
    "    loss = F.nll_loss(log_logits[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "explainer = GNNExplainer(model, epochs=200)\n",
    "node_idx = 10\n",
    "node_feat_mask, edge_mask = explainer.explain_node(node_idx, x, edge_index)\n",
    "plt = explainer.visualize_subgraph(node_idx, edge_index, edge_mask, y=data.y)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder for unsupervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = pyg_nn.GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "def unsupervised_train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    writer.add_scalar(\"loss\", loss.item(), epoch)\n",
    "\n",
    "def unsupervised_test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = Planetoid(\"/tmp/citeseer\", \"Citeseer\", T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "channels = 16\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA availability:', torch.cuda.is_available())\n",
    "\n",
    "# encoder: written by us; decoder: default (inner product)\n",
    "model = pyg_nn.GAE(Encoder(dataset.num_features, channels)).to(dev)\n",
    "labels = data.y\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "\n",
    "#data = model.split_edges(data)\n",
    "data = pyg_utils.train_test_split_edges(data)\n",
    "\n",
    "x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    unsupervised_train(epoch)\n",
    "    auc, ap = unsupervised_test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    writer.add_scalar(\"AUC\", auc, epoch)\n",
    "    writer.add_scalar(\"AP\", ap, epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z = model.encode(x, train_pos_edge_index)\n",
    "colors = [color_list[y] for y in labels]\n",
    "\n",
    "xs, ys = zip(*TSNE().fit_transform(z.cpu().detach().numpy()))\n",
    "\n",
    "plt.figure(figsize=(24, 20))\n",
    "plt.scatter(xs, ys, color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
